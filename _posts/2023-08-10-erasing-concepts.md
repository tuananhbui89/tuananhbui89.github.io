---
title: 'On Reading: Erasing Concepts from Diffusion Models'
date: 2023-08-05
permalink: /posts/2023/08/papers/erasingconcepts/
tags:
  - Generative model
  - Diffusion model
  - Paper reading
---
<br>

- [About the paper](#about-the-paper)
- [Approach](#approach)
- [How to implement](#how-to-implement)

About the paper
=====

- Published at ICCV 2023
- Affiliations: Northeastern University and MIT.
- Motivation: Remove specific concepts from diffusion models weights. The concept can be a specific style (i.e., nudity, Van Gogh style, etc.) or a specific object (i.e., car, dog, etc.) while preserving capability on other concepts.

<!-- Add an image -->
|![Examples](https://raw.githubusercontent.com/tuananhbui89/website_images/master/posts/erasing_concepts/examples.png)|
|:--:|
| *Examples of erasing nudity, Van Gogh style or an objects from a Stable Diffusion model (Image source: [Gandikota et al. (2023)](https://erasing.baulab.info/))* |
- Project page: [https://erasing.baulab.info/](https://erasing.baulab.info/)


Approach
=====

The central optimization problem is to reduce  the probability of generating an image $x$ according to the likelihood that is described by the concept, scaled by a power factor $\eta$.

$$P_\theta(x) \propto \frac{P_{\theta^*}(x)}{{P_{\theta^*}(c \mid x)}^\eta}$$

where $P_{\theta^*}(x)$ is the distribution generated by the original model $\theta^*$ and $P_{\theta^*}(c \mid x)$ is the probability of the concept $c$ given the image $x$. The power factor $\eta$ controls the strength of the concept erasure. A larger $\eta$ means a stronger erasure. $\theta$ is the parameters of the model after unlearning the concept $c$.

It can be interpreted as: if the concept $c$ is present in the image $x$ in which $P_{\theta^*} (c \mid x)$ is high, then the likelihood of the image $x$ under the new model $P_{\theta} (x)$ will be reduced.
While if the concept $c$ is not present in the image $x$ in which $P_{\theta^*} (c \mid x)$ is low, then the likelihood of the image $x$ under the new model $P_{\theta} (x)$ will be increased.

Because of the conditional likelihood:

$$ P_{\theta^*} (c \mid x) = \frac{P_{\theta^*} (x \mid c) P_{\theta^*} (c)}{P_{\theta^*} (x)} $$

Therefore, the above equation can be rewritten when taking the derivative w.r.t. $x$ as follows:

$$ \nabla_{x} \log P_{\theta} (x) \propto \nabla_{x} \log P_{\theta^*} (x) - \eta \nabla_{x} \log P_{\theta^*} (c \mid x) $$

$$ \nabla_{x} \log P_{\theta} (x) \propto \nabla_{x} \log P_{\theta^*} (x) - \eta (\nabla_{x} \log P_{\theta^*} (x \mid c) + \nabla_{x} \log P_{\theta^*} (c) - \nabla_{x} \log P_{\theta^*} (x)) $$

$$ \nabla_{x} \log P_{\theta} (x) \propto \nabla_{x} \log P_{\theta^*} (x) - \eta (\nabla_{x} \log P_{\theta^*} (x \mid c) - \nabla_{x} \log P_{\theta^*} (x)) $$

Because in the diffusion model, each step has been approximated to a Gaussian distribution, therefore, the gradient of the log-likelihood is computed as follows:

$$ \nabla_{x} \log P_{\theta^*} (x) = \frac{1}{\sigma^2} (x - \mu) $$

where $\mu$ is the mean of the diffusion model, $\sigma$ is the standard deviation of the diffusion model, and $c$ is the concept.
Based on the repameterization trick, the gradient of the log-likelihood is correlated with the noise $\epsilon$ at each step as follows:

$$ \epsilon_{\theta}(x_t,t) \propto \epsilon_{\theta^*} (x_t,t) - \eta (\epsilon_{\theta^*}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t)) $$

where $\epsilon_{\theta}(x_t,t)$ is the noise at step $t$ of the diffusion model after unlearning the concept $c$.
Finally, to fine-tune the diffusion model from pretrained model $\theta^*$ to new cleaned model $\theta$, the authors proposed to minimize the following loss function:

$$ \mathcal{L}(\theta) = \mathbb{E}_{x_0 \sim \mathcal{D}} \left[ \sum_{t=0}^{T-1} \left\| \epsilon_{\theta}(x_t,t) - \epsilon_{\theta^*} (x_t,t) + \eta (\epsilon_{\theta^*}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t)) \right\|^2 \right] $$

where $x_0$ is the input image sampled from data distribution $\mathcal{D}$, $T$ is the number of steps of the diffusion model.

Instead of recursively sampling the noise $\epsilon_{\theta}(x_t,t)$ at every step, we can sample the time step $t \sim \mathcal{U}(0, T-1)$ and then sample the noise $\epsilon_{\theta}(x_t,t)$ at that time step.
Therefore, the loss function can be rewritten as follows:

$$ \mathcal{L}(\theta) = \mathbb{E}_{x_0 \sim \mathcal{D}} \left[ \left\| \epsilon_{\theta}(x_t,t) - \epsilon_{\theta^*} (x_t,t) + \eta (\epsilon_{\theta^*}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t)) \right\|^2 \right] $$

where $t \sim \mathcal{U}(0, T-1)$.

However, in the paper, instead of using the above loss function, the author proposed to use the following loss function:

$$ \mathcal{L}(\theta) = \mathbb{E}_{x_0 \sim \mathcal{D}} \left[  \left\| \epsilon_{\theta}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t) + \eta (\epsilon_{\theta^*}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t)) \right\|^2 \right] $$

where $t \sim \mathcal{U}(0, T-1)$.

The difference between the two loss functions is that the first loss function is computed based on the unconditional noise $\epsilon_{\theta}(x_t,t)$ at the time step $t$ while the second loss function is computed based on the noise $\epsilon_{\theta}(x_t,c,t)$ at the time step $t$ conditioned on the concept $c$.

Interpretation of the loss function: By minimizing the above loss function, we try to force the conditional noise $\epsilon_{\theta}(x_t,c,t)$ to be close to the unconditional noise $\epsilon_{\theta^*} (x_t,t)$ of the original model.

How to implement
=====
