<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Comprehensive Algorithm Portfolio Evaluation using Item Response Theory | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="How to evaluate how good an algorithm is?">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="http://localhost:4000/blog/2023/fairness-irt/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Comprehensive Algorithm Portfolio Evaluation using Item Response Theory</h1>
    <p class="post-meta">September 1, 2023</p>
    <p class="post-tags">
      <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>
        ·  
        <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          <a href="/blog/tag/tml">
          <i class="fas fa-hashtag fa-sm"></i> tml</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#about-the-paper">About the paper</a></li>
<li class="toc-entry toc-h2"><a href="#summary">Summary</a></li>
<li class="toc-entry toc-h2">
<a href="#item-response-theory">Item Response Theory</a>
<ul>
<li class="toc-entry toc-h3">
<a href="#family-of-irt-models">Family of IRT models</a>
<ul>
<li class="toc-entry toc-h4"><a href="#dichotomous-irt-model">Dichotomous IRT model</a></li>
<li class="toc-entry toc-h4"><a href="#polytomous-irt-model">Polytomous IRT model</a></li>
<li class="toc-entry toc-h4"><a href="#continuous-irt-model">Continuous IRT model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#mapping-algorithm-evaluation-to-irt">Mapping algorithm evaluation to IRT</a></li>
<li class="toc-entry toc-h2"><a href="#characteristics-of-algorithms-estimated-by-irt-model">Characteristics of algorithms estimated by IRT model</a></li>
<li class="toc-entry toc-h2"><a href="#framework">Framework</a></li>
<li class="toc-entry toc-h2"><a href="#questions">Questions</a></li>
<li class="toc-entry toc-h2">
<a href="#future-work-irt-based-disentanglement-learning">Future work: IRT-based Disentanglement Learning</a>
<ul>
<li class="toc-entry toc-h3"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h3"><a href="#proposed-framework">Proposed framework</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#references">References</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <h2 id="about-the-paper">About the paper</h2>

<ul>
  <li>Link to the paper: <a href="https://arxiv.org/abs/2307.15850" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2307.15850</a>
</li>
  <li>Authors: Sevvandi Kandanaarachchi, Kate Smith-Miles, CSIRO, Uni Melb</li>
  <li>
<a href="https://www.youtube.com/watch?v=gA-Ds1PEP_o&amp;ab_channel=OPTIMAARC" rel="external nofollow noopener" target="_blank">Talk at OPTIMA ARC</a> and <a href="https://www.slideshare.net/SevvandiKandanaarach/algorithm-evaluation-using-item-response-theorypptx?from_action=save" rel="external nofollow noopener" target="_blank">its slide</a>
</li>
</ul>

<h2 id="summary">Summary</h2>

<p>The paper proposed a framework to evaluate a portfolio of algorithms using Item Response Theory (IRT). Instead of using the standard IRT mapping, the authors proposed to invert the mapping by considering the datasets as agents and the algorithms as items. By using this mapping, the IRT model now can give more insights about the characteristics of algorithms including the algorithm anomalousness, consistency, and dataset difficulty. In addition, the framework also provides analysis of strengths and weaknesses of algorithms in the problem space which can be used to select the best algorithm for a given dataset.</p>

<h2 id="item-response-theory">Item Response Theory</h2>

<p>Item Response Theory (IRT) is a psychometric theory that models the relationship between the latent trait (such as verbal or mathematical ability, that cannot be directly measured) of a person and the probability of a person to answer a question correctly. Using the participant responses to the test items, an IRT model is fitted to estimate the discrimination and difficulty of test items and the ability of participants.</p>

<h3 id="family-of-irt-models">Family of IRT models</h3>

<h4 id="dichotomous-irt-model">Dichotomous IRT model</h4>

<p>The simplest IRT model is the dichotomous IRT model, which assumes that the probability of a person to answer a question correctly is a logistic function of the difference between the person’s ability and the item’s difficulty. The model is formulated as follows:</p>

\[P(X_{ij} = 1 \mid \theta_i, \alpha_j, \beta_j) = \frac{1}{1 + e^{- \alpha_j (\theta_i - \beta_j)}}\]

<p>where \(X_{ij}\) is the response of person \(i\) to item \(j\), \(\theta_i\) is the ability of person \(i\), \(\beta_j\) is the difficulty of item \(j\), and \(\alpha_j\) is the discrimination parameter.</p>

<p>3PL: introducing one additional guesing parameter \(\gamma_j\) to the model:</p>

\[P(X_{ij} = 1 \mid \theta_i, \alpha_j, \beta_j, \gamma_j) = \gamma_j + (1 - \gamma_j) \frac{1}{1 + e^{- \alpha_j (\theta_i - \beta_j)}}\]

<p>Figure below shows the probability of a person to answer a question correctly as a function of the person’s ability \(\theta_i\) given the item’s parameters \(\alpha_j, \beta_j, \gamma_j\).</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2309/fairness-irt/3PL-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2309/fairness-irt/3PL-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2309/fairness-irt/3PL-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2309/fairness-irt/3PL.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    3PL
</div>

<h4 id="polytomous-irt-model">Polytomous IRT model</h4>

<p>The polytomous IRT model is an extension of the dichotomous IRT model that allows for more than two response categories (e.g., an answer is marked not just correct/incorrect but with score from 1 to K). The most common polytomous IRT model is the graded response model (GRM), in which the cummulative probabilities of a person to get a higher or equal to score \(k\) is formulated as follows:</p>

\[P(X_{ij} \geq k \mid \theta_i, \alpha_j, \beta_j^k) = \frac{1}{1 + e^{- \alpha_j (\theta_i - \beta_j^k)}}\]

<p>where \(X_{ij}\) is the response of person \(i\) to item \(j\), \(\theta_i\) is the ability of person \(i\), \(\beta_j^k\) is the difficulty of item \(j\) for response category \(k\), and \(\alpha_j\) is the discrimination parameter. Each item \(j\) has a set of difficulties \(\beta_j = \{ \beta_j^k \}_{k=1}^K\) which is making sense because the difficulty of an item is different for different response categories.</p>

<p>The probability of a person to get a score \(k\) is formulated as follows:</p>

\[P(X_{ij} = k \mid \theta_i, \alpha_j, \beta_j) = P(X_{ij} \geq k \mid \theta_i, \alpha_j, \beta_j^k) - P(X_{ij} \geq k+1 \mid \theta_i, \alpha_j, \beta_j^{k+1})\]

<p>Given parameters \(\alpha_j, \beta_j\) are known and fixed, the probability of a person to get a score \(k\) is a curve that is a function of the person’s ability \(\theta_i\). And given the person’s ability \(\theta_i\) and the item’s parameters \(\alpha_j, \beta_j\), we can estimate the most likely score \(k\) of the person which is the score that maximizes the probability \(P(X_{ij} = k \mid \theta_i, \alpha_j, \beta_j)\).</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2309/fairness-irt/poly-IRT-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2309/fairness-irt/poly-IRT-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2309/fairness-irt/poly-IRT-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2309/fairness-irt/poly-IRT.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Polytomous IRT
</div>

<h4 id="continuous-irt-model">Continuous IRT model</h4>

<p>The continuous IRT model is an extension of the dichotomous IRT model that allows for continuous responses (e.g., the response is a real number between 0 and 1). The density function of the continuous IRT model is formulated as follows:</p>

\[f(z_{ij} \mid \theta_i) = \frac{\alpha_j \gamma_j}{2 \pi} \exp(- \frac{\alpha_j^2}{2}(\theta_i - \beta_j - \gamma_j z_j))\]

<p>where \(\theta_i\) is the ability of person \(i\), \(\beta_j\) is the difficulty of item \(j\), \(\alpha_j\) is the discrimination parameter, and \(\gamma_j\) is the scaling factor. \(z_{ij}\) is the normalized response of person \(i\) to item \(j\) which is formulated as follows:</p>

\[z_{j} = \ln \frac{x_{j}}{ k_j -  x_j}\]

<p>where \(x_{j}\) is a continuous score between 0 and \(k_j\) and \(k_j\) is the maximum score of item \(j\). \(z_j\) has a range between \(-\infty\) and \(\infty\).</p>

<p>In this model, these are total 3 parameters for each item \(j\) (i.e., \(\beta_j, \alpha_j, \gamma_j\)$) and 1 parameter for each person \(i\) (i.e., \(\theta_i\)$). Unlike the polytomous IRT model, the difficulty \(\beta_j\) of an item \(j\) is the same for all response categories.</p>

<h2 id="mapping-algorithm-evaluation-to-irt">Mapping algorithm evaluation to IRT</h2>

<!-- Given a group of students (i.e., algorithms) and a set of items/questions (i.e., datasets), the goal of IRT is to estimate the ability of each student and the difficulty of each question. The ability of a student is the probability of the student to answer a question correctly. -->

<p>To understand the mapping better, let’s consider the following components of IRT:</p>

<ul>
  <li>The agents: a group of students or algorithms in which each agent is associated with a set of characteristics (e.g., ability of a student, parameters of an algorithm)</li>
  <li>The items: a set of questions or datasets in which each item is associated with a set of characteristics (e.g., difficulty, discrimination, bias)</li>
  <li>The responses: the responses of agents to items (e.g., the responses of students to questions, the performance of algorithms on datasets)</li>
</ul>

<p>IRT models the relationship between the characteristics of agents and items and the responses of agents to items. The goal of IRT is to estimate the characteristics of agents and items given the responses of agents to items, with the primary goal of estimating the characteristics of items (e.g., the difficulty of questions which is broader interest than the ability of each individual student).</p>

<p>It can be seen that, in the dichotomous IRT model, there are two parameters of an item (i.e., difficulty and discrimination) and one parameter of an agent (i.e., ability). In the polytomous IRT model, for each item, there are \(K\) parameters of difficulty (i.e., \(\{\beta_j^k\}_{k=1}^K\)$) and one parameter \(\alpha_j\) for discrimination, while there is only one parameter of an agent (i.e., ability \(\theta_i\)$).</p>

<p><strong>Mapping algorithm evaluation to IRT</strong>:</p>

<p>In the context of algorithm evaluation, the agents are algorithms and the items are datasets. The responses are the performance of algorithms on datasets. Let \(f_{\theta_i}\) is an agent (i.e., an algorithm) parameterized by \(\theta_i\). \(x_j\) is an item (i.e., a dataset) belonging to set of items \(X\), each dataset \(x_j\) is associated with a set of characteristics \(c_j\) (e.g., difficulty, discrimination, bias).</p>

<p>Within the context, the IRT model now estimates the probability of an algorithm \(f_{\theta_i}\) to solve a dataset \(x_j\) given the characteristics \(c_j\) of the dataset and the ability \(\theta_i\) of the algorithm.</p>

<p>However, as the authors mentioned in the paper, with this standard mapping, the IRT model is focusing on evaluating the characteristics of datasets (i.e., items) rather than the characteristics of algorithms (i.e., agents). Therefore, the authors proposed to invert the mapping by considering the datasets as agents and the algorithms as items.</p>

<p>By using the inverted mapping, the IRT model now can give more insights about the characteristics of algorithms rather than the characteristics of datasets, thanks to the fact that there are more parameters to be estimated for each algorithm (i.e., 3 parameters for each algorithm in the continuous IRT model) than for each dataset (i.e., 1 parameter for each dataset in the continuous IRT model).</p>

<p>More specifically, if we consider the continuous IRT model and the inverted mapping, the following are the parameters of the model:</p>

<ul>
  <li>\(\beta_j\) is the difficulty of item \(j\), in this case, the (reversed) difficulty limit of algorithm \(j\).</li>
  <li>\(\alpha_j\) is the discrimination parameter of item \(j\), in this case, the (reversed) algorithm anomalousness and consistency.</li>
  <li>\(\gamma_j\) is the scaling factor of item \(j\), in this case, the algorithm bias (I am not sure about this because it was not mentioned in the paper).</li>
  <li>\(\theta_i\) is the ability of agent \(i\), in this case, the (reversed) dataset difficulty.</li>
</ul>

<h2 id="characteristics-of-algorithms-estimated-by-irt-model">Characteristics of algorithms estimated by IRT model</h2>

<ul>
  <li>
    <p><strong>Dataset difficulty</strong>: It is estimated by \(\delta_i = -\theta_i\) which is the ability of agent \(i\), in this case the dataset difficulty. Given a fixed algorithm’s characteristics, the probability of a dataset to be solved by the algorithm will increase as \(\theta_i\) increases. Therefore, an dataset \(i\) is considered to be easy if \(\theta_i\) is large or vice versa.</p>
  </li>
  <li>
    <p><strong>Algorithm anomalousness</strong>: It is estimated by \(sign(\alpha_j)\) (i.e., TRUE if \(\alpha_j &lt; 0\) and FALSE if \(\alpha_j &gt; 0\)$) show whether the algorithm is anomalous or not. It is because in the logistic function, if \(\alpha_j &lt; 0\), then the probability of the agent (i.e., a dataset) act on the item (i.e., an algorithm) is decreasing as the ability of the agent increases (i.e., \(\theta_i\) or easiness of a dataset). In other words, the algorithm is more likely to fail on a easy dataset than on a hard dataset which is an anomalous behavior.</p>
  </li>
  <li>
    <p><strong>Algorithm consistency</strong>: It is estimated by \(1/\|\alpha_j\|\) (i.e., inverse of the absolute value of \(\alpha_j\)$), which shows the consistency of the algorithm. It is because in the logistic function, the \(\alpha_j\) is the slope of the curve, therefore, the larger the \(\alpha_j\), the steeper the curve, which means that the algorithm is changing its behavior more rapidly as the ability of the agent changes (i.e., \(\theta_i\) or easiness of a dataset). In other words, large \(\alpha_j\) or small \(1/\|\alpha_j\|\) means that the algorithm is less consistent/stable/robust against the change of the difficulty of a dataset.</p>
  </li>
  <li>
    <p><strong>Difficulty limit of algorithm</strong>: It is estimated by \(-\beta_j\) which is the difficulty of item \(j\). In this case, the difficulty limit of algorithm \(j\). It is because in the logistic function, the \(\beta_j\) is the point at which the probability of the agent (i.e., a dataset) act on the item (i.e., an algorithm) is 0.5. In other words, the difficulty limit of algorithm \(j\) is the difficulty of a dataset \(i\) at which the algorithm \(j\) has 50% chance to solve the dataset \(i\). The higher difficulty limit of algorithm \(j\), the more difficult dataset that the algorithm \(j\) can solve.</p>
  </li>
  <li>
    <p><strong>Algorithm bias</strong>: (This was not mentioned in the paper but just my analysis) It is estimated by \(\gamma_j\) which is the scaling factor of item \(j\). In this case, the algorithm bias. It can be seen that in the continuous IRT model, the \(\gamma_j\) has to be same sign as \(\alpha_j\) (i.e., \(\alpha_j \gamma_j &gt; 0\)$). Just consider the case when \(\gamma_j &gt; 0\), then the higher the \(\gamma_j\), the higher the probability that the dataset is solved by the algorithm. More interestingly, the \(\gamma_j\) is the scaling factor of the response \(z_j = \ln \frac{x_j}{k_j - x_j}\) which will be very large if \(x_j\) is close to \(k_j\) (i.e., the maximum score of item \(j\)$). Therefore, the density function \(f(z_{ij} \mid \theta_i)\) will be very large if \(x_j\) is close to \(k_j\) which means that the probability of the dataset to be solved by the algorithm is very high if \(x_j\) is close to \(k_j\) which is makes sense because the dataset is easy. In contrast, the density function \(f(z_{ij} \mid \theta_i)\) will be very small if \(x_j\) is close to 0. Therefore, the continuous IRT model is strongly biased towards the extreme values of the response \(x_j\) (i.e., \(x_j = 0\) or \(x_j = k_j\)$) which is not good. However, if the scaling factor \(\gamma_j\) is small, it reduces this bias issue, vice versa. Therefore, the \(\gamma_j\) can be used to measure the bias of the algorithm.</p>
  </li>
  <li>
    <p><strong>Performance-Dataset Difficulty Curve</strong>: after getting all the above parameteres of \(n\) algorithms on \(N\) datasets/problems, we can estimate the performance-dataset difficulty curve \(h_j(\delta)\) of each algorithm \(j\) by using function estimation method (i.e., smoothing spline as proposed in the paper).</p>
  </li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2309/fairness-irt/smoothing-spline-2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2309/fairness-irt/smoothing-spline-2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2309/fairness-irt/smoothing-spline-2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2309/fairness-irt/smoothing-spline-2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Smoothing spline
</div>

<ul>
  <li>
<strong>Strengths and weaknesses of algorithm</strong>: based on the performance-dataset difficulty curve \(h_j(\delta)\), we can identify the strengths and weaknesses of each algorithm \(j\) by comparing between curves/algorithms. For example, if the curve of algorithm \(j\) is above the curve of algorithm \(k\) for all \(\delta\), then algorithm \(j\) is better than algorithm \(k\) for all \(\delta\). Given a dataset difficulty \(\delta\), we can find the best algorithm which has the highest value of \(h_j(\delta)\). We also can define a region where an algorithm can be considered as algorithm’s strengths or weaknesses.</li>
</ul>

<h2 id="framework">Framework</h2>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2309/fairness-irt/algorithm-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2309/fairness-irt/algorithm-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2309/fairness-irt/algorithm-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2309/fairness-irt/algorithm.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    AIRT framework
</div>

<p>The AIRT framework can be found in page 28 of the paper, which consists of 3 main stages:</p>

<ul>
  <li>
<strong>Stage 1 - Fitting the IRT model with inverted mapping</strong> Given an input matrix \(Y_{N \times n}\) containing accuracy measures of \(n\) algorithms for \(N\) datasets, the IRT model is fitted to estimate the parameters of the model (i.e., \(\beta_j, \alpha_j, \gamma_j, \theta_i\)). The authors proposed to use the continuous IRT model with the inverted mapping. The parameters of the model are estimated using the Expectation-Maximization (EM) algorithm.</li>
  <li>
<strong>Stage 2 - Calculation of algorithm and dataset metrics</strong> For each algorithm \(j\) compute the anomalous indicator, algorithm consistency score and difficulty limit. For each dataset \(i\) compute the dataset difficulty \(\delta_i = - \theta_i\).</li>
  <li><strong>Stage 3 - Computing strengths and weaknesses and construct airt portfolio</strong></li>
</ul>

<h2 id="questions">Questions</h2>

<ul>
  <li>In IRT model, an agent (e.g., an algorithm) and an item (e.g., a dataset) are assumed to be independent. However, in the context of machine learning where an algorithm is trained on a training set and tested on a test set - which is the item in IRT model, the assumption of independence is not true.
For example, a good algorithm but was trained on a biased training set will perform worse on a test set than a bad algorithm but was trained on an unbiased training set. Therefore, the performance of an algorithm on a test set is not only determined by the algorithm itself but also the training set it was trained on. So how to deal with this issue in IRT model?</li>
  <li>Extend the above question, how to deal with the case when many algorithms were trained on the same training set?</li>
</ul>

<h2 id="future-work-irt-based-disentanglement-learning">Future work: IRT-based Disentanglement Learning</h2>

<h3 id="introduction">Introduction</h3>

<p>This project aims to disentangle ML-bias into algorithmic and data bias focussing on intersectional subgroups.</p>

<p>So what are algorithmic bias and data bias in the context of machine learning?</p>

<ul>
  <li>
<strong>Data bias</strong> is the bias in the training data that is used to train the ML model. It occurs when the data used for training is not representative of the real-world population or when it contains inherent biases. For example, a dataset of images of people that is used to train a facial recognition system may contain more images of white people than people of color. This can lead to the facial recognition system being less accurate when identifying people of color.</li>
  <li>
<strong>Algorithmic bias</strong> is the bias in the algorithm itself. It occurs when the algorithm is not designed to be fair or when it is not trained to be fair. For example, a facial recognition system that is trained with purpose to identify people in a specific demographic group (e.g., white people) will be less accurate when identifying people in other demographic groups (e.g., people of color).</li>
</ul>

<p>Recognizing data bias is a challenging task because the data bias is not always obvious and the dataset is usually large and complex.
Equally complex is the task of recognizing algorithmic bias because the training process of a ML model is also complex where the bias can be introduced at any stage such as data collection, feature selection, or the choice of objective function.</p>

<p>To adapt the IRT model to the context of machine learning, we need to consider the following:</p>

<ul>
  <li>
<strong>The algorithm</strong> is the pretrained model which is trained on a training set (which can be biased or unbiased but we don’t know)</li>
  <li>
<strong>The dataset</strong> is to mention the test set which is used to evaluate the algorithm. The dataset can be sampled from the same distribution as the training set or from a different distribution.</li>
  <li>The algorithms are assumed to be independent even are trained on the same training set. The algorithms also have the same task on the test set (e.g., the pretrained ResNet50, VGG19 models to predict an image into 1 of 10 classes).</li>
  <li>The dataset are assumed to be disjoint. The datasets also are served for the same task (e.g., to test performance of classification models)</li>
  <li>
<strong>The data bias</strong> problem in this context is the bias of the test item which is used to evaluated the algorithm (not the bias of the training set as in ML literature). For example, let’s consider education system where a test item is a set of questions and an algorithm is a student. We want to evaluate diverse knowledge of students on several subjects, i.e., math, physics, chemistry, literature, etc. The data bias problem in this context is that the test item is only able to evaluate on a specific subject (e.g., math) but not on all subjects. <strong>The algorithmic bias</strong> problem in this specific example is that the student is only good at math but not good at other subjects.</li>
</ul>

<p>Problem setting: Given \(n\) algorithms and \(N\) datasets, the goal is to identify which algorithm/dataset has bias problem. On the other words, how to distinguish a good algorithm performing poorly on a biased dataset from an equally performed bad algorithm?</p>

<p><strong>Note:</strong></p>

<ul>
  <li>The term “disentangle learning” is commonly referred to the approach that learns disentangled representations of data in machine learning. However, in this project, the term “disentangle learning” is used to refer to the approach that disentangle ML-bias into algorithmic and data bias.</li>
</ul>

<h3 id="proposed-framework">Proposed framework</h3>

<!-- Let $$F_b, F_u$$ be the set of biased and unbiased algorithms, and $$D_b, D_u$$ be the set of biased and unbiased datasets, respectively. $$\|F_b\| + \|F_u\| = n$$ and $$\|D_b\| + \|D_u\| = N$$. -->
<p>We need to make some assumptions as follows:</p>

<ul>
  <li>an biased algorithm might perform poorly on an unbiased dataset.</li>
  <li>an unbiased algorithm might perform poorly on a biased dataset.</li>
  <li>an biased algorithm might not necessary perform well on an biased dataset because it might be trained on different biased training set.</li>
  <li>in this project, a poor generalization algorithm which performs poorly on both biased and unbiased datasets might be different from a biased algorithm which might perform well on biased datasets but poorly on unbiased datasets.</li>
</ul>

<p>We consider two IRT models simultaneously, the standard IRT model and the IRT model with inverted mapping. The standard IRT model is used to estimate the characteristics of datasets (i.e., difficulty, discrimination) while the IRT model with inverted mapping is used to estimate the characteristics of algorithms (i.e., difficulty limit, anomalousness, consistency).</p>

<p>For the IRT model with inverted mapping, we consider the performance-dataset difficulty curve \(h^d_{a_j}(\delta_d)\) of each algorithm \(a_j\), while for the standard IRT model, we consider the performance-algorithm difficulty curve \(h^a_{d_i}(\delta_a)\) of each dataset \(d_i\). With the two curves, we can identify a biased dataset as follows:</p>

<ul>
  <li>A dataset \(d_i\) is considered to be biased if it is solved well by a biased algorithm \(a_j \in F_b\) but poorly by an unbiased algorithm \(a_j \in F_u\).</li>
</ul>

<p>\(h^d_{a_j} (\delta_d) \leq \epsilon_{low} \; \forall \; a_j \in F_u\)
\(h^d_{a_j} (\delta_d) \geq \epsilon_{up} \; \forall \; a_j  \in F_b\)</p>

<ul>
  <li>An algorithm \(a_j\) is considered to be biased if it performs well on a biased dataset \(d_i \in D_b\) but poorly on an unbiased dataset \(d_i \in D_u\).</li>
</ul>

<p>\(h^a_{d_i} (\delta_a) \leq \epsilon_{low} \; \forall \; d_i \in D_u\)
\(h^a_{d_i} (\delta_a) \geq \epsilon_{up} \; \forall \; d_i \in D_b\)</p>

<p>where \(\epsilon_{low}\) and \(\epsilon_{up}\) are the lower and upper thresholds, respectively.</p>

<p>We can also a 3D map where the z-axis is the performance of an algorithm on a dataset, the x-axis is the difficulty of the dataset, and the y-axis is the difficulty limit of the algorithm.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2309/fairness-irt/couple-IRT-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2309/fairness-irt/couple-IRT-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2309/fairness-irt/couple-IRT-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2309/fairness-irt/couple-IRT.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    3D map
</div>

<!-- Central question is how to select an unbiased and sufficiently diverse set of datasets to evaluate an algorithm portfolio. -->

<h2 id="references">References</h2>

<p>Fernando Martínez-Plumed, Ricardo BC Prudêncio, Adolfo Martínez-Usó, and José HernándezOrallo. Item Response Theory in AI: Analysing machine learning classifiers at the instance level. Artificial Intelligence, 271:18–42, 2019.</p>

<p>Yu Chen, Ricardo BC Prudêncio, Tom Diethe, Peter Flach, et al. β3-IRT: A New Item Response Model and its Applications. arXiv preprint, arXiv:1903.04016, 2019.</p>

    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/anti-personalization-v2/">Anti-Personalization - A review after 2 years</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/safe-completion-training/">GPT-5 Series - Safe Completion Training</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/personalized-llms/">Personalized LLMs</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/educating-kids-age-of-ai/">Educating Kids in the Age of AI</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
