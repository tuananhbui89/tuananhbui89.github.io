<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Papers Reading | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="Generative Models and Trustworthy Machine Learning">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2023/papers-pool/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->
<!-- Page/Post style -->
<style type="text/css">
  
</style>


<div class="post">

  <header class="post-header">
    <h1 class="post-title">Papers Reading</h1>
    <p class="post-meta">August 5, 2023</p>
    <p class="post-tags">
      <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>
        ·  
        <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          <a href="/blog/tag/tml">
          <i class="fas fa-hashtag fa-sm"></i> tml</a>  
          <a href="/blog/tag/diffusion">
          <i class="fas fa-hashtag fa-sm"></i> diffusion</a>  
          <a href="/blog/tag/genai">
          <i class="fas fa-hashtag fa-sm"></i> genai</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#universal-and-transferable-adversarial-attacks-on-aligned-language-models">Universal and Transferable Adversarial Attacks on Aligned Language Models</a></li>
<li class="toc-entry toc-h2"><a href="#cold-diffusion-inverting-arbitrary-image-transforms-without-noise">Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise</a></li>
<li class="toc-entry toc-h2"><a href="#your-diffusion-model-is-secretly-a-zero-shot-classifier">Your Diffusion Model is Secretly a Zero-Shot Classifier</a></li>
<li class="toc-entry toc-h2"><a href="#rethinking-conditional-diffusion-sampling-with-progressive-guidance">Rethinking Conditional Diffusion Sampling with Progressive Guidance</a></li>
<li class="toc-entry toc-h2"><a href="#a-new-perspective-on-the-motivation-of-vae-by-dinh">A new perspective on the motivation of VAE (by Dinh)</a></li>
<li class="toc-entry toc-h2"><a href="#flow-matching-for-generative-modeling-iclr-2023">FLOW MATCHING FOR GENERATIVE MODELING (ICLR 2023)</a></li>
<li class="toc-entry toc-h2"><a href="#diffusion-models-beat-gans-on-image-synthesis">Diffusion Models Beat GANs on Image Synthesis</a></li>
<li class="toc-entry toc-h2"><a href="#trading-information-between-latents-in-hierarchical-variational-autoencoders">TRADING INFORMATION BETWEEN LATENTS IN HIERARCHICAL VARIATIONAL AUTOENCODERS</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <h2 id="universal-and-transferable-adversarial-attacks-on-aligned-language-models"><a href="https://arxiv.org/pdf/2307.15043.pdf" rel="external nofollow noopener" target="_blank">Universal and Transferable Adversarial Attacks on Aligned Language Models</a></h2>

<ul>
  <li>Link to the blog post: <a href="https://tuananhbui89.github.io/blog/2024/paper-llm-attacks/">https://tuananhbui89.github.io/blog/2024/paper-llm-attacks/</a>
</li>
</ul>

<h2 id="cold-diffusion-inverting-arbitrary-image-transforms-without-noise"><a href="https://arxiv.org/abs/2208.09392" rel="external nofollow noopener" target="_blank">Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise</a></h2>

<ul>
  <li>Link to the blog post: <a href="https://tuananhbui89.github.io/blog/2024/paper-cold-diffusion/">https://tuananhbui89.github.io/blog/2024/paper-cold-diffusion/</a>
</li>
</ul>

<h2 id="your-diffusion-model-is-secretly-a-zero-shot-classifier"><a href="https://arxiv.org/abs/2303.16203" rel="external nofollow noopener" target="_blank">Your Diffusion Model is Secretly a Zero-Shot Classifier</a></h2>

<ul>
  <li>Accepted to ICCV 2023.</li>
  <li>Affiliation: CMU.</li>
  <li>Github: <a href="https://github.com/diffusion-classifier/diffusion-classifier" rel="external nofollow noopener" target="_blank">https://github.com/diffusion-classifier/diffusion-classifier</a>
</li>
</ul>

<p>Motivations:</p>

<ul>
  <li>Diffusion models such as Stable Diffusion are trained with self-supervised learning, i.e., \((x,y)\), with \(y\) is the label of \(x\), such as an image’s caption.</li>
  <li>Question: Can we use a pre-trained DM to estimate \(p(y \mid x)\)?</li>
</ul>

<p>Proposed Method:</p>

<p>In general, classification using a conditional generative model can be done by using Bayes’ theorem:</p>

\[p_\theta (c_i \mid c) = \frac{p(c_i) p_\theta(x \mid c_i)}{\sum_j p(c_j) p_\theta (x \mid c_j)}\]

<p>where \(c_i\) is the class label of \(x\), prior \(p(c)\) over labels \(\{ c_i \}\).</p>

<p>However, obtain posterior distribution \(p_\theta (c_i \mid x)\) over set of labels \(\{ c_i \}\) is intractable.</p>

\[p_\theta (c_i \mid x) = \frac{\exp{ \{ - \mathbb{E}_{t,\epsilon} \| \epsilon - \epsilon_\theta (x_t, c_i) \| } \} }{\sum_j \exp{ \{  - \mathbb{E}_{t,\epsilon}  \| \epsilon - \epsilon_\theta (x_t, c_j) \| } \} }\]

<p><strong>Why is it intractable?</strong> Because the expectation \(\mathbb{E}_{t,\epsilon}\) is over the diffusion process, which is intractable / expensive to compute.</p>

<p>Therefore, the authors propose to use the following approximation:</p>

\[p_\theta (c_i \mid x) \approx \frac{1}{\sum_j \exp \{ \mathbb{E}_{t,\epsilon} \left[ \| \epsilon - \epsilon_\theta (x_t, c_i) \|^2 - \| \epsilon - \epsilon_\theta (x_t, c_j) \|^2  \right] \}}\]

<p><strong>Why is it cheaper?</strong> Because using the above approximation, we only need to compute the difference between each pair of \(c_i\) and \(c_j\). To support this approximation, the authors measured the error score \(\| \epsilon - \epsilon_\theta(x_t, c_i) \|\) for four different \(\epsilon\) and varying \(t\) and found that the error pattern is dependent on \(\epsilon\), and the difference between the error scores of two classes seems to be independent of \(\epsilon\) (ref. Figure 2)</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/240111/dm_as_zeroshot_fig2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/240111/dm_as_zeroshot_fig2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/240111/dm_as_zeroshot_fig2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/240111/dm_as_zeroshot_fig2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<p><strong>Comparing the computational cost</strong>: Given one query image \(x\) and total \(C\) classes:</p>

<ul>
  <li>The cost of the exact posterior \(p_\theta (c_i \mid x)\) is: \(C\) times of the cost to compute \(\mathbb{E}_{t,\epsilon} \| \epsilon - \epsilon_\theta (x_t, c_i) \|\). To compute \(\mathbb{E}_{t,\epsilon} \| \epsilon - \epsilon_\theta (x_t, c_i) \|\), we need to sample \(N\) pairs of \((t, \epsilon)\). Therefore, the cost is \(O(C N)\).</li>
  <li>The cost of the approximate posterior: also \(C\) times of the cost to compute \(\mathbb{E}_{t,\epsilon} [ \| \epsilon - \epsilon_\theta (x_t, c_i) \|^2 - \| \epsilon - \epsilon_\theta (x_t, c_j) \|^2 ]\).</li>
</ul>

<p>Given the above analysis, I can see that the advantage of the approximation is not computational cost but the ability to compute the posterior distribution more accurately.</p>

<p>Some promising directions:</p>

<ul>
  <li>Using more straight diffusion models such as <a href="https://arxiv.org/abs/2209.03003" rel="external nofollow noopener" target="_blank">Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow</a> or <a href="https://arxiv.org/pdf/2303.01469.pdf?curius=2525" rel="external nofollow noopener" target="_blank">Consistency models</a> to accelerate the computation of the posterior.</li>
</ul>

<h2 id="rethinking-conditional-diffusion-sampling-with-progressive-guidance"><a href="https://openreview.net/pdf?id=gThGBHhqcU" rel="external nofollow noopener" target="_blank">Rethinking Conditional Diffusion Sampling with Progressive Guidance</a></h2>

<p>Increase the diversity of classifier guidance paper by introduing a new technique called <strong>Progressive Guidance</strong>. In the DDPM model</p>

\[x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1-\alpha_t}{\sqrt{1 - \bar{\alpha}_t} \epsilon_\theta (x_t, t)} \right) + \sigma_t z\]

<p>where \(z\) is a random noise. In the classifier guidance</p>

\[x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1-\alpha_t}{\sqrt{1 - \bar{\alpha}_t} \epsilon_\theta (x_t, t)} \right) + \sigma_t z + s \sigma_t^2 \nabla_{x_t} \log p_\phi (y_c \mid x_t)\]

<p>Their proposed method:</p>

\[x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1-\alpha_t}{\sqrt{1 - \bar{\alpha}_t} \epsilon_\theta (x_t, t)} \right) + \sigma_t z + w * \sum_{i=1}^c s_i \sigma_t^2 \nabla_{x_t} \log p_\phi (y_i \mid x_t)\]

<p>with \(s_i \geq 0\) is the degree of information injected into the sampling process by class \(y_i\).</p>

<p>Their intuition:</p>

<ul>
  <li>By incorporating gradients from other classes during sampling, the conflict between the sampling and discriminative objectives can be decreased, resulting in diverse generated samples</li>
  <li>Using other classes’ gradients beyond the conditional class gradient helps avoid adversarial effects</li>
</ul>

<p>What is <strong>adversarial effects</strong>? In the formulation of classifier guidance, the guidance signal is quite similar as in adversarial perturbation so that the perturbation is making nonsense to human eyes, however, it is still classified as the target class.</p>

<p>One important point of this paper is how to choose vector \(s\). They propose to model the correlation between labels via the description text of labels as follows:</p>

<ul>
  <li>utilize ChatGPT to generate text descriptions for each class, e.g., class “dog” is described as “a domesticated carnivorous mammal that typically has a long snout, an acute sense of smell, nonretractable claws, and a barking, howling, or whining voice.”</li>
  <li>After removing stop words and other preprocessing text, we use a CLIP model to obtain each class’s embedding information \(v_i\).</li>
  <li>The embedding information is then utilized to calculate the similarity based on cosine similarity \(sim_{i,j} = \frac{v_i v_j}{\mid v_i \mid \mid v_j \mid}\).</li>
  <li>Given the conditional label c, we have the information degree for each label \(s_i = \frac{sim_{c,i}}{\sum_{j=1}^C sim_{c,j}} \; \forall 1 \leq i \leq C\).</li>
</ul>

<p>Given starting vector \(s\), they also propose a strategy to update \(s\) during sampling process to make the vector \(s\) becomes more one-hot vector (with the highest value is the target class). The speed of updating is controlled by a hyperparameter \(\gamma\). It can be seen from Table 5 in the paper, if \(\gamma=0\) means that there is no update, the performance is very poor. However, if \(\gamma\) large means that the vector \(s\) is become more one-hot vector fast and keep it that way through the sampling process, the performance is also not good.</p>

<p>In Table 6, they also show the importance of starting vector \(s\), if \(s\) is from label smoothing or uniform distribution, the performance is not good as using the CLIP embedding.</p>

<h2 id="a-new-perspective-on-the-motivation-of-vae-by-dinh">A new perspective on the motivation of VAE (by Dinh)</h2>

<ul>
  <li>Assume that \(x\) was generated from \(z\) through a generative process \(p(x \mid z)\).</li>
  <li>Before observing \(x\), we have a prior belief about \(z\), i.e., \(z\) can be sampled from a Gaussian distribution \(p(z) = \mathcal{N}(0, I)\).</li>
  <li>After observing \(x\), we want to correct our prior belief about \(z\) to a posterior belief \(p(z \mid x)\).</li>
  <li>However, we cannot directly compute \(p(z \mid x)\) because it is intractable. Therefore, we use a variational distribution \(q(z \mid x)\) to approximate \(p(z \mid x)\). The variational distribution \(q(z \mid x)\) is parameterized by an encoder \(e(z \mid x)\). The encoder \(e(z \mid x)\) is trained to minimize the KL divergence between \(q(z \mid x)\) and \(p(z \mid x)\). This is the motivation of VAE.</li>
</ul>

<p>Mathematically, we want to minimize the KL divergence between \(q_{\theta} (z \mid x)\) and \(p(z \mid x)\):</p>

\[\mathcal{D}_{KL} (q_{\theta} (z \mid x) \parallel p(z \mid x) ) = \mathbb{E}_{q_{\theta} (z \mid x)} \left[ \log \frac{q_{\theta} (z \mid x)}{p(z \mid x)} \right] = \mathbb{E}_{q_{\theta} (z \mid x)} \left[ \log q_{\theta} (z \mid x) - \log p(z \mid x) \right]\]

<p>Applying Bayes rule, we have:</p>

\[\mathcal{D}_{KL} (q_{\theta} (z \mid x) \parallel p(z \mid x) ) = \mathbb{E}_{q_{\theta} (z \mid x)} \left[ \log q_{\theta} (z \mid x) - \log p(x \mid z) - \log p(z) + \log p(x) \right]\]

\[\mathcal{D}_{KL} (q_{\theta} (z \mid x) \parallel p(z \mid x) ) = \mathbb{E}_{q_{\theta} (z \mid x)} \left[ \log q_{\theta} (z \mid x) - \log p(x \mid z) - \log p(z) \right] + \log p(x)\]

\[\mathcal{D}_{KL} (q_{\theta} (z \mid x) \parallel p(z \mid x) ) = - \mathbb{E}_{q_{\theta} (z \mid x)} \left[ \log p(x \mid z) \right] + \mathcal{D}_{KL} \left[ q_{\theta} (z \mid x) \parallel p(z) \right] + \log p(x)\]

<p>So, minimizing \(\mathcal{D}_{KL} (q_{\theta} (z \mid x) \parallel p(z \mid x) )\) is equivalent to maximizing the ELBO: \(\mathbb{E}_{q_{\theta} (z \mid x)} \left[ \log p(x \mid z) \right] - \mathcal{D}_{KL} \left[ q_{\theta} (z \mid x) \parallel p(z) \right]\).</p>

<p>Another perspective on the motivation of VAE can be seen from the development of the Auto Encoder (AE) model.</p>

<ul>
  <li>The AE model is trained to minimize the reconstruction error between the input \(x\) and the output \(\hat{x}\).</li>
  <li>The AE process is deterministic, i.e., given \(x\), the output \(\hat{x}\) is always the same.</li>
  <li>Therefore, the AE model does not have contiguity and completeness properties as desired in a generative model.</li>
  <li>To solve this problem, we change the deterministic encoder of the AE model to a stochastic encoder, i.e., instead of mapping \(x\) to a single point \(z\), the encoder maps \(x\) to a distribution \(q_{\theta} (z \mid x)\). This distribution should be close to the prior distribution \(p(z)\). This is the motivation of VAE.</li>
</ul>

<h2 id="flow-matching-for-generative-modeling-iclr-2023">FLOW MATCHING FOR GENERATIVE MODELING (ICLR 2023)</h2>

<ul>
  <li>Link to the paper: <a href="https://openreview.net/pdf?id=PqvMRDCJT9t" rel="external nofollow noopener" target="_blank">https://openreview.net/pdf?id=PqvMRDCJT9t</a>
</li>
  <li>Link to my blog post: <a href="https://tuananhbui89.github.io/blog/2023/flowmatching/">https://tuananhbui89.github.io/blog/2023/flowmatching/</a>
</li>
</ul>

<h2 id="diffusion-models-beat-gans-on-image-synthesis">Diffusion Models Beat GANs on Image Synthesis</h2>

<p>Link to <a href="https://tuananhbui89.github.io/blog/2023/conditional-diffusion/">blog post</a></p>

<h2 id="trading-information-between-latents-in-hierarchical-variational-autoencoders"><a href="https://openreview.net/forum?id=eWtMdr6yCmL" rel="external nofollow noopener" target="_blank">TRADING INFORMATION BETWEEN LATENTS IN HIERARCHICAL VARIATIONAL AUTOENCODERS</a></h2>

<ul>
  <li>published on ICLR 2023.</li>
</ul>

<p>Revisit Rate-Distortion trade-off theory:</p>

<ul>
  <li>Problem setting of Rate-Distortion trade-off
    <ul>
      <li>How to learn a “useful” representation of data for downstream tasks?</li>
      <li>Using powerful encoder-decoder such as VAE, PixelCNN, etc. can easily ignore \(z\) and still obtain high marginal likelihood \(p(x \mid \theta)\). Therefore, we need to use a regularization term to encourage the encoder to learn a “useful” representation of \(z\), for example, as in Beta-VAE.</li>
    </ul>
  </li>
</ul>

<p>Rate distortion theory?</p>

\[H - D \leq I(z,x) \leq R\]

<p>where \(H\) is the entropy of data \(x\) and \(D\) is the distortion of the reconstruction \(x\) from \(z\). \(R\) is the rate of the latent code \(z\) (e.g., compression rate).</p>

<p>\(R = \log \frac{e(z \mid x)}{m(z)}\) where \(e(z \mid x)\) is the encoder and \(m(z)\) is the prior distribution of \(z\). The higher the rate, the more information of \(x\) is preserved in \(z\). However, if the rate is high, it lessen the generalization ability of the \(\log p(x \mid z, \theta)\).</p>

<p>The mutual information has upper bound by the rate of the latent code \(z\). For example, if \(R=0\) then \(I(z,x)=0\). This is because \(e(z \mid x) = m(z)\), which means that the encoder cannot learn anything from the data \(x\).</p>

<p>Motivation of the paper:</p>

<ul>
  <li>Reconsider the rate distortion theory in the context of hierarchical VAEs where there are multiple levels of latent codes \(z_1, z_2, \dots, z_L\).</li>
  <li>The authors proposed a direct links between the input \(x\) and the latent codes \(z_1, z_2, \dots, z_L\). With this architecture, they can decompose the total rate to the rate of each latent code \(z_1, z_2, \dots, z_L\). Unlike the standard hierarchical VAEs, where the rate of each latent code is not directly related to the input \(x\) but the previous latent code \(z_{l-1}\).</li>
  <li>Then they can control the rate of each latent code.</li>
</ul>

<p>Standard hierarchical VAEs:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/230901/standard-hvae-objective-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/230901/standard-hvae-objective-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/230901/standard-hvae-objective-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/230901/standard-hvae-objective.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Standard hierarchical VAEs
</div>

<p>Generalized Hierarchical VAEs:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/230901/all-three-hvae-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/230901/all-three-hvae-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/230901/all-three-hvae-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/230901/all-three-hvae.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Generalized Hierarchical VAEs
</div>

    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/erasing-concepts/">Fake Taylor Swift and the Adversarial Game of Concept Erasure and Injection</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/watermark-diffusion/">Tree-Ring Watermarks - Fingerprints for Diffusion Images that are Invisible and Robust</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/fairness-irt/">Comprehensive Algorithm Portfolio Evaluation using Item Response Theory</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/diffusion-tutorial/">A Tutorial on Diffusion Models (Part 1)</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/conditional-diffusion/">Diffusion Models Beat GANs on Image Synthesis</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
