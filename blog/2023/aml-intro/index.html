<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Tutorial on Adversarial Machine Learning - Part 1 | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="The Good, The Bad, The Ugly, The Efforts, and The Difficulties">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2023/aml-intro/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "Tutorial on Adversarial Machine Learning - Part 1",
      "description": "The Good, The Bad, The Ugly, The Efforts, and The Difficulties",
      "published": "June 2, 2023",
      "authors": [
        {
          "author": "Tuan-Anh Bui",
          "authorURL": "https://tuananhbui89.github.io/",
          "affiliations": [
            {
              "name": "Monash University",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>Tutorial on Adversarial Machine Learning - Part 1</h1>
        <p>The Good, The Bad, The Ugly, The Efforts, and The Difficulties</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#the-good">The Good</a></div>
            <div><a href="#the-bad">The Bad</a></div>
            <div><a href="#the-ugly">The Ugly</a></div>
            <div><a href="#the-efforts">The Efforts</a></div>
            <div><a href="#the-difficulties">The Difficulties</a></div>
            
          </nav>
        </d-contents>

        <h2 id="the-good---the-age-of-deep-neural-networks">The Good - The Age of Deep Neural Networks</h2>

<p>Deep Neural Networks (DNNs) have revolutionized various domains, showcasing remarkable achievements in computer vision <d-cite key="he2016deep"></d-cite>, natural language processing <d-cite key="vaswani2017attention"></d-cite>, and speech processing <d-cite key="amodei2016deep"></d-cite>. These powerful models have surpassed human-level accuracy in tasks like image classification and language processing, propelling them into real-world applications. 
Nowadays, DNNs are ubiquitous, powering the technology we use every day, from voice assistants like Siri to self-driving Tesla cars.
Their impact is undeniable, transforming the way we interact with technology and reshaping industries across the globe.</p>

<h2 id="the-bad---current-dnns-are-not-reliable-and-secure">The Bad - Current DNNs are not reliable and secure</h2>

<p>While DNNs have achieved unprecedented success and widespread adoption, their reliability and security remain a concern. 
DNNs are known as black-box models, meaning that their internal workings are not transparent to users, and even their creators.
This lack of transparency makes it difficult to understand their behavior and trust their decisions.</p>

<p>For some low-stakes applications, such as fraud transactions detection or movie recommendation, it is not a big deal if the model makes a mistake. The consequences of incorrect predictions are not severe. However, for some high-stakes applications, such as autonomous driving, clinical diagnostics, auto-trading bots where the model’s decisions can lead to life-threatening conditions or economic collapse, it is crucial to understand the model’s behavior and trust its decisions. Just think about a situation, when you have a serious disease and a machine learning model predicts that you should take a specific medicine, would you trust the model’s decision to take the medicine?</p>

<table>
  <thead>
    <tr>
      <th>AI’s application</th>
      <th>AI’s risk</th>
      <th>Consequence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Commercial Ads recommendation</td>
      <td>Matching “users-interest” incorrectly</td>
      <td>Seeing non-interested Ads</td>
    </tr>
    <tr>
      <td>Auto-trading bot</td>
      <td>Triggering wrong signal</td>
      <td>Financial loss</td>
    </tr>
    <tr>
      <td>Autopilot in Tesla</td>
      <td>Mist-Classifying “Stop-Sign”</td>
      <td>Fatal crash</td>
    </tr>
    <tr>
      <td>Autonomous drone swarms</td>
      <td>Wrong targeting/attacking</td>
      <td>Fatal mistake - many deaths</td>
    </tr>
  </tbody>
</table>

<p><strong>Some examples of catastrophic failures of unreliable DNNs in real-life:</strong></p>

<ul>
  <li><a href="https://www.theguardian.com/technology/2022/dec/22/tesla-crash-full-self-driving-mode-san-francisco" rel="external nofollow noopener" target="_blank">Tesla behind eight-vehicle crash was in ‘full self-driving’ mode</a></li>
  <li><a href="https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/" rel="external nofollow noopener" target="_blank">IBM’s Watson supercomputer recommended ‘unsafe and incorrect’ cancer treatments</a></li>
  <li><a href="https://www.smh.com.au/business/markets/how-a-fake-ai-photo-of-a-pentagon-blast-wiped-billions-off-wall-street-20230524-p5daqo.html" rel="external nofollow noopener" target="_blank">A fake AI photo of a Pentagon blast wiped billions off Wall Street</a></li>
</ul>

<p><strong>Conclusion: The more autonomous the AI system is, the more important it is to understand the model’s behavior and trust its decisions.</strong></p>

<h2 id="the-ugly---adversarial-examples-on-dnns">The Ugly - Adversarial examples on DNNs</h2>

<p>In addition to their lack of transparency, DNNs are also vulnerable to adversarial attacks including backdoor attacks, poisoning attacks, and adversarial examples. 
A notable work from Szegedy et al. (2014) <d-cite key="szegedy2013intriguing"></d-cite> was the first work demonstrated that DNNs are susceptible to adversarial examples, subtle modifications to input data that can manipulate their behavior. 
And the worst part is that generating adversarial examples is easy and fast <d-cite key="madry2017towards"></d-cite>.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://raw.githubusercontent.com/tuananhbui89/website_images/master/posts/aml_intro/adversarial_1_10-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://raw.githubusercontent.com/tuananhbui89/website_images/master/posts/aml_intro/adversarial_1_10-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://raw.githubusercontent.com/tuananhbui89/website_images/master/posts/aml_intro/adversarial_1_10-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="https://raw.githubusercontent.com/tuananhbui89/website_images/master/posts/aml_intro/adversarial_1_10.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Adversarial examples <a href="https://github.com/tuananhbui89/demo_attack" rel="external nofollow noopener" target="_blank">(link to the demo)</a>.
</div>

<p>The above example illustrates an adversarial example generated from a pre-trained ResNet50 model. The image on the left is the original image of a koala, which is correctly classified as a koala with nearly 50% confidence. The image in the middle is the adversarial perturbation, which is imperceptible to the human eye. The image on the right is the adversarial example generated from the original image on the left. The adversarial example is misclassified as a ballon with nearly 100% confidence.</p>

<h2 id="efforts-to-tackle-adversarial-examples">Efforts to Tackle Adversarial Examples</h2>

<p>Since the discovery of adversarial examples [4], it has been an extensive with the number of papers on this topic increasing exponentially, as shown in the figure below.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://raw.githubusercontent.com/tuananhbui89/website_images/master/posts/aml_intro/papers_per_year_side_by_side-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://raw.githubusercontent.com/tuananhbui89/website_images/master/posts/aml_intro/papers_per_year_side_by_side-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://raw.githubusercontent.com/tuananhbui89/website_images/master/posts/aml_intro/papers_per_year_side_by_side-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="https://raw.githubusercontent.com/tuananhbui89/website_images/master/posts/aml_intro/papers_per_year_side_by_side.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Number of adversarial examples papers published on arXiv from 2014 to May 2023. Data source from Carlini's post <a href="https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html" rel="external nofollow noopener" target="_blank">(link)</a>.
</div>

<p>On the one hand, various attack methods have been proposed to enhance effectiveness <d-cite key="madry2017towards"></d-cite> , computational efficiency <d-cite key="zhang2022revisiting"></d-cite> , transferability among inputs <d-cite key="moosavi2017universal"></d-cite>  or among models <d-cite key="papernot2016transferability"></d-cite> .</p>

<p>On the other hand, there is also an extremely large number of defense methods proposed to mitigate adversarial attacks, from all aspects of the machine learning pipeline.</p>

<ul>
  <li>Architecture-based defenses: Ensemble models <d-cite key="tramer2017ensemble"></d-cite> , distillation <d-cite key="papernot2016distillation"></d-cite> , quantization <d-cite key="gui2019model"></d-cite> , model pruning <d-cite key="dhillon2018stochastic"></d-cite> , smooth activation functions <d-cite key="xie2020smooth"></d-cite> , etc.</li>
  <li>Preprocessing-based defenses: transformations to remove adversarial perturbations such as JPEG compression <d-cite key="dziugaite2016study"></d-cite> , etc.</li>
  <li>Postprocessing-based defenses: detecting adversarial examples <d-cite key="metzen2017detecting"></d-cite> , etc.</li>
  <li>Training-based defenses: adversarial training <d-cite key="madry2017towards"></d-cite>, regularization <d-cite key="bui2020improving"></d-cite> , etc.</li>
</ul>

<p>Despite numerous defense strategies being proposed to counter adversarial attacks, no method has yet provided comprehensive protection or completely illuminated the vulnerabilities of DNNs.</p>

<h2 id="the-difficulties-of-evaluating-adversarial-robustness">The Difficulties of Evaluating Adversarial Robustness</h2>

<p>Checking out the toughness of adversarial examples is a lot trickier than your usual machine learning model checks. This is mainly because adversarial examples don’t just pop up naturally, you have to create them using adversaries. And let’s just say, making these examples to honestly reflect the threat model takes a lot of genuine efforts.</p>

<p>Now, there’s this thing called gradient masking that folks often use to stop gradient information from being used to make adversarial examples. Attacks like PGD, for instance, need to work out the gradients of the model’s loss function to create adversarial examples. But sometimes, due to the way the model is built or trained, you might not be able to get the precise gradients you need, and this can throw a wrench in the works of adversarial attacks.</p>

<p>Also, adversarial attacks can be quite picky when it comes to specific settings. Like, a PGD attack might work great when you use a certain step size, number of iterations, and scale of logits, but not so well in other settings. Transferred attacks, on the other hand, care a lot about the model you choose as a substitute. So, you’ve got to make sure you’re checking the toughness of adversarial examples in lots of different settings.</p>

<p>Carlini et al. (2019) <d-cite key="carlini2019evaluating"></d-cite>  came up with a really handy checklist in 2019. It points out common slip-ups people make when they’re checking out adversarial robustness and offers some tips to dodge these pitfalls.</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/2023-06-02-distill.bib"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;">
  <script>
    let giscusTheme = localStorage.getItem("theme");
    let giscusAttributes = {
        "src": "https://giscus.app/client.js",
        "data-repo": "alshedivat/al-folio",
        "data-repo-id": "MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==",
        "data-category": "Comments",
        "data-category-id": "DIC_kwDOA5PmLc4CTBt6",
        "data-mapping": "title",
        "data-strict": "1",
        "data-reactions-enabled": "1",
        "data-emit-metadata": "0",
        "data-input-position": "bottom",
        "data-theme": giscusTheme,
        "data-lang": "en",
        "crossorigin": "anonymous",
        "async": "",
    };


    let giscusScript = document.createElement("script");
    Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
    document.getElementById("giscus_thread").appendChild(giscusScript);
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a>
</noscript>
</div>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
