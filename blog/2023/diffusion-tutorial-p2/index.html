<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>A Tutorial on Diffusion Models (Part 2) | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="DDIM, Diffusion Inversion and Accelerating Inference">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="http://localhost:4000/blog/2023/diffusion-tutorial-p2/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "A Tutorial on Diffusion Models (Part 2)",
      "description": "DDIM, Diffusion Inversion and Accelerating Inference",
      "published": "October 3, 2023",
      "authors": [
        {
          "author": "Tuan-Anh Bui",
          "authorURL": "https://tuananhbui89.github.io/",
          "affiliations": [
            {
              "name": "Monash University",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>A Tutorial on Diffusion Models (Part 2)</h1>
        <p>DDIM, Diffusion Inversion and Accelerating Inference</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#ddim">DDIM</a></div>
            <div><a href="#diffusion-inversion">Diffusion Inversion</a></div>
            <div><a href="#implementation">Implementation</a></div>
            <ul>
              <li><a href="#jumping-prediction">Jumping Prediction</a></li>
              <li><a href="#notebooks">Notebooks</a></li>
              
            </ul>
          </nav>
        </d-contents>

        <!-- I have been asked by Dinh to develop a short tutorial/lecture on diffusion models for the course "Deep Learning" at Monash University (FIT3181). And, here it is. -->

<h2 id="resources">Resources</h2>

<ul>
  <li>The Jupyter notebooks associated with this tutorial can be found <a href="https://github.com/tuananhbui89/diffusion_demo" rel="external nofollow noopener" target="_blank">here</a>.</li>
  <li>The first part of this tutorial can be found <a href="https://tuananhbui89.github.io/blog/2023/diffusion-tutorial/" rel="external nofollow noopener" target="_blank">here</a>.</li>
  <li>FastAI tutorial about DDIM can be found <a href="https://course.fast.ai/Lessons/lesson21.html" rel="external nofollow noopener" target="_blank">here</a>.</li>
</ul>

<h2 id="ddim">DDIM</h2>

<p>One of the main drawbacks of DDPM is that training process requires a large \(T\) to reach the equilibrium state. In inference, to obtain a sample \(x_0\), we need to run through \(T\) reverse steps, sequentially, which is very slow. To address this issue, Song et al. <d-cite key="song2020denoising"></d-cite> proposed a new diffusion model called DDIM (Denoising Diffusion Implicit Model) which allows us to accelerate the inference process while using the same training process as DDPM (it means that you can use the pre-trained DDPM model to inference with DDIM method).</p>

<h3 id="change-of-notation">Change of Notation</h3>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/diffusion/notation-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/diffusion/notation-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/diffusion/notation-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/diffusion/notation.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Meme stealing from <a href="https://www.tanishq.ai/" rel="external nofollow noopener" target="_blank">Tanishq</a> at <a href="https://course.fast.ai/Lessons/lesson21.html" rel="external nofollow noopener" target="_blank">https://course.fast.ai/Lessons/lesson21.html</a>
</div>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>DDPM</th>
      <th>DDIM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
<strong>atomic</strong> param <img class="emoji" title=":joy:" alt=":joy:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png" height="20" width="20">
</td>
      <td>\(0 &lt; \alpha_t &lt; 1, \beta_t = 1 - \alpha_t\)</td>
      <td>\(0 &lt; \bar{\alpha}_t &lt; 1, \beta_t = 1 - \bar{\alpha}_t\)</td>
    </tr>
    <tr>
      <td>
<strong>cummulative</strong> param</td>
      <td>\(\bar{\alpha}_t = \prod_{i=1}^{t} \alpha_i\)</td>
      <td>\(\alpha_t = \prod_{i=1}^{t} \bar{\alpha}_i\)</td>
    </tr>
    <tr>
      <td>\(q(x_t \mid x_{t-1})\)</td>
      <td>\(\mathcal{N} (x_t; \sqrt{\alpha_t} x_t, (1 - \alpha_t) I)\)</td>
      <td>\(\mathcal{N} (x_t; \sqrt{\frac{\alpha_t}{\alpha_{t-1}}}x_{t-1}, (1 - \frac{\alpha_t}{\alpha_{t-1}})I)\)  \(^{\star}\)</td>
    </tr>
    <tr>
      <td>\(q(x_t \mid x_0)\)</td>
      <td>\(\mathcal{N} (x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)\)</td>
      <td>\(\mathcal{N} (x_t; \sqrt{\alpha_t} x_0, (1 - \alpha_t) I)\)</td>
    </tr>
    <tr>
      <td>(forward) sampling \(x_t\)</td>
      <td>\(x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon\)</td>
      <td>\(x_t = \sqrt{\alpha_t} x_0 + \sqrt{1-\alpha_t} \epsilon\)</td>
    </tr>
    <tr>
      <td>(reverse) sampling \(x_{t-1}\)</td>
      <td>\(\frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta (x_t, t) \right) + \sigma_t z\)</td>
      <td>\(\frac{1}{\sqrt{\bar{\alpha}_t}} \left( x_t - \frac{1 - \bar{\alpha}_t}{\sqrt{1 - \alpha_t}} \epsilon_\theta (x_t, t) \right) + \sigma_t z\)</td>
    </tr>
    <tr>
      <td>\(\sigma_t\)</td>
      <td>\(\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t}\)</td>
      <td>\(\frac{1 - \alpha_{t-1}}{1 - \alpha_t}\)</td>
    </tr>
  </tbody>
</table>

<p>\(^{\star}\) In the DDIM paper, the authors made a note that <code class="language-plaintext highlighter-rouge">covariance matrix is ensured to have positive terms on its diagonal</code>. The \(\alpha_{1:T} \in  (0, 1]^T\) is a decreasing sequence, i.e., \(\alpha_{t+1} \leq \alpha_t\), \(\alpha_1 = 1\) and \(\alpha_T \approx 0\) where \(T \rightarrow \infty\).</p>

<p>With this in mind, I believe that the variable naming in the <code class="language-plaintext highlighter-rouge">LDM</code> implementation (which can be found here: <a href="https://github.com/Stability-AI/stablediffusion/blob/main/ldm/models/diffusion/ddpm.py#" rel="external nofollow noopener" target="_blank">https://github.com/Stability-AI/stablediffusion/blob/main/ldm/models/diffusion/ddpm.py</a> cannot confuse you anymore <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">to_torch</span> <span class="o">=</span> <span class="nf">partial</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">betas</span><span class="sh">'</span><span class="p">,</span> <span class="nf">to_torch</span><span class="p">(</span><span class="n">betas</span><span class="p">))</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">alphas_cumprod</span><span class="sh">'</span><span class="p">,</span> <span class="nf">to_torch</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">))</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">alphas_cumprod_prev</span><span class="sh">'</span><span class="p">,</span> <span class="nf">to_torch</span><span class="p">(</span><span class="n">alphas_cumprod_prev</span><span class="p">))</span>

    <span class="c1"># calculations for diffusion q(x_t | x_{t-1}) and others
</span>    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">sqrt_alphas_cumprod</span><span class="sh">'</span><span class="p">,</span> <span class="nf">to_torch</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">)))</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">sqrt_one_minus_alphas_cumprod</span><span class="sh">'</span><span class="p">,</span> <span class="nf">to_torch</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)))</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">log_one_minus_alphas_cumprod</span><span class="sh">'</span><span class="p">,</span> <span class="nf">to_torch</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)))</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">sqrt_recip_alphas_cumprod</span><span class="sh">'</span><span class="p">,</span> <span class="nf">to_torch</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">alphas_cumprod</span><span class="p">)))</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">sqrt_recipm1_alphas_cumprod</span><span class="sh">'</span><span class="p">,</span> <span class="nf">to_torch</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">alphas_cumprod</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
</code></pre></div></div>

<p>Fortunately, in the implementation of <code class="language-plaintext highlighter-rouge">DDIM</code>, the authors keep the same notation of the <code class="language-plaintext highlighter-rouge">DDPM</code> implementation and introduce some new variables just for the <code class="language-plaintext highlighter-rouge">DDIM</code> model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1"># ddim sampling parameters
</span>    <span class="n">ddim_sigmas</span><span class="p">,</span> <span class="n">ddim_alphas</span><span class="p">,</span> <span class="n">ddim_alphas_prev</span> <span class="o">=</span> <span class="nf">make_ddim_sampling_parameters</span><span class="p">(</span><span class="n">alphacums</span><span class="o">=</span><span class="n">alphas_cumprod</span><span class="p">.</span><span class="nf">cpu</span><span class="p">(),</span>
                                                                                <span class="n">ddim_timesteps</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">ddim_timesteps</span><span class="p">,</span>
                                                                                <span class="n">eta</span><span class="o">=</span><span class="n">ddim_eta</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">ddim_sigmas</span><span class="sh">'</span><span class="p">,</span> <span class="n">ddim_sigmas</span><span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">ddim_alphas</span><span class="sh">'</span><span class="p">,</span> <span class="n">ddim_alphas</span><span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">ddim_alphas_prev</span><span class="sh">'</span><span class="p">,</span> <span class="n">ddim_alphas_prev</span><span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">ddim_sqrt_one_minus_alphas</span><span class="sh">'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">ddim_alphas</span><span class="p">))</span>
    <span class="n">sigmas_for_original_sampling_steps</span> <span class="o">=</span> <span class="n">ddim_eta</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span>
        <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">alphas_cumprod_prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">alphas_cumprod</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
                    <span class="mi">1</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">alphas_cumprod</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">alphas_cumprod_prev</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="diffusion-inversion">Diffusion Inversion</h2>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/watermark/gan-inversion-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/watermark/gan-inversion-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/watermark/gan-inversion-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/watermark/gan-inversion.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
     Illustration of GAN inversion (Image source <d-cite key="xia2022gan"></d-cite>).
</div>

<p>Generative inversion is a technique that allows us to invert the generation process. In other words, given a pre-trained generative model \(g_\theta(z)\) and an image \(x\) which can be either real image or generated one, we can find the noise \(z\) such that \(g_\theta(z)\) is close to \(x\). This technique was first proposed for GANs in Zhu et al. (2016) <d-cite key="zhu2016generative"></d-cite>, Creswell et al. (2016) <d-cite key="creswell2018inverting"></d-cite> not long after the introduction of GAN in 2014. It can be seen that, obtaining the inverted latent code brings many useful implications such as capability to edit/manipulate generated images by editing the latent code, or adversarial perturbation removal <d-cite key="samangouei2018defense"></d-cite>.</p>

<p>Because requring the deterministic property: one noise \(z\) always generates the same image \(x\), this technique is not trivial to apply to other generative models such as VAEs or Flow-based models. For Diffusion Models, thanks to the deterministic property in DDIM, we can apply this technique to invert the diffusion process, i.e., given an image \(x_0\), we can find the noise \(x_T\) to reconstruct \(x_0\). And with the blooming of Diffusion Models in the last two years, we can see many cool applications of this technique such as Textual Inversion <d-cite key="gal2022image"></d-cite>, Image Editing <d-cite key="mokady2023null"></d-cite> or Watermarking <d-cite key="wen2023tree"></d-cite>).</p>

<p>In the DDPM framework, the forward diffusion process has a nice property that:</p>

\[x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon_t\]

<p>where \(x_0\) is the initial image, \(\epsilon_t \sim \mathcal{N}(0, I)\) is the noise at time \(t\). This property allows us to <strong>predict</strong> noisy version \(x_t\) of \(x_0\) at any arbitrary time \(t\). On the other hand, given \(\epsilon_t = \epsilon_\theta(x_t, t)\) is the predicted noise at time \(t\) by the denoising network \(\epsilon_\theta\) and \(x_t\), we can <strong>predict</strong> \(\tilde{x}_0\) as follows:</p>

\[\tilde{x}_0 = \frac{x_t - \sqrt{1-\bar{\alpha}_t} \epsilon_\theta(x_t, t)}{\sqrt{\bar{\alpha}_t}}\]

<p>Now we consider the next step in the forward diffusion process:</p>

\[x_{t+1} = \sqrt{\bar{\alpha}_{t+1}} x_0 + \sqrt{1 - \bar{\alpha}_{t+1}} \epsilon_{t+1}\]

<p>where \(\epsilon_{t+1} \sim \mathcal{N}(0, I)\) is the noise at time \(t+1\). If we replace the original \(x_0\) with the predicted \(\tilde{x}_0\) and assume that the diffusion process is large enough so that \(\epsilon_{t+1} \approx \epsilon_\theta(x_t, t)\), we can obtain the inverted diffusion process as follows:</p>

\[x_{t+1} = \sqrt{\bar{\alpha}_{t+1}} \frac{x_t - \sqrt{1-\bar{\alpha}_t} \epsilon_\theta(x_t, t)}{\sqrt{\bar{\alpha}_t}} + \sqrt{1 - \bar{\alpha}_{t+1}} \epsilon_\theta(x_t, t)\]

<p>which now depends only on \(x_t\) and \(\epsilon_\theta(x_t, t)\). Repeating this process from \(t=0\) to \(t=T\), we can obtain the inverted code \(x_T\) that reconstructs \(x_0\) (again it works for DDIM model only).</p>

<h2 id="implementation">Implementation</h2>

<h3 id="jumping-prediction">Jumping Prediction</h3>

<p>In this demo, I will show you one of the applications of diffusion inversion - jumping prediction. The goal is to predict the initial image \(x_0\) from the image \(x_t\) at any arbitrary time \(t\) in the diffusion process. It can be done by using the following equation:</p>

\[\tilde{x}_0 = \frac{x_t - \sqrt{1-\bar{\alpha}_t} \epsilon_\theta(x_t, t)}{\sqrt{\bar{\alpha}_t}}\]

<p>where \(\tilde{x}_0\) is the predicted image at time \(t=0\) given the image \(x_t\) at time \(t\) and the noise \(\epsilon_\theta(x_t, t)\).</p>

<p><strong>Why care about this?</strong></p>

<p><strong>Standard Diffusion Model</strong> In the first part, I use the <a href="https://github.com/openai/guided-diffusion" rel="external nofollow noopener" target="_blank">Guided-Diffusion</a> by OpenAI as the codebase to demonstrate this technique (i.e., predicting \(x_0\) from \(x_t\)). The codebase is for the <a href="http://arxiv.org/abs/2105.05233" rel="external nofollow noopener" target="_blank">Diffusion Models Beat GANS on Image Synthesis</a> paper. I have blogged about this paper and some important components of the codebase <a href="https://tuananhbui89.github.io/blog/2023/conditional-diffusion/" rel="external nofollow noopener" target="_blank">here</a>.</p>

<p>The main function to predict \(x_0\) from \(x_t\) as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">pred_eps_and_x0_from_xstart_uncond</span><span class="p">(</span><span class="n">model_fn</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        the (uncondition/standard) $$\epsilon_</span><span class="se">\t</span><span class="s">heta(x_t,t)$$
        the (uncondition/standard) $$</span><span class="se">\t</span><span class="s">ilde{x}_0 = </span><span class="se">\f</span><span class="s">rac{x_t - \sqrt{1 - </span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t} \epsilon_</span><span class="se">\t</span><span class="s">heta(x_t,t)}{\sqrt{</span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t}}$$
        note 1: the _predict_xstart_from_eps() function does not have parameter, therefore, using auxiliary_diffusion or diffusion does not matter
        </span><span class="sh">"""</span>
        <span class="k">assert</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">B</span><span class="p">,)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">q_sample</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_scale_timesteps</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># only this step has trainable parameter
</span>        <span class="k">assert</span> <span class="n">eps</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
        <span class="n">eps</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">x_0</span> <span class="o">=</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_predict_xstart_from_eps</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eps</span><span class="p">,</span> <span class="n">x_0</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">pred_eps_and_x0_from_xstart_cond</span><span class="p">(</span><span class="n">model_fn</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">,</span> <span class="n">cond_fn</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        the condition $$\hat{\epsilon}_{</span><span class="se">\t</span><span class="s">heta}(x_t,t,y,\phi) = \epsilon_</span><span class="se">\t</span><span class="s">heta(x_t,t) - \sqrt{1 - </span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t} </span><span class="se">\n</span><span class="s">abla_{x_t} \log p_\phi (y \mid x_t)$$ as in classifier-guidance model
        the condition $$</span><span class="se">\t</span><span class="s">ilde{x}_0 = </span><span class="se">\f</span><span class="s">rac{x_t - \sqrt{1 - </span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t} \hat{\epsilon}_{</span><span class="se">\t</span><span class="s">heta}(x_t,t,y,\phi)}{\sqrt{</span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t}}$$
        note 1: the _predict_xstart_from_eps() function does not have parameter, therefore, using auxiliary_diffusion or diffusion does not matter
        note 2: the classifier should be the ORIGINAL classifier, not the auxiliary classifier
        </span><span class="sh">"""</span>
        <span class="k">assert</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">B</span><span class="p">,)</span>
        <span class="n">alpha_bar</span> <span class="o">=</span> <span class="nf">_extract_into_tensor</span><span class="p">(</span><span class="n">diffusion</span><span class="p">.</span><span class="n">alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">q_sample</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_scale_timesteps</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># only this step has trainable parameter
</span>        <span class="k">assert</span> <span class="n">eps</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
        <span class="n">eps</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="nf">cond_fn</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_scale_timesteps</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_bar</span><span class="p">).</span><span class="nf">sqrt</span><span class="p">()</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">x_0</span> <span class="o">=</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_predict_xstart_from_eps</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eps</span><span class="p">,</span> <span class="n">x_0</span>
</code></pre></div></div>

<p><strong>Latent Diffusion Model</strong> 
<!-- In this part, I will use the codebase from the paper [Erasing Concepts from Diffusion Models](https://erasing.baulab.info/) which is based on the [Stable Diffusion Model](https://github.com/CompVis/stable-diffusion) by [CompVis lab](https://github.com/CompVis) as the codebase to demonstrate this technique.  -->
Unlike the previous codebase, the latent diffusion model has three main components: encoder \(\mathcal{E}\) and decoder \(\mathcal{D}\), U-Net \(\epsilon_\theta\), and the conditioning mechanism \(\tau\), in which the diffusion process is on the latent space instead of the image space.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/diffusion/latent-diffusion-architecture-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/diffusion/latent-diffusion-architecture-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/diffusion/latent-diffusion-architecture-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/diffusion/latent-diffusion-architecture.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Latent Diffusion Model architecture. Image credit to <d-cite key="rombach2022high"></d-cite>
</div>

<p>Therefore, to make a prediction of \(x_0\) from \(x_t\) we need the following steps:</p>

<p><strong>Step 1</strong>: Getting \(z_t\). There are two ways to obtain \(z_t\):</p>

<ul>
  <li>Using forward process given \(x_0\) as \(z_t = \sqrt{\bar{\alpha}_t} z_0 + \sqrt{1-\bar{\alpha}_t} \epsilon_t\) where \(z_0 = \mathcal{E}(x_0)\) is the latent code of the input image \(x_0\), and \(\epsilon_t \sim \mathcal{N}(0, I)\) is the noise at time \(t\).</li>
  <li>Using the reverse process given \(z_T\) and a prompt \(c\) as \(z_{t-1} = \frac{1}{\sqrt{\alpha_t}} (z_{t+1} - \frac{1 - \alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta (z_{t+1}, t, \tau(c))) + \sigma_t \epsilon\) where \(\epsilon\) is the noise. It is important to note that we consider the conditional diffusion process, i.e., \(\epsilon_\theta (z_{t+1}, t, \tau(c))\) where \(\tau(c)\) is the embedding vector of the prompt \(c\).</li>
</ul>

<p><strong>Step 2</strong>: Predict the latent code \(z_0\) from \(z_t\) using a similar equation as in the standard diffusion model. However, again, we need to consider the conditional diffusion process.</p>

\[\tilde{z}_0 = \frac{z_t - \sqrt{1-\bar{\alpha}_t} \epsilon_\theta(z_t, t, \tau(c))}{\sqrt{\bar{\alpha}_t}}\]

<p><strong>Step 3</strong>: Using the decoder to obtain the image \(x_0\) from \(z_0\).</p>

\[\tilde{x}_0 = \mathcal{D}(\tilde{z}_0)\]

<!-- Detailed implementation as follows:

```python
quick_sample_till_t = lambda c, s, start_code, t: sample_model(model, sampler,
                                                                 c, image_size, image_size, ddim_steps, s, ddim_eta,
                                                                 start_code=start_code, till_T=t, verbose=False)

# Step 1: get z_t
z_t = quick_sample_till_t(emb_c, start_guidance, start_code, t_enc)

# Step 2a: predict epsilon_t
e_t = model.apply_model(z_t, t_enc_ddpm, emb_c)

# Step 2b: predict z_0
z_0_tilde = (z_t - (1 - alpha_bar).sqrt() * e_t) / alpha_bar.sqrt()

# Step 3: predict x_0
``` -->

<p>It is a worth noting that, in the inference process of the LDM (with <code class="language-plaintext highlighter-rouge">diffusers</code>) (which can be found in the <a href="https://github.com/rohitgandikota/erasing/blob/a2189e9ae677aca22a00c361bde25d3d320d8a61/eval-scripts/generate-images.py#L132" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">generate-images.py</code></a>) in each inference step, the U-Net outputs the unconditional noise \(\epsilon_u\) and the conditional noise \(\epsilon_c\). And the final noise \(\epsilon = \epsilon_u + \text{guidance_scale} (\epsilon_c - \epsilon_u)\) is used to sample the next latent code \(z_{t+1}\).</p>

<h3 id="notebooks">Notebooks</h3>

<p>Here is the embedded Jupyter notebook. The result is really interesting. In this example, I use a prompt <code class="language-plaintext highlighter-rouge">Image of cassette player</code> to generate images with Stable Diffusion version 1.4 with DDIM and 100 steps. Each row shows the <code class="language-plaintext highlighter-rouge">Predicted image</code> \(\tilde{x}_0 = \mathcal{D}(\tilde{z}_0)\), <code class="language-plaintext highlighter-rouge">Generated image using the current latent code</code> \(\tilde{x}_t = \mathcal{D}(\tilde{z}_t)\), and <code class="language-plaintext highlighter-rouge">Scaled Difference</code> between two images \(\delta = \frac{\tilde{x}_0 - \tilde{x}_t}{\max (\tilde{x}_0 - \tilde{x}_t)}\), respectively.</p>

<p>We can see that, at early steps (i.e., \(t &gt; 80\)) the two images look very noisy and do not show any sign of desired object in the prompt. However, if looking to the difference image (i.e., <code class="language-plaintext highlighter-rouge">delta</code>), we can still see some patterns of the object. It shows that the prediction technique works even at very early steps of the diffusion process. And, through the diffusion process, the difference becomes smaller and smaller and the two images nearly identical at the end of the process.</p>




    <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;">
  <div class="jupyter-notebook-iframe-container">
    <iframe src="/assets/jupyter/demo_ddim_jump.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe>
  </div>
</div>



<h3 id="how-to-generate-an-image-with-a-gaussian-noise">How to generate an image with a Gaussian noise?</h3>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/2023-10-17-watermark.bib"></d-bibliography>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
