<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>A Tutorial on Diffusion Models (Part 2) | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="DDIM, Diffusion Inversion and Accelerating Inference">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2023/diffusion-tutorial-p2/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "A Tutorial on Diffusion Models (Part 2)",
      "description": "DDIM, Diffusion Inversion and Accelerating Inference",
      "published": "October 3, 2023",
      "authors": [
        {
          "author": "Tuan-Anh Bui",
          "authorURL": "https://tuananhbui89.github.io/",
          "affiliations": [
            {
              "name": "Monash University",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>A Tutorial on Diffusion Models (Part 2)</h1>
        <p>DDIM, Diffusion Inversion and Accelerating Inference</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#ddim">DDIM</a></div>
            <div><a href="#diffusion-inversion">Diffusion Inversion</a></div>
            <div><a href="#implementation">Implementation</a></div>
            
          </nav>
        </d-contents>

        <!-- I have been asked by Dinh to develop a short tutorial/lecture on diffusion models for the course "Deep Learning" at Monash University (FIT3181). And, here it is. -->

<h2 id="resources">Resources</h2>

<ul>
  <li>The Jupyter notebook with Tensorflow2 implementation is available on <a href="https://github.com/tuananhbui89/diffusion_tf2" rel="external nofollow noopener" target="_blank">Github</a>.</li>
  <li>The slide can be found here: <a href="https://www.dropbox.com/scl/fi/x7ucu2reluvv0v7rahw75/A-short-tutorial-on-Diffusion_v2.pdf?rlkey=yplk7jib1fx1wqg39fdibwlh3&amp;dl=0" rel="external nofollow noopener" target="_blank">(Dinh’s revision)</a>.</li>
  <li>The lecture about Generative Models which includes VAE, GAN and Diffusion Models that I taught at VietAI is available <a href="https://docs.google.com/presentation/d/1WT0OeAuTrRpCWq0agIbfaSh5VCuscUND85i3WT-ggZs/edit?usp=sharing" rel="external nofollow noopener" target="_blank">here</a>.</li>
  <li>The first part of this tutorial can be found <a href="https://tuananhbui89.github.io/blog/2023/diffusion-tutorial/">here</a>.</li>
</ul>

<h2 id="ddim">DDIM</h2>

<p>One of the main drawbacks of DDPM is that training process requires a large \(T\) to reach the equilibrium state. In inference, to obtain a sample \(x_0\), we need to run through \(T\) reverse steps, sequentially, which is very slow. To address this issue, Song et al. <d-cite key="song2020denoising"></d-cite> proposed a new diffusion model called DDIM (Denoising Diffusion Implicit Model) which allows us to accelerate the inference process while using the same training process as DDPM (it means that you can use the pre-trained DDPM model to inference).</p>

<p>(To be continued)</p>

<h2 id="diffusion-inversion">Diffusion Inversion</h2>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/watermark/gan-inversion-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/watermark/gan-inversion-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/watermark/gan-inversion-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/watermark/gan-inversion.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
     Illustration of GAN inversion (Image source <d-cite key="xia2022gan"></d-cite>).
</div>

<p>Generative inversion is a technique that allows us to invert the generation process. In other words, given a pre-trained generative model \(g_\theta(z)\) and an image \(x\) which can be either real image or generated one, we can find the noise \(z\) such that \(g_\theta(z)\) is close to \(x\). This technique was first proposed for GANs in Zhu et al. (2016) <d-cite key="zhu2016generative"></d-cite>, Creswell et al. (2016) <d-cite key="creswell2018inverting"></d-cite> not long after the introduction of GAN in 2014. It can be seen that, obtaining the inverted latent code brings many useful implications such as capability to edit/manipulate generated images by editing the latent code, or adversarial perturbation removal <d-cite key="samangouei2018defense"></d-cite>.</p>

<p>Because requring the deterministic property: one noise \(z\) always generates the same image \(x\), this technique is not trivial to apply to other generative models such as VAEs or Flow-based models. For Diffusion Models, thanks to the deterministic property in DDIM, we can apply this technique to invert the diffusion process, i.e., given an image \(x_0\), we can find the noise \(x_T\) to reconstruct \(x_0\). And with the blooming of Diffusion Models in the last two years, we can see many cool applications of this technique such as Textual Inversion <d-cite key="gal2022image"></d-cite>, Image Editing <d-cite key="mokady2023null"></d-cite> or the work we are discussing - Watermarking <d-cite key="wen2023tree"></d-cite>).</p>

<p>In the DDPM framework, the forward diffusion process has a nice property that:</p>

\[x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon_t\]

<p>where \(x_0\) is the initial image, \(\epsilon_t \sim \mathcal{N}(0, I)\) is the noise at time \(t\). This property allows us to <code class="language-plaintext highlighter-rouge">predict</code> noisy version \(x_t\) of \(x_0\) at any arbitrary time \(t\). On the other hand, given \(\epsilon_t = \epsilon_\theta(x_t, t)\) is the predicted noise at time \(t\) by the denoising network \(\epsilon_\theta\) and \(x_t\), we can <code class="language-plaintext highlighter-rouge">predict</code> \(\tilde{x_0}\) as follows:</p>

\[\tilde{x}_0 = \frac{x_t - \sqrt{1-\bar{\alpha}_t} \epsilon_\theta(x_t, t)}{\sqrt{\bar{\alpha}_t}}\]

<p>Now we consider the next step in the forward diffusion process:</p>

\[x_{t+1} = \sqrt{\bar{\alpha}_{t+1}} x_0 + \sqrt{1 - \bar{\alpha}_{t+1}} \epsilon_{t+1}\]

<p>where \(\epsilon_{t+1} \sim \mathcal{N}(0, I)\) is the noise at time \(t+1\). If we replace the original \(x_0\) with the predicted \(\tilde{x}_0\) and assume that the diffusion process is large enough so that \(\epsilon_{t+1} \approx \epsilon_\theta(x_t, t)\), we can obtain the inverted diffusion process as follows:</p>

\[x_{t+1} = \sqrt{\bar{\alpha}_{t+1}} \frac{x_t - \sqrt{1-\bar{\alpha}_t} \epsilon_\theta(x_t, t)}{\sqrt{\bar{\alpha}_t}} + \sqrt{1 - \bar{\alpha}_{t+1}} \epsilon_\theta(x_t, t)\]

<p>which now depends only on \(x_t\) and \(\epsilon_\theta(x_t, t)\). Repeating this process from \(t=0\) to \(t=T\), we can obtain the inverted code \(x_T\) that reconstructs \(x_0\) (again it works for DDIM model only).</p>

<h2 id="implementation">Implementation</h2>

<h3 id="ddim-1">DDIM</h3>

<h3 id="predicting-x_0-from-x_t">Predicting \(x_0\) from \(x_t\)</h3>

<p><strong>Standard Diffusion Model</strong> In the first part, I use the<a href="https://github.com/openai/guided-diffusion" rel="external nofollow noopener" target="_blank"> Guided-Diffusion</a> by OpenAI as the codebase to demonstrate this technique (i.e., predicting \(x_0\) from \(x_t\)). The codebase is for the <a href="http://arxiv.org/abs/2105.05233" rel="external nofollow noopener" target="_blank">Diffusion Models Beat GANS on Image Synthesis</a> paper. I have blogged about this paper and some important components of the codebase <a href="https://tuananhbui89.github.io/blog/2023/conditional-diffusion/">here</a>.</p>

<p>The main function to predict \(x_0\) from \(x_t\) as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">pred_eps_and_x0_from_xstart_uncond</span><span class="p">(</span><span class="n">model_fn</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        the (uncondition/standard) $$\epsilon_</span><span class="se">\t</span><span class="s">heta(x_t,t)$$
        the (uncondition/standard) $$</span><span class="se">\t</span><span class="s">ilde{x}_0 = </span><span class="se">\f</span><span class="s">rac{x_t - \sqrt{1 - </span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t} \epsilon_</span><span class="se">\t</span><span class="s">heta(x_t,t)}{\sqrt{</span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t}}$$
        note 1: the _predict_xstart_from_eps() function does not have parameter, therefore, using auxiliary_diffusion or diffusion does not matter
        </span><span class="sh">"""</span>
        <span class="k">assert</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">B</span><span class="p">,)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">q_sample</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_scale_timesteps</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># only this step has trainable parameter
</span>        <span class="k">assert</span> <span class="n">eps</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
        <span class="n">eps</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">x_0</span> <span class="o">=</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_predict_xstart_from_eps</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eps</span><span class="p">,</span> <span class="n">x_0</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">pred_eps_and_x0_from_xstart_cond</span><span class="p">(</span><span class="n">model_fn</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">,</span> <span class="n">cond_fn</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        the condition $$\hat{\epsilon}_{</span><span class="se">\t</span><span class="s">heta}(x_t,t,y,\phi) = \epsilon_</span><span class="se">\t</span><span class="s">heta(x_t,t) - \sqrt{1 - </span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t} </span><span class="se">\n</span><span class="s">abla_{x_t} \log p_\phi (y \mid x_t)$$ as in classifier-guidance model
        the condition $$</span><span class="se">\t</span><span class="s">ilde{x}_0 = </span><span class="se">\f</span><span class="s">rac{x_t - \sqrt{1 - </span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t} \hat{\epsilon}_{</span><span class="se">\t</span><span class="s">heta}(x_t,t,y,\phi)}{\sqrt{</span><span class="se">\b</span><span class="s">ar{</span><span class="se">\a</span><span class="s">lpha}_t}}$$
        note 1: the _predict_xstart_from_eps() function does not have parameter, therefore, using auxiliary_diffusion or diffusion does not matter
        note 2: the classifier should be the ORIGINAL classifier, not the auxiliary classifier
        </span><span class="sh">"""</span>
        <span class="k">assert</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">B</span><span class="p">,)</span>
        <span class="n">alpha_bar</span> <span class="o">=</span> <span class="nf">_extract_into_tensor</span><span class="p">(</span><span class="n">diffusion</span><span class="p">.</span><span class="n">alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">q_sample</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_scale_timesteps</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># only this step has trainable parameter
</span>        <span class="k">assert</span> <span class="n">eps</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
        <span class="n">eps</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="nf">cond_fn</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_scale_timesteps</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_bar</span><span class="p">).</span><span class="nf">sqrt</span><span class="p">()</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">x_0</span> <span class="o">=</span> <span class="n">diffusion</span><span class="p">.</span><span class="nf">_predict_xstart_from_eps</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eps</span><span class="p">,</span> <span class="n">x_0</span>
</code></pre></div></div>

<p><strong>Latent Diffusion Model</strong> In this part, I will use the codebase from the paper <a href="https://erasing.baulab.info/" rel="external nofollow noopener" target="_blank">Erasing Concepts from Diffusion Models</a> which is based on the <a href="https://github.com/CompVis/stable-diffusion" rel="external nofollow noopener" target="_blank">Stable Diffusion Model</a> by <a href="https://github.com/CompVis" rel="external nofollow noopener" target="_blank">CompVis lab</a> as the codebase to demonstrate this technique. Unlike the previous codebase, the latent diffusion model has three main components: encoder \(\mathcal{E}\) and decoder \(\mathcal{D}\), U-Net \(\epsilon_\theta\), and the conditioning mechanism \(\tau\), in which the diffusion process is on the latent space instead of the image space.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/diffusion/latent-diffusion-architecture-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/diffusion/latent-diffusion-architecture-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/diffusion/latent-diffusion-architecture-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/diffusion/latent-diffusion-architecture.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Latent Diffusion Model architecture. Image credit to <d-cite key="rombach2022high"></d-cite>
</div>

<p>Therefore, to make a prediction of \(x_0\) from \(x_t\) we need the following steps:</p>

<p><strong>Step 1</strong>: Getting \(z_t\). There are two ways to obtain \(z_t\):</p>

<ul>
  <li>Using forward process given \(x_0\) as \(z_t = \sqrt{\bar{\alpha}_t} z_0 + \sqrt{1-\bar{\alpha}_t} \epsilon_t\) where \(z_0 = \mathcal{E}(x_0)\) is the latent code of the input image \(x_0\), and \(\epsilon_t \sim \mathcal{N}(0, I)\) is the noise at time \(t\).</li>
  <li>Using the reverse process given \(z_T\) and a prompt \(c\) as \(z_{t-1} = \frac{1}{\sqrt{\alpha_t}} (z_{t+1} - \frac{1 - \alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta (z_{t+1}, t, \tau(c))) + \sigma_t \epsilon\) where \(\epsilon\) is the noise. It is important to note that we consider the conditional diffusion process, i.e., \(\epsilon_\theta (z_{t+1}, t, \tau(c))\) where \(\tau(c)\) is the embedding vector of the prompt \(c\).</li>
</ul>

<p><strong>Step 2</strong>: Predict the latent code \(z_0\) from \(z_t\) using a similar equation as in the standard diffusion model. However, again, we need to consider the conditional diffusion process.</p>

\[\tilde{z}_0 = \frac{z_t - \sqrt{1-\bar{\alpha}_t} \epsilon_\theta(z_t, t, \tau(c))}{\sqrt{\bar{\alpha}_t}}\]

<p><strong>Step 3</strong>: Using the decoder to obtain the image \(x_0\) from \(z_0\).</p>

\[\tilde{x}_0 = \mathcal{D}(\tilde{z}_0)\]

<p>Detailed implementation as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">quick_sample_till_t</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">c</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">start_code</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nf">sample_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span>
                                                                 <span class="n">c</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">ddim_steps</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">ddim_eta</span><span class="p">,</span>
                                                                 <span class="n">start_code</span><span class="o">=</span><span class="n">start_code</span><span class="p">,</span> <span class="n">till_T</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Step 1: get z_t
</span><span class="n">z_t</span> <span class="o">=</span> <span class="nf">quick_sample_till_t</span><span class="p">(</span><span class="n">emb_c</span><span class="p">,</span> <span class="n">start_guidance</span><span class="p">,</span> <span class="n">start_code</span><span class="p">,</span> <span class="n">t_enc</span><span class="p">)</span>

<span class="c1"># Step 2a: predict epsilon_t
</span><span class="n">e_t</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">apply_model</span><span class="p">(</span><span class="n">z_t</span><span class="p">,</span> <span class="n">t_enc_ddpm</span><span class="p">,</span> <span class="n">emb_c</span><span class="p">)</span>

<span class="c1"># Step 2b: predict z_0
</span><span class="n">z_0_tilde</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_t</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_bar</span><span class="p">).</span><span class="nf">sqrt</span><span class="p">()</span> <span class="o">*</span> <span class="n">e_t</span><span class="p">)</span> <span class="o">/</span> <span class="n">alpha_bar</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">()</span>

<span class="c1"># Step 3: predict x_0
</span></code></pre></div></div>

<p>It is a worth noting that, in the inference process of the LDM (with <code class="language-plaintext highlighter-rouge">diffusers</code>) (which can be found in the <a href="https://github.com/rohitgandikota/erasing/blob/a2189e9ae677aca22a00c361bde25d3d320d8a61/eval-scripts/generate-images.py#L132" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">generate-images.py</code></a>) in each inference step, the U-Net outputs the unconditional noise \(\epsilon_u\) and the conditional noise \(\epsilon_c\). And the final noise \(\epsilon = \epsilon_u + \text{guidance_scale} (\epsilon_c - \epsilon_u)\) is used to sample the next latent code \(z_{t+1}\).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># random a timestep to stop at, so that we can predict the image at that timestep
# note 1: the scheduler.timesteps is in reverse order, i.e., [999, 998, ..., 1, 0] if num_inference_steps=1000 
# note 2: if num_inference_steps = 100, then the scheduler.timesteps is [999, 989, 979, ..., 19, 9, 0]
</span>
<span class="n">stop_timestep</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="p">)</span>
<span class="n">count_timestep</span> <span class="o">=</span> <span class="n">num_inference_steps</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">scheduler</span><span class="p">.</span><span class="n">timesteps</span><span class="p">):</span>
    <span class="n">count_timestep</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="c1"># expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.
</span>    <span class="n">latent_model_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">latents</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">latent_model_input</span> <span class="o">=</span> <span class="n">scheduler</span><span class="p">.</span><span class="nf">scale_model_input</span><span class="p">(</span><span class="n">latent_model_input</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>

    <span class="c1"># predict the noise residual
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">noise_pred</span> <span class="o">=</span> <span class="nf">unet</span><span class="p">(</span><span class="n">latent_model_input</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">text_embeddings</span><span class="p">).</span><span class="n">sample</span>

    <span class="c1"># perform guidance
</span>    <span class="n">noise_pred_uncond</span><span class="p">,</span> <span class="n">noise_pred_text</span> <span class="o">=</span> <span class="n">noise_pred</span><span class="p">.</span><span class="nf">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">noise_pred</span> <span class="o">=</span> <span class="n">noise_pred_uncond</span> <span class="o">+</span> <span class="n">guidance_scale</span> <span class="o">*</span> <span class="p">(</span><span class="n">noise_pred_text</span> <span class="o">-</span> <span class="n">noise_pred_uncond</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">count_timestep</span> <span class="o">&gt;</span> <span class="n">stop_timestep</span><span class="p">:</span>
        <span class="c1"># compute the previous noisy sample x_t -&gt; x_t-1
</span>        <span class="n">latents</span> <span class="o">=</span> <span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">noise_pred</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">).</span><span class="n">prev_sample</span>
    <span class="k">elif</span> <span class="n">count_timestep</span> <span class="o">==</span> <span class="n">stop_timestep</span><span class="p">:</span>
        <span class="c1"># Predict the latent code $$z_0$$ from $$z_t$$
</span>        <span class="c1"># $$\tilde{z}_0 = \frac{z_t - \sqrt{1-\bar{\alpha}_t} \epsilon_\theta(z_t, t, \tau(c))}{\sqrt{\bar{\alpha}_t}}$$
</span>        <span class="n">alpha_bar_t</span> <span class="o">=</span> <span class="n">scheduler</span><span class="p">.</span><span class="n">alphas_cumprod</span><span class="p">[</span><span class="n">stop_timestep</span><span class="p">]</span>

        <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_bar_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise_pred</span><span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">alpha_bar_t</span><span class="p">)</span>

        <span class="c1"># break out of the loop
</span>        <span class="k">break</span>                
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Something went wrong, the stop timestep is smaller than the current timestep</span><span class="sh">"</span><span class="p">,</span> <span class="n">count_timestep</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">stop_timestep</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="p">)</span>
        <span class="nf">exit</span><span class="p">()</span>

<span class="c1"># scale and decode the image latents with vae
</span><span class="n">latents</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">0.18215</span> <span class="o">*</span> <span class="n">latents</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">vae</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">latents</span><span class="p">).</span><span class="n">sample</span>

<span class="n">image</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">).</span><span class="nf">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">numpy</span><span class="p">()</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span> <span class="o">*</span> <span class="mi">255</span><span class="p">).</span><span class="nf">round</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="sh">"</span><span class="s">uint8</span><span class="sh">"</span><span class="p">)</span>
<span class="n">pil_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">Image</span><span class="p">.</span><span class="nf">fromarray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">]</span>
<span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">im</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">pil_images</span><span class="p">):</span>
    <span class="n">im</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">folder_path</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">prompts_name</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">case_number</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">stop_timestep</span><span class="si">}</span><span class="s">.png</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/2023-10-17-watermark.bib"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;">
  <script>
    let giscusTheme = localStorage.getItem("theme");
    let giscusAttributes = {
        "src": "https://giscus.app/client.js",
        "data-repo": "alshedivat/al-folio",
        "data-repo-id": "MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==",
        "data-category": "Comments",
        "data-category-id": "DIC_kwDOA5PmLc4CTBt6",
        "data-mapping": "title",
        "data-strict": "1",
        "data-reactions-enabled": "1",
        "data-emit-metadata": "0",
        "data-input-position": "bottom",
        "data-theme": giscusTheme,
        "data-lang": "en",
        "crossorigin": "anonymous",
        "async": "",
    };


    let giscusScript = document.createElement("script");
    Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
    document.getElementById("giscus_thread").appendChild(giscusScript);
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a>
</noscript>
</div>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
