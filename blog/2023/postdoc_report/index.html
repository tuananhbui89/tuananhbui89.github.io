<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Postdoc Working Report | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="Researcher in Generative AI and Trustworthy AI
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="http://localhost:4000/blog/2023/postdoc_report/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Postdoc Working Report</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <h2 id="-introduction">
<a name="intro"></a> Introduction</h2>

<p>Main projects:</p>

<ul>
  <li>
<a href="#anti-personalized">anti-personalized</a> Anti-Personalized Generative Models (On-hold)</li>
  <li>
<a href="#erasing">erasing</a> Erasing Underiable Concepts from Diffusion Models (Working)</li>
</ul>

<p>Other tasks such as:</p>

<ul>
  <li>[cosup] Working with Van-Anh Nguyen on her PhD project: Distributional Robustness and Sharpness Aware Minimization to improve Generalization of Deep Learning Models</li>
  <li>[reading] Managing a group reading every Friday on the topic of Generative Models</li>
  <li>[grant] Writing grant proposals if required</li>
  <li>[admin] Admin tasks such as support Dinh to prepare some documents</li>
</ul>

<h2 id="-erasing-underiable-concepts-from-diffusion-models">
<a name="erasing"></a> Erasing Underiable Concepts from Diffusion Models</h2>

<p>Given a pre-trained generative model such as Stable Diffusion, we aim to remove a generation capability of the model regarding specific concept or keyword, for example “Barack Obama”.
By unlearning that concept, the model cannot generate meaningful output image whenever a prompt with this specific keyword while still retain its capability for all other things.</p>

<p>This idea has been proposed in the paper “Erasing Concepts from Diffusion Models”. However, there are some limitations of this paper:</p>

<ul>
  <li>The concept is erased not completely, but only reduced its probability of generating an image according to the likelihood that is described by the concept, scaled by a power factor \(\eta\).</li>
  <li>The concept to be erased needs to be associated with a specific keyword (e.g., “Barack Obama” or “nudity” or “gun”). However, a concept can be described in many different ways, for example, “Barack Obama” can be described as “the 44th president of the United States” or “the first African American president of the United States”. Therefore, it is not possible to erase all concepts related to “Barack Obama” by just erasing the keyword “Barack Obama”.</li>
  <li>When erasing a specific concept (e.g., “Barack Obama”), related concepts (e.g., “Donald Trump”) can be also erased.</li>
  <li>This erased concept can be recovered by an adversary by crawling images with this concept from the Internet and use Textual Inversion to recover the erased concept.</li>
</ul>

<p>Therefore, we propose a new idea to erase a specific concept completely, without effecting other related concepts. The idea is to utilize an auxiliary classifier to classify the concept (or set of concepts) and then use the gradient of the classifier to guide the unlearning process in the diffusion model.</p>

<h2 id="-anti-personalized-generative-models">
<a name="anti-personalized"></a> Anti-Personalized Generative Models</h2>

<p>Generate a perturbation that can be added to the input images to prevent these images from then being learned by a personalized method.</p>

<ul>
  <li>Defender’s goal: generate a perturbation that can be added to the input images to prevent these images from then being learned by a personalized method.</li>
  <li>Attacker’s goal: get the perturbed images and use them to personalize the model.</li>
</ul>

<p>What are the differences between this idea and the Anti-Dreambooth idea?</p>

<ul>
  <li>We focus on specific set of key words or concepts</li>
  <li>These images can still be learned by personalized method, but cannot generate meaningful images if there is a prohitibited keyword/concept in the prompt.</li>
</ul>

<h2 id="24112023">24/11/2023</h2>

<h3 id="erasing-concepts-from-diffusion-models">Erasing Concepts from Diffusion Models</h3>

<h4 id="version-3">Version 3</h4>

<p><strong>Change the codebase</strong>: from OpenAI Guided Diffusion (i.e., able to generate ImageNet dataset only, conditioning on an auxiliary classifier) to Stable Diffusion (i.e., able to generate more diverse, complex images, using a prompt as input).</p>

<p><strong>Idea of version 3.1</strong>: Utilize the jumping prediction property of the DDIM model to improve the erasing performance.</p>

<p><strong>Idea of version 3.2</strong>: Utilize the CLIP embedding to align the concept embedding with the image embedding.</p>

<p>Using CLIP to align the output of the fine-tuned model with the prompts. Given three inputs: the prompt with erased concept \(c_{era}\) (i.e., <code class="language-plaintext highlighter-rouge">nudity</code> or <code class="language-plaintext highlighter-rouge">cassette player</code>), the prompt with targeted concept \(c_{tar}\) (i.e., <code class="language-plaintext highlighter-rouge">null</code>) and the generated image \(x_{0,era} = G(z_T, c_{era})\). We will have three corresponding embeddings \(E_T (c_{era})\), \(E_T (c_{tar})\) and \(E_I (x_{0,era})\) from the CLIP model. The goal is to align the embeddings \(E_I (x_{0, era})\) to the embeddings \(E_T (c_{tar})\) but not to the embeddings \(E_T (c_{era})\).</p>

<p>The loss function of the diffusion model as follows:</p>

\[\mathcal{L}_{\text{align}}(\theta) = \alpha * (1 - \text{sim} (E_I (x_{0, era}), E_T (c_{tar}))) + \beta * \mid \text{sim} (E_I (x_{0, era}), E_T (c_{era})) \mid\]

<p><strong>Results</strong> See in other report. Overall, the results are good, IMO, better than the baseline. Ready for extensive evaluation phase.</p>

<h4 id="admin">Admin</h4>

<ul>
  <li>Seeking approval from DST on the change of the workpackage (In general, the main theme is still exploring Multi-Objective Optimization for Trustworthy Machine Learning. But in the amendment proposal, we would like to explore it in the modern context of Generative Models, which is extremely hot and important)</li>
  <li>Meeting to report progress of the project monthly and with Paul and Tamas biweekly.</li>
</ul>

<h4 id="action-items">Action Items</h4>

<ul>
  <li>Ethic approval for “nudity” concept from Monash University and DST. Not only “nudity” but also harmful concepts as well.</li>
  <li>Think about evaluation method such as evaluate how this method effect to synonym concepts, such as “cassette player” and “tape player”.</li>
  <li>Think about the better way to measure the different instead of just use L2.</li>
</ul>

<h3 id="others">Others</h3>

<ul>
  <li>[grant] submit Amazon Research Award (ARA) 2023 application</li>
  <li>[admin] Help Dinh to draw a org chart for the EoY Department meeting</li>
  <li>[research] Discuss with Trang about collaboration on the RLHF with MOO. In this idea, we propose a new additional signal/prompt s_i to control the corresponding reward function R_i so that R_i and R_j will be orthogonal in term of output (each R_i will focus on different set of goals).</li>
</ul>

<h4 id="version-2">Version 2</h4>

<ul>
  <li>See details in other report.</li>
  <li>Results: Not better than the baseline <a href="https://arxiv.org/pdf/2308.14761.pdf" rel="external nofollow noopener" target="_blank">“Unified Concept Editing in Diffusion Models”</a>.</li>
</ul>

<!-- 
## 24/08/2023

### TML for GenAI project

#### Main idea 
To date, we have three directions that we can explore regarding TML for GenAI. 

- Direction 1: Anti-Textual Inversion: Protect personal identity from personalized GenAI

  - Main idea: We want to learn perturbed personal images so that these images after applying personalized/conceptual learning techniques such as textual - inversion method, can be highly conflicted with a set of texts, and keywords that we think should be harmful. For example, "naked, sexual harassment, attacking, fighting, etc". The set of text, and keywords can be flexible and pre-defined. The embedding vector representing the personalized concept can be shared and used for good purposes (i.e., prompt without these restricted keywords), but when a prompt has these keywords, the generated output will be nonsense.

- Direction 2: Adversarial Cleaning for Personalization learning 
  
- Direction 3: Completely erasing a concept from diffusion model 

  - Presentations about related works [https://drive.google.com/file/d/1CA0ybshvZQkOrc4ms7C6nR3Z9NcDJZ7Y/view?usp=sharing](https://drive.google.com/file/d/1CA0ybshvZQkOrc4ms7C6nR3Z9NcDJZ7Y/view?usp=sharing)

#### Progress

- Link to report file [here](./protect_ti.md) 


### Others

- Monthly meeting TML project will happens on 04 September.
  - I will present current progress on Direction 1.

- Other research/collaborations:
  - With Van Anh (lead) and Trung: connect distributional robustness on data space (our ICLR paper) and model space (i.e., SAM) into one nice framework (derive using approach as in our ICLR paper) which aims to achieve better generalization (Weekly meeting on Monday) 
  - With Khanh (VinAI), Long and Trung: Mixup Class-Guidance Diffusion Model (Weekly meeting on Thursday)

- Trust & Safety Research Awards (Google Research)
  - Link: https://research.google/outreach/trust-and-safety-program/
  - Deadline: 11:59:59 PST September 20, 2023
  - No progress yet (sorry)

- DSAI GenAI Response:
  - In collaborate with Ehsan Shareghi.
  - No progress yet (waiting Ehsan for further instruction).

- DPM - GenAI hackathon
  - With Trang and Long
  - Progress: we have discussed but not finalized yet. Might need further instruction fro m Dinh

## 13/08/2023

### TML for GenAI project
 
#### Technicality:

- Main idea: We want to learn perturbed personal images so that these images after applying personalized/conceptual learning techniques such as textual - inversion method, can be highly conflicted with a set of texts, and keywords that we think should be harmful. For example, "naked, sexual harassment, attacking, fighting, etc". The set of text, and keywords can be flexible and pre-defined. The embedding vector representing the personalized concept can be shared and used for good purposes (i.e., prompt without these restricted keywords), but when a prompt has these keywords, the generated output will be nonsense. 
 
- Progress: 
  - Attack side: Generate harmful images given token learned by Textual Inversion (done, have shown some images on the last meeting with DST, however, the quality of output is still questionable). 
  - Defense side: Implement with the Huggingface library (In progress, however recently having a bug in getting gradient). Take a longer time because not familiar with the Huggingface library. 
  - Recently, the defense idea is still very simple and not much different from the Anti-Dreambooth work. I want to get familiar with the new codebase first and to see any interesting observations. 
 
Next step:
  - Asking for support on fixing the bug in the defense side from VinAI peers. (Update 24/08: No need, I fixed it)
  - Get a better prompt template as in the paper [1]. (Update 24/08: Done, using I2P benchmark to generate NSFW images)
 
 
Logistic:
  - In collaboration with DSTG (Paul and Tamas, biweekly meeting Thursday from 10h am to 11h am) 
  - Also, collaborate with Tuan-Anh Tran and his mentee at VinAI. (Waiting for feedback from anh Tuan-Anh) (Update 24/08: Sadly, anh Tuan Anh and his mentee decided to go independently - with quite similar idea) 
 
Others
  - Teaching FIT3181 (1 lab per week every Friday 2 pm-4 pm) 
  - Help Trung to run the Generative AI Reading group (every Friday 10h am - 11h30 am). Will present 2 papers about TML for GenAI on Friday, 11, Aug. ([1,2])
  - No further update on the Germany trip (it is likely to cancel the trip because I could not find support to take care of the children)
 
[1] Erasing Concepts from Diffusion Models  https://arxiv.org/pdf/2303.07345.pdf

[2] CIRCUMVENTING CONCEPT ERASURE METHODS FOR TEXT-TO-IMAGE GENERATIVE MODELS  https://arxiv.org/pdf/2308.01508.pdf -->

          </article>
</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
