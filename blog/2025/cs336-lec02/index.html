<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>CS336 Lecture 2 - PyTorch, resource accounting | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="AI Summary of CS336 Lecture">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2025/cs336-lec02/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->
<!-- Page/Post style -->
<style type="text/css">
  
</style>


<div class="post">

  <header class="post-header">
    <h1 class="post-title">CS336 Lecture 2 - PyTorch, resource accounting</h1>
    <p class="post-meta">December 8, 2025</p>
    <p class="post-tags">
      <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>
        ·  
        <a href="/blog/tag/genai">
          <i class="fas fa-hashtag fa-sm"></i> genai</a>  
          <a href="/blog/tag/llm">
          <i class="fas fa-hashtag fa-sm"></i> llm</a>  
          <a href="/blog/tag/tutorial">
          <i class="fas fa-hashtag fa-sm"></i> tutorial</a>  
          <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#course-objectives-and-lecture-plan">Course objectives and lecture plan</a></li>
<li class="toc-entry toc-h1"><a href="#napkin-math-approach-for-large-scale-training-time-estimation">Napkin-math approach for large-scale training time estimation</a></li>
<li class="toc-entry toc-h1"><a href="#memory-limited-model-size-estimation-on-gpus">Memory-limited model size estimation on GPUs</a></li>
<li class="toc-entry toc-h1"><a href="#pedagogical-focus-on-primitives-and-resource-accounting-mindset">Pedagogical focus on primitives and resource-accounting mindset</a></li>
<li class="toc-entry toc-h1"><a href="#tensors-and-floating-point-data-types-fp32-fp16-bf16-fp8">Tensors and floating-point data types: FP32, FP16, BF16, FP8</a></li>
<li class="toc-entry toc-h1"><a href="#device-placement-and-data-movement-between-cpu-and-gpu">Device placement and data movement between CPU and GPU</a></li>
<li class="toc-entry toc-h1"><a href="#tensor-storage-model-views-strides-contiguity-and-mutation-semantics">Tensor storage model, views, strides, contiguity and mutation semantics</a></li>
<li class="toc-entry toc-h1"><a href="#matrix-multiplication-batching-and-einsum-style-dimension-naming">Matrix multiplication, batching and einsum-style dimension naming</a></li>
<li class="toc-entry toc-h1"><a href="#flops-terminology-hardware-peak-performance-and-marketing-caveats">FLOPs terminology, hardware peak performance and marketing caveats</a></li>
<li class="toc-entry toc-h1"><a href="#matmul-flop-cost-formula-and-mfu-benchmarking">Matmul FLOP cost formula and MFU benchmarking</a></li>
<li class="toc-entry toc-h1"><a href="#gradient-computation-cost-and-the-six-times-rule">Gradient computation cost and the six-times rule</a></li>
<li class="toc-entry toc-h1"><a href="#parameter-objects-and-initialization-best-practices">Parameter objects and initialization best practices</a></li>
<li class="toc-entry toc-h1"><a href="#deterministic-seeding-and-large-scale-token-data-loading">Deterministic seeding and large-scale token data loading</a></li>
<li class="toc-entry toc-h1"><a href="#optimizers-per-parameter-state-and-total-memory-accounting">Optimizers, per-parameter state, and total memory accounting</a></li>
<li class="toc-entry toc-h1"><a href="#activation-storage-checkpointing-training-loop-mixed-precision-and-checkpointing">Activation storage, checkpointing, training loop, mixed precision and checkpointing</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <div style="display: flex; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/msHyYioAyNE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
    </iframe>
</div>

<h1 id="course-objectives-and-lecture-plan">Course objectives and lecture plan</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-00-25-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-00-25-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-00-25-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-00-25.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Objective:</strong> Demonstrate how to build language models from <strong>first principles</strong>, emphasizing <strong>PyTorch primitives</strong>, <strong>model construction</strong>, <strong>optimizers</strong>, and an <strong>efficient training loop</strong>.<br></p>

<p>The lecture prioritizes <strong>practical mechanics</strong> over high-level architecture. Key focus areas include:<br></p>

<ul>
  <li>
<strong>Tensors</strong> — representation, manipulation, and lifecycle in training<br>
</li>
  <li>
<strong>Parameter storage</strong> — how model parameters are stored and updated<br>
</li>
  <li>
<strong>Computation placement</strong> — deciding where operations run (CPU vs GPU) and why it matters<br>
</li>
  <li>
<strong>Resource accounting</strong> — precise tracking of <strong>memory</strong> and <strong>compute</strong> (FLOPs and bytes) to inform design and scale decisions<br>
</li>
</ul>

<p>Efficiency is treated as a <strong>first-class concern</strong>: the lecture motivates why exact bookkeeping of <strong>FLOPs and bytes</strong> matters when scaling models and systems.<br></p>

<p>Student expectations:<br></p>

<ol>
  <li>
<strong>Apply these primitives</strong> directly in assignments and implementation exercises.<br>
</li>
  <li>
<strong>Defer architectural deep-dives</strong> (for example, the <strong>transformer</strong>) until those topics are covered later in the course.<br>
</li>
</ol>

<hr>

<h1 id="napkin-math-approach-for-large-scale-training-time-estimation">Napkin-math approach for large-scale training time estimation</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-01-40-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-01-40-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-01-40-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-01-40.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Training-time estimation (order-of-magnitude)</strong><br></p>

<ol>
  <li>
<strong>Compute total training FLOPs</strong>:<br>
    <ul>
      <li>Use the rule of thumb: <strong>Total training FLOPs ≈ 6 × number_of_parameters × number_of_tokens</strong>.<br>
</li>
      <li>The <strong>factor of six</strong> accounts for forward and backward computation across the training run.<br>
</li>
    </ul>
  </li>
  <li>
<strong>Compute effective hardware throughput</strong>:<br>
    <ul>
      <li>
<strong>Effective throughput = hardware peak FLOPs/sec × model FLOPs utilization (MFU)</strong>.<br>
</li>
      <li>A practical choice in this method is <strong>MFU = 0.5</strong>; combining that with <strong>H100</strong> spec-sheet peak FLOPs gives a concrete throughput estimate.<br>
</li>
    </ul>
  </li>
  <li>
<strong>Estimate training time</strong>:<br>
    <ul>
      <li>
<strong>Training time ≈ Total training FLOPs / Effective throughput</strong>.<br>
</li>
    </ul>
  </li>
</ol>

<p>Notes:<br></p>
<ul>
  <li>This approach gives <strong>quick, order-of-magnitude answers</strong> useful for <strong>cost and resource planning</strong> for very large models.<br>
</li>
  <li>It relies on the simplified <strong>6 × parameters × tokens</strong> FLOPs rule and an assumed <strong>MFU</strong>, so treat results as estimates rather than precise timings.</li>
</ul>

<hr>

<h1 id="memory-limited-model-size-estimation-on-gpus">Memory-limited model size estimation on GPUs</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-03-00-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-03-00-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-03-00-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-03-00.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>The maximum parameter count that can be stored on a GPU fleet is constrained by <strong>high-bandwidth memory (HBM) capacity</strong> and the <strong>per-parameter byte footprint</strong> required for <strong>parameters, gradients, and optimizer state</strong>.<br></p>

<p>Example (back-of-the-envelope):<br></p>
<ol>
  <li>
<strong>Available HBM per device</strong>: e.g., an <strong>80 GB HBM device</strong>.<br>
</li>
  <li>
<strong>Per-parameter footprint</strong>: roughly <strong>16 bytes per parameter</strong> (accounting for parameter values, gradient accumulator, and optimizer state in <strong>FP32</strong>).<br>
</li>
  <li>
<strong>Resulting scale</strong>: this yields on the order of <strong>tens of billions of parameters per device</strong> (coarse estimate).<br>
</li>
</ol>

<p>Key caveats:<br></p>
<ul>
  <li>The estimate deliberately omits <strong>activation storage</strong>, which can be significant depending on architecture and training phase.<br>
</li>
  <li>The usable parameter capacity also <strong>depends on batch and sequence sizes</strong>, and on whether additional runtime memory is needed for other tensors or kernels.<br>
</li>
</ul>

<p>Why this matters:<br></p>
<ul>
  <li>This coarse calculation is sufficient to <strong>scope feasible model sizes</strong>.<br>
</li>
  <li>It directly informs decisions about <strong>model parallelism</strong> and <strong>precision reduction strategies</strong> (e.g., moving to lower-precision formats to reduce per-parameter footprint).</li>
</ul>

<hr>

<h1 id="pedagogical-focus-on-primitives-and-resource-accounting-mindset">Pedagogical focus on primitives and resource-accounting mindset</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-04-24-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-04-24-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-04-24-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-04-24.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Instructional emphasis is on mastering <strong>low-level primitives</strong> in <strong>PyTorch</strong> and developing a <strong>resource-accounting mindset</strong>, rather than on the architectural theory of <strong>transformers</strong>.<br></p>

<p>Practical goals are to:<br></p>
<ol>
  <li>
<strong>Measure and reason</strong> about where <strong>memory and compute</strong> are used in a <strong>model pipeline</strong>—identify hotspots and understand per-layer/resource costs.<br>
</li>
  <li>Make design choices that explicitly trade off <strong>accuracy</strong>, <strong>numerical stability</strong>, and <strong>runtime/memory cost</strong>—weigh correctness against performance and resource limits.<br>
</li>
  <li>Build a foundation for applying <strong>resource-aware optimizations</strong> when scaling to <strong>larger architectures</strong> or integrating <strong>hardware-aware techniques</strong>.<br>
</li>
</ol>

<p>This foundation enables <strong>informed, resource-conscious engineering</strong> later on, so optimizations are driven by measured costs and clear trade-offs rather than by opaque abstractions.<br></p>

<hr>

<h1 id="tensors-and-floating-point-data-types-fp32-fp16-bf16-fp8">Tensors and floating-point data types: FP32, FP16, BF16, FP8</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-09-54-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-09-54-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-09-54-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-09-54.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Tensors</strong> are the fundamental storage objects. Their <strong>memory footprint</strong> equals the <strong>number of elements × bytes per element</strong>, where the bytes per element are determined by the chosen floating‑point format.<br></p>

<ul>
  <li>
<strong>FP32 (32‑bit)</strong> — common baseline; <strong>4 bytes per element</strong>.<br>
</li>
  <li>
<strong>FP16 (16‑bit)</strong> — roughly <strong>halves memory</strong> (≈2 bytes per element) but has <strong>reduced dynamic range</strong> and can <strong>underflow/overflow</strong> for very small/large values.<br>
</li>
  <li>
<strong>BF16 (bfloat16)</strong> — keeps <strong>FP32 dynamic range</strong> while using <strong>FP16 memory</strong> by reallocating exponent bits; a <strong>practical choice</strong> for many training computations.<br>
</li>
  <li>
<strong>FP8</strong> — offers <strong>further memory reduction</strong> at the cost of precision; <strong>requires specialized hardware support</strong> and <strong>careful numeric handling</strong>.<br>
</li>
</ul>

<p>In production training people typically use <strong>mixed precision</strong> to balance efficiency and stability:<br></p>
<ol>
  <li>Use <strong>lower precision</strong> for <strong>transient compute</strong> to <strong>reduce memory</strong> and <strong>increase throughput</strong>.<br>
</li>
  <li>Keep <strong>higher precision (FP32)</strong> for <strong>parameters</strong> and <strong>optimizer state</strong> to <strong>preserve numerical stability</strong>.<br>
</li>
</ol>

<hr>

<h1 id="device-placement-and-data-movement-between-cpu-and-gpu">Device placement and data movement between CPU and GPU</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-15-26-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-15-26-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-15-26-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-15-26.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>By default, <strong>tensors</strong> are allocated on the <strong>host (CPU)</strong> and must be explicitly moved to <strong>accelerator devices (GPU)</strong> to exploit hardware acceleration — this movement incurs a nontrivial <strong>host-to-device transfer cost</strong>.<br></p>

<p>Creating <strong>tensors directly on the target device</strong> avoids that copy and the associated overhead.<br></p>

<p>Use <strong>instrumentation</strong> or <strong>asserts</strong> in code to track where a tensor resides. This helps <strong>prevent accidental transfers</strong> and the resulting performance degradation.<br></p>

<p>Typical workflows to minimize transfer overhead:</p>
<ol>
  <li>
<strong>Allocate model parameters on GPU memory</strong> whenever possible so they do not need repeated transfers.<br>
</li>
  <li>
<strong>Create or move input batches to GPU</strong> once per batch, rather than moving individual tensors frequently.<br>
</li>
  <li>
<strong>Check memory allocated before and after operations</strong> as a quick sanity check for unexpected allocations or copies.<br>
</li>
  <li>
<strong>Design pipelines to minimize frequent host-device round-trips</strong> by batching work and keeping data and computation co-located.<br>
</li>
</ol>

<p>Following these practices reduces unnecessary transfers and preserves the performance benefits of accelerators.</p>

<hr>

<h1 id="tensor-storage-model-views-strides-contiguity-and-mutation-semantics">Tensor storage model, views, strides, contiguity and mutation semantics</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-19-24-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-19-24-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-19-24-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-19-24.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>A <strong>PyTorch tensor</strong> is essentially <strong>metadata</strong>—its <strong>shape</strong> and <strong>strides</strong>—that index into an <strong>underlying contiguous storage buffer</strong>. The <strong>stride</strong> for each dimension determines how to compute the <strong>storage offset</strong> for an index.<br></p>

<ul>
  <li>Many tensor manipulations create <strong>zero-copy views</strong> that <strong>share the same storage</strong>:<br>
    <ul>
      <li>
<strong>slices</strong><br>
</li>
      <li>
<strong>transposes</strong><br>
</li>
      <li>
<strong>reshapes</strong> (via <strong>view</strong>)<br>
Mutating one view will therefore <strong>mutate the underlying buffer</strong> and <strong>affect other views</strong> that reference it.<br>
</li>
    </ul>
  </li>
  <li>Some view operations produce <strong>non-contiguous</strong> memory layouts. Calling <strong>.contiguous()</strong> forces replication into a <strong>contiguous buffer</strong> and thus produces a <strong>copy</strong>.<br>
</li>
</ul>

<p>Understanding these semantics is essential to <strong>control memory use</strong>, <strong>avoid inadvertent data duplication</strong>, and <strong>reason about correctness</strong> when <strong>in-place mutations</strong> occur.</p>

<hr>

<h1 id="matrix-multiplication-batching-and-einsum-style-dimension-naming">Matrix multiplication, batching and einsum-style dimension naming</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-27-52-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-27-52-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-27-52-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-27-52.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Matrix multiplication</strong> is the computational workhorse of <strong>deep learning</strong> and is typically executed in <strong>batched form</strong>, where tensors carry <strong>batch</strong> and <strong>sequence</strong> dimensions in addition to per-token <strong>feature</strong> dimensions.<br></p>

<ul>
  <li>
<strong>Batched matmul semantics</strong>: a <strong>(B×S×M)</strong> tensor multiplied by an <strong>(M×K)</strong> matrix performs the same <strong>M×K</strong> matmul for every batch/sequence element, producing a <strong>(B×S×K)</strong> result.<br>
    <ul>
      <li>This pattern is pervasive in <strong>language models</strong> and underlies most token-wise linear transformations.<br>
</li>
    </ul>
  </li>
</ul>

<p><strong>Dimension-naming conventions</strong> such as <strong>einsum</strong> or <strong>einops/rearrange</strong> provide readable, explicit specifications of tensor contractions and reshapes:<br></p>

<ul>
  <li>Reduce indexing errors by making intent explicit.<br>
</li>
  <li>Can be compiled efficiently into optimized kernels.<br>
</li>
  <li>Make multi-head and head-splitting operations (e.g., <strong>head × head_dim ↔ flattened hidden_dim</strong>) explicit and auditable, simplifying reasoning about model internals.<br>
</li>
</ul>

<hr>

<h1 id="flops-terminology-hardware-peak-performance-and-marketing-caveats">FLOPs terminology, hardware peak performance and marketing caveats</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-35-29-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-35-29-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-35-29-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-35-29.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>FLOPs</strong> = count of <strong>floating‑point operations</strong>, while <strong>FLOPs/sec</strong> = <strong>floating‑point operations per second</strong>, a measure of <strong>hardware throughput</strong>.<br></p>

<ul>
  <li>
<strong>Hardware peak FLOPs/sec</strong> depends strongly on <strong>data type</strong> and availability of <strong>specialized units</strong> (e.g., <strong>tensor cores</strong>).<br>
</li>
  <li>
<strong>Vendor specs</strong> often quote <strong>idealized peaks</strong> that assume <strong>sparsity</strong> or specific data types; these quoted peaks are a <strong>useful upper bound</strong> but are not a guarantee of real-world performance.<br>
</li>
</ul>

<p>Practical evaluation requires benchmarking real kernels on your target shapes and data types because several implementation factors substantially affect realized performance:<br></p>
<ol>
  <li>Measure kernels on the actual <strong>shapes</strong> and <strong>data types</strong> you will use — theoretical peaks may not apply.<br>
</li>
  <li>Account for <strong>memory bandwidth</strong>, <strong>kernel shape</strong>, and runtime <strong>overheads</strong> (launch, synchronization, packing, etc.), which frequently dominate performance.<br>
</li>
  <li>Use vendor peaks only as an <strong>upper bound</strong> and rely on empirical benchmarks to determine achievable throughput.<br>
</li>
</ol>

<hr>

<h1 id="matmul-flop-cost-formula-and-mfu-benchmarking">Matmul FLOP cost formula and MFU benchmarking</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-43-08-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-43-08-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-43-08-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-43-08.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>A dense matrix multiplication of shapes <strong>(m×n) × (n×p)</strong> requires <strong>2 × m × n × p FLOPs</strong> — one multiply and one add per inner-product component.<br></p>

<p>The same rule extends to <strong>batched matmuls</strong> by applying the calculation <strong>per batch/sequence element</strong>.<br></p>

<p>For model-level accounting, the forward pass FLOPs often reduce to approximately <strong>2 × tokens × parameters</strong>.<br></p>

<p>Measuring utilization is a small process:<br></p>
<ol>
  <li>Time the kernel to get <strong>measured FLOPs/sec</strong>.<br>
</li>
  <li>Divide that by the <strong>hardware theoretical peak FLOPs/sec</strong>.<br>
</li>
  <li>The ratio is <strong>Model FLOPs Utilization (MFU)</strong> — a practical metric for how effectively the workload uses the hardware.<br>
</li>
</ol>

<ul>
  <li>
<strong>MFU</strong> values above <strong>~0.5</strong> are common targets for good utilization.<br>
</li>
  <li>
<strong>Datatype choices</strong> (e.g., <strong>FP32</strong>, <strong>BF16</strong>, <strong>FP8</strong>) and the use of <strong>tensor cores</strong> affect both the <strong>peak</strong> and <strong>measured FLOPs/sec</strong>, and thus influence <strong>MFU</strong>.</li>
</ul>

<hr>

<h1 id="gradient-computation-cost-and-the-six-times-rule">Gradient computation cost and the six-times rule</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/00-53-22-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/00-53-22-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/00-53-22-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/00-53-22.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Backpropagation</strong> increases compute cost relative to a <strong>forward pass</strong> because <strong>gradients</strong> require additional <strong>matrix operations</strong> whose dimensions mirror those in the forward path.<br></p>

<p>For typical <strong>dense layers</strong>, the backward work is about <strong>twice</strong> the forward work <strong>per parameter</strong>.<br></p>

<p>Worked example (linear layers):<br></p>
<ol>
  <li>
<strong>Forward pass</strong>: cost ≈ <strong>2 × tokens × parameters</strong>.<br>
</li>
  <li>
<strong>Backward pass (gradients)</strong>: cost ≈ <strong>4 × tokens × parameters</strong>.<br>
</li>
  <li>
<strong>Total per training step</strong>: ≈ <strong>6 × tokens × parameters</strong> — the <strong>six-times multiplier</strong>.<br>
</li>
</ol>

<p>This <strong>six-times multiplier</strong> is a practical rule-of-thumb that captures the <strong>dominant cost</strong> when per-step matrix multiplications touch most parameters, and it’s widely used for <strong>napkin-scale training-time estimates</strong>.<br></p>

<hr>

<h1 id="parameter-objects-and-initialization-best-practices">Parameter objects and initialization best practices</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/01-01-06-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/01-01-06-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/01-01-06-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/01-01-06.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Parameters in PyTorch are represented by <strong>nn.Parameter</strong> objects and <strong>must be initialized</strong> to avoid large variance growth across layers.<br></p>

<p>A naive <strong>i.i.d. Gaussian initialization</strong> yields activation variances that <strong>scale with dimensionality</strong>, which can destabilize training as network width or depth increases.<br></p>

<p>Common remedies and best practices:<br></p>
<ol>
  <li>Use <strong>Xavier-style (Glorot) scaling</strong> — rescale random initial weights by <strong>1/√fan_in</strong> (or an equivalent constant) to keep activation magnitudes <strong>order-one across layers</strong>.<br>
</li>
  <li>Consider <strong>truncated distributions</strong> to limit extreme tail values from the random initializer, reducing outlier weights that harm training stability.<br>
</li>
</ol>

<p>Proper initialization reduces the need for corrective <strong>learning-rate hacking</strong> and improves <strong>numerical stability</strong>, particularly for <strong>deep or wide linear blocks</strong>.</p>

<hr>

<h1 id="deterministic-seeding-and-large-scale-token-data-loading">Deterministic seeding and large-scale token data loading</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/01-05-19-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/01-05-19-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/01-05-19-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/01-05-19.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Reproducibility</strong> requires <strong>deterministic handling</strong> of all <strong>randomness sources</strong>, including:<br></p>
<ul>
  <li>
<strong>parameter initialization</strong><br>
</li>
  <li>
<strong>data ordering</strong><br>
</li>
  <li>
<strong>augmentation</strong><br>
Setting <strong>distinct, fixed seeds</strong> per randomness source enables targeted experiments and simplifies debugging.<br>
</li>
</ul>

<p><strong>Tokenized language datasets</strong> are sequences of integers and can be extremely large (often terabytes).<br>
Use <strong>memory-mapped file access</strong> (e.g., <strong>numpy.memmap</strong>) to expose on-disk data as <strong>array-like objects</strong> without loading full datasets into RAM.<br></p>
<ul>
  <li>This provides efficient, low-memory access to very large token sequences<br>
</li>
  <li>Keeps the dataset accessible via familiar NumPy-style indexing and slicing<br>
</li>
</ul>

<p>To train from memmap-backed data, follow a simple workflow:<br></p>
<ol>
  <li>Create a <strong>numpy.memmap</strong> that points to the tokenized on-disk file.<br>
</li>
  <li>Use a <strong>DataLoader-style sampler</strong> to draw indices or ranges from the memmap.<br>
</li>
  <li>Form minibatches by indexing the memmap with those indices and feed them to the training loop.<br>
This yields training batches while keeping memory usage <strong>bounded</strong> and predictable.</li>
</ol>

<hr>

<h1 id="optimizers-per-parameter-state-and-total-memory-accounting">Optimizers, per-parameter state, and total memory accounting</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/01-09-18-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/01-09-18-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/01-09-18-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/01-09-18.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Optimizers maintain per-parameter auxiliary state</strong> (e.g., <strong>momentum buffers</strong>, <strong>running averages of squared gradients</strong>) that scale with parameter count and must be included in memory budgets.<br></p>

<p>Classic optimizers and their per-parameter state include:<br></p>
<ul>
  <li>
<strong>SGD with momentum</strong> — per-parameter <strong>momentum buffer</strong> (velocity)</li>
  <li>
<strong>Adagrad</strong> — per-parameter <strong>cumulative squared gradients</strong>
</li>
  <li>
<strong>RMSProp</strong> — per-parameter <strong>exponential average of squared gradients</strong>
</li>
  <li>
<strong>Adam</strong> — per-parameter <strong>first and second moment estimates</strong> (mean and squared-mean)<br>
</li>
</ul>

<p>Each algorithm therefore dictates a specific <strong>per-parameter state layout</strong> and corresponding <strong>update rule</strong>, which determines how much extra memory the optimizer requires.<br></p>

<p>Implementations typically maintain a <strong>state dictionary keyed by parameter handles</strong>, so optimizer state is explicitly associated with each parameter.<br></p>

<p><strong>Aggregate memory requirement</strong> (bytes) can be expressed as:<br>
bytes_per_element × (num_parameters + num_gradients + num_optimizer_states + num_activations)<br></p>

<p>Where the terms are:<br></p>
<ul>
  <li>
<strong>num_parameters</strong> — model weights</li>
  <li>
<strong>num_gradients</strong> — gradient tensors (often same size as parameters)</li>
  <li>
<strong>num_optimizer_states</strong> — additional per-parameter buffers required by the optimizer (varies by algorithm)</li>
  <li>
<strong>num_activations</strong> — intermediate activations (depends on batch size and architecture)<br>
</li>
</ul>

<p>Because optimizer states scale with parameter count, <strong>total memory accounting is essential when sizing models for a given device</strong>.</p>

<hr>

<h1 id="activation-storage-checkpointing-training-loop-mixed-precision-and-checkpointing">Activation storage, checkpointing, training loop, mixed precision and checkpointing</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec02/01-15-38-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec02/01-15-38-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec02/01-15-38-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec02/01-15-38.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>By default, <strong>activations</strong> from the <strong>forward pass</strong> are retained to compute gradients in the <strong>backward pass</strong>—storing these activations can often <strong>dominate memory use</strong>.<br></p>

<p><strong>Activation checkpointing</strong> trades extra compute for lower memory by <strong>recomputing intermediate activations on demand</strong> rather than storing them permanently.<br></p>

<p>A typical training loop follows these steps:<br></p>
<ol>
  <li>
<strong>Load batch</strong><br>
</li>
  <li>
<strong>Forward pass</strong> (compute activations and predictions)<br>
</li>
  <li>
<strong>Compute loss</strong><br>
</li>
  <li>
<strong>backward()</strong> (accumulate gradients using retained/recomputed activations)<br>
</li>
  <li>
<strong>optimizer.step()</strong> (update parameters)<br>
</li>
  <li>
<strong>Periodically checkpoint</strong> the <strong>model state</strong>, <strong>optimizer state</strong>, and <strong>iteration count</strong> to disk to protect long-running training progress<br>
</li>
</ol>

<p><strong>Mixed precision training</strong> uses lower-precision formats for transient computation while keeping critical state in higher precision to balance speed and numeric stability:<br></p>
<ul>
  <li>Transient compute formats: <strong>BF16</strong>, <strong>FP16</strong>, <strong>FP8</strong><br>
</li>
  <li>Persistent state kept in <strong>FP32</strong>: <strong>parameters</strong>, <strong>optimizer state</strong><br>
</li>
</ul>

<p>Finally, <strong>aggressive post-training quantization</strong> can be applied for <strong>inference</strong> to obtain additional <strong>efficiency gains</strong> (reduced memory, lower latency, and smaller model size).</p>

<hr>


    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec06/">MIT 6.S184 - Lecture 6 - Diffusion for Protein Generation</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec05/">MIT 6.S184 - Lecture 5 - Diffusion for Robotics</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec04/">MIT 6.S184 - Lecture 4 - Building an Image Generator</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec03/">MIT 6.S184 - Lecture 3 - Training Flow and Diffusion Models</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec02/">MIT 6.S184 - Lecture 2 -  Constructing a Training Target</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
