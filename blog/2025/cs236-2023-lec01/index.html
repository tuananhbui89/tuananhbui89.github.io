<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Stanford CS236 - Deep Generative Models I 2023 I Lecture 1 - Introduction | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="AI Summary Lecture">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2025/cs236-2023-lec01/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->
<!-- Page/Post style -->
<style type="text/css">
  
</style>


<div class="post">

  <header class="post-header">
    <h1 class="post-title">Stanford CS236 - Deep Generative Models I 2023 I Lecture 1 - Introduction</h1>
    <p class="post-meta">December 18, 2025</p>
    <p class="post-tags">
      <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>
        ·  
        <a href="/blog/tag/genai">
          <i class="fas fa-hashtag fa-sm"></i> genai</a>  
          <a href="/blog/tag/llm">
          <i class="fas fa-hashtag fa-sm"></i> llm</a>  
          <a href="/blog/tag/tutorial">
          <i class="fas fa-hashtag fa-sm"></i> tutorial</a>  
          <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#course-introduction-and-goals">Course introduction and goals</a></li>
<li class="toc-entry toc-h1"><a href="#fundamental-challenge-making-sense-of-high-dimensional-sensory-signals">Fundamental challenge: making sense of high-dimensional sensory signals</a></li>
<li class="toc-entry toc-h1"><a href="#generation-as-a-test-of-understanding-feynman-analogy">Generation as a test of understanding (Feynman analogy)</a></li>
<li class="toc-entry toc-h1"><a href="#rendering-inverse-graphics-and-latent-descriptions">Rendering, inverse graphics, and latent descriptions</a></li>
<li class="toc-entry toc-h1"><a href="#statistical-generative-models-and-the-data-versus-prior-spectrum">Statistical generative models and the data-versus-prior spectrum</a></li>
<li class="toc-entry toc-h1"><a href="#probability-distributions-as-generative-simulators-and-sampling">Probability distributions as generative simulators and sampling</a></li>
<li class="toc-entry toc-h1"><a href="#control-signals-and-conditional-generation">Control signals and conditional generation</a></li>
<li class="toc-entry toc-h1"><a href="#applications-medical-imaging-and-inverse-problems">Applications: medical imaging and inverse problems</a></li>
<li class="toc-entry toc-h1"><a href="#historical-progress-in-image-generation-gans-to-diffusion-models">Historical progress in image generation: GANs to diffusion models</a></li>
<li class="toc-entry toc-h1"><a href="#text-to-image-synthesis-and-multimodal-understanding">Text-to-image synthesis and multimodal understanding</a></li>
<li class="toc-entry toc-h1"><a href="#image-editing-sketch-to-image-and-interactive-control">Image editing, sketch-to-image, and interactive control</a></li>
<li class="toc-entry toc-h1"><a href="#image-based-medical-reconstructions-revisited">Image-based medical reconstructions revisited</a></li>
<li class="toc-entry toc-h1"><a href="#audio-generation-and-speech-models">Audio generation and speech models</a></li>
<li class="toc-entry toc-h1"><a href="#large-language-models-and-text-generation">Large language models and text generation</a></li>
<li class="toc-entry toc-h1"><a href="#conditional-generation-for-translation-and-code-synthesis">Conditional generation for translation and code synthesis</a></li>
<li class="toc-entry toc-h1"><a href="#video-generation-and-short-form-synthesis">Video generation and short-form synthesis</a></li>
<li class="toc-entry toc-h1"><a href="#generative-models-for-decision-making-and-imitation-learning">Generative models for decision-making and imitation learning</a></li>
<li class="toc-entry toc-h1"><a href="#generative-design-for-molecules-and-scientific-applications">Generative design for molecules and scientific applications</a></li>
<li class="toc-entry toc-h1"><a href="#risks-misuse-and-deepfakes">Risks, misuse, and deepfakes</a></li>
<li class="toc-entry toc-h1"><a href="#core-course-topics-representation-learning-and-inference">Core course topics: representation, learning, and inference</a></li>
<li class="toc-entry toc-h1"><a href="#models-covered-and-their-trade-offs">Models covered and their trade-offs</a></li>
<li class="toc-entry toc-h1"><a href="#prerequisites-logistics-and-resources">Prerequisites, logistics, and resources</a></li>
<li class="toc-entry toc-h1"><a href="#grading-structure-homeworks-and-project-expectations">Grading structure, homeworks, and project expectations</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <div style="display: flex; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/XZ0PMRWXBEU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
    </iframe>
</div>

<h1 id="course-introduction-and-goals">Course introduction and goals</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-00-41-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-00-41-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-00-41-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-00-41.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>This course provides foundational theory and practice for <strong>deep generative models</strong>, with the objective of teaching how <strong>state-of-the-art generative methods</strong> used in industry and academia actually work.<br></p>

<p>It frames the study around building models that can generate <strong>images, text, and other modalities</strong>, while enabling students to <strong>develop, evaluate, and deploy generative systems</strong>.<br></p>

<p>The curriculum emphasizes the core concepts required to design and improve <strong>generative architectures</strong>, <strong>loss functions</strong>, and <strong>training procedures</strong>.<br></p>

<p>The course situates <strong>generative modeling</strong> as a timely topic with broad practical impact across multiple application domains.<br></p>

<hr>

<h1 id="fundamental-challenge-making-sense-of-high-dimensional-sensory-signals">Fundamental challenge: making sense of high-dimensional sensory signals</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-02-16-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-02-16-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-02-16-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-02-16.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>High-dimensional signals</strong> (images, audio, text) are represented as large arrays or sequences of raw values that often lack immediate semantic structure for decision making.<br></p>

<p>The central challenge is to map these complex objects to <strong>representations</strong> that are useful for downstream tasks such as <strong>recognition, localization, or reasoning</strong>.<br></p>

<p>This requires:</p>
<ul>
  <li>Modeling dependencies across many variables.<br>
</li>
  <li>Extracting abstractions about <strong>objects, materials, motion, and semantics</strong>.<br>
</li>
</ul>

<p><strong>Generative modeling</strong> offers a pathway to capture such structure by learning underlying distributions and <strong>latent factors</strong> that explain observed data.<br></p>

<hr>

<h1 id="generation-as-a-test-of-understanding-feynman-analogy">Generation as a test of understanding (Feynman analogy)</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-03-55-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-03-55-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-03-55-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-03-55.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Generating data</strong> is presented as a principled test of understanding: if a system can produce realistic instances of a concept, it likely captures the concept’s essential structure.<br></p>

<p>This perspective motivates building models that can <strong>synthesize images or text</strong>, since synthesis requires internalizing <strong>grammar, semantics, and common-sense relations</strong>.<br></p>

<p>The contrapositive is informative too: inability to generate realistic data indicates <strong>incomplete understanding</strong>.<br></p>

<p>This philosophical stance underlies the emphasis on generative models as both <strong>explanatory tools</strong> and <strong>practical simulators</strong> for AI.<br></p>

<hr>

<h1 id="rendering-inverse-graphics-and-latent-descriptions">Rendering, inverse graphics, and latent descriptions</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-05-55-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-05-55-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-05-55-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-05-55.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Computer graphics</strong> exemplifies a <strong>forward generative process</strong> that maps high-level scene descriptions (objects, materials, viewpoint) to images; inverting that process gives the interpretation of vision as <strong>inverse graphics</strong>.<br></p>

<p><strong>Statistical generative models</strong> follow a similar structure by defining <strong>latent variables</strong> that encode scene or semantic descriptions which, when rendered, produce observable signals.<br></p>

<p>Inferring latent variables from raw inputs yields representations useful for downstream tasks and provides a conceptual bridge between <strong>graphics-based modeling</strong> and <strong>data-driven probabilistic approaches</strong>.<br></p>

<p>The course focuses on <strong>statistical, data-driven incarnations</strong> of these ideas rather than traditional physics-based renderers.<br></p>

<hr>

<h1 id="statistical-generative-models-and-the-data-versus-prior-spectrum">Statistical generative models and the data-versus-prior spectrum</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-08-10-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-08-10-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-08-10-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-08-10.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Generative models</strong> are formalized as <strong>probability distributions over observations</strong> that combine data-driven learning with prior knowledge (architectural biases, loss choices).<br></p>

<p>There is a spectrum of approaches:</p>
<ul>
  <li>
<strong>Physics-rich modeling</strong> (graphics) on one end.<br>
</li>
  <li>
<strong>Highly data-driven approaches</strong> that minimize hand-designed priors on the other.<br>
</li>
</ul>

<p>Priors manifest in choices such as:</p>
<ul>
  <li>Neural network <strong>architectures</strong> and <strong>inductive biases</strong>.<br>
</li>
  <li>
<strong>Optimization algorithms</strong> and loss formulations.<br>
</li>
</ul>

<p>These priors shape <strong>sample efficiency</strong> and <strong>generalization</strong>. The practical focus is on methods that leverage substantial data to learn flexible probabilistic models for images, text, and other modalities.<br></p>

<hr>

<h1 id="probability-distributions-as-generative-simulators-and-sampling">Probability distributions as generative simulators and sampling</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-10-43-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-10-43-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-10-43-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-10-43.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>A <strong>generative model</strong> defines a function that assigns <strong>probabilities to observations</strong> and can act as a <strong>data simulator</strong> by sampling from the learned distribution.<br></p>

<p>Key points about learning and use:</p>
<ul>
  <li>
<strong>Learning</strong> fits a model distribution so that samples resemble the empirical data distribution.<br>
</li>
  <li>The learned model can be queried for <strong>likelihood-based judgments</strong> to assess how typical or atypical an observation is (useful for outlier detection).<br>
</li>
  <li>In practice, <strong>sampling methods</strong> and the ability to efficiently generate <strong>diverse outputs</strong> are central design concerns.<br>
</li>
</ul>

<hr>

<h1 id="control-signals-and-conditional-generation">Control signals and conditional generation</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-13-42-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-13-42-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-13-42-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-13-42.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Generative models can be <strong>controlled by conditioning</strong> on auxiliary inputs so that sampling produces outputs satisfying user-provided constraints.<br></p>

<p>Examples of control signals:</p>
<ul>
  <li>
<strong>Text captions</strong>, <strong>sketches</strong>, low-resolution or grayscale images, and <strong>sensor measurements</strong>.<br>
</li>
</ul>

<p>Benefits of conditioning:</p>
<ul>
  <li>Enables applications such as <strong>text-to-image synthesis</strong>, <strong>colorization</strong>, and <strong>translation</strong>.<br>
</li>
  <li>Transforms unconstrained sampling into <strong>controlled simulation</strong>, facilitating guided content creation and solving inverse problems.<br>
</li>
</ul>

<p>Implementation note: conditioning is typically incorporated into the <strong>model architecture</strong> and/or the <strong>training objective</strong> to ensure fidelity to the control input.<br></p>

<hr>

<h1 id="applications-medical-imaging-and-inverse-problems">Applications: medical imaging and inverse problems</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-16-10-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-16-10-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-16-10-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-16-10.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Generative models substantially improve <strong>inverse imaging tasks</strong> by encoding priors about plausible signals and enabling reconstruction from limited or noisy measurements.<br></p>

<p>Applications and benefits:</p>
<ul>
  <li>In <strong>medical imaging</strong>, conditional generative models can reconstruct higher-quality CT or MRI images from fewer measurements or lower radiation doses, improving patient safety and throughput.<br>
</li>
  <li>Tasks like <strong>super-resolution</strong>, <strong>denoising</strong>, and <strong>inpainting</strong> are natural inverse problems where learned generative priors supply missing information and enforce global consistency.<br>
</li>
</ul>

<p>These applications illustrate how generative modeling can reduce measurement costs while preserving clinically or operationally relevant details.<br></p>

<hr>

<h1 id="historical-progress-in-image-generation-gans-to-diffusion-models">Historical progress in image generation: GANs to diffusion models</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-18-38-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-18-38-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-18-38-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-18-38.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Image generation quality has advanced rapidly from early low-resolution outputs to <strong>photo-realistic high-resolution images</strong> via successive model classes.<br></p>

<p>Notable model families and their impacts:</p>
<ul>
  <li>
<strong>Generative Adversarial Networks (GANs)</strong> accelerated perceptual realism by optimizing <strong>adversarial training</strong> objectives that favor sample fidelity.<br>
</li>
  <li>
<strong>Score-based diffusion models</strong> and related formulations pushed state-of-the-art further by modeling <strong>score functions</strong> or <strong>denoising processes</strong>, enabling stable, high-fidelity synthesis and principled likelihood interpretations.<br>
</li>
</ul>

<p>Each family introduces trade-offs in <strong>training stability</strong>, <strong>sample quality</strong>, and <strong>likelihood tractability</strong>.<br></p>

<hr>

<h1 id="text-to-image-synthesis-and-multimodal-understanding">Text-to-image synthesis and multimodal understanding</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-21-59-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-21-59-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-21-59-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-21-59.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Modern <strong>diffusion-based generative models</strong> enable conditioning on <strong>natural language</strong> to synthesize coherent, novel images that combine concepts not typically observed together in training data.<br></p>

<p>Key capabilities:</p>
<ul>
  <li>Text-conditioned models learn <strong>joint language-vision representations</strong> that support <strong>compositionality</strong> (e.g., producing an astronaut riding a horse even when the combination is rare).<br>
</li>
  <li>This multimodal capability reflects the model’s ability to internalize <strong>semantics of objects and relations</strong>, underpinning contemporary text-to-image systems used in creative and production settings.<br>
</li>
</ul>

<p>Stochastic sampling from the learned <strong>conditional distribution</strong> yields diverse outputs for a single prompt.<br></p>

<hr>

<h1 id="image-editing-sketch-to-image-and-interactive-control">Image editing, sketch-to-image, and interactive control</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-24-56-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-24-56-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-24-56-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-24-56.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Generative models support diverse <strong>editing interfaces</strong>, including <strong>sketch-to-image refinement</strong>, <strong>stroke-based editing</strong>, and <strong>natural-language-guided transformations</strong>.<br></p>

<p>Practical behaviors:</p>
<ul>
  <li>By conditioning on partial or structured inputs, models can <strong>preserve user-provided layout or content</strong> while rendering photorealistic details and stylistic changes.<br>
</li>
  <li>Applications include <strong>style transfer</strong>, <strong>pose editing</strong>, <strong>object insertion</strong>, and semantic edits (for example, “spread the wings” or “make the birds kiss”).<br>
</li>
</ul>

<p>These conditional editing capabilities rely on architectures and loss functions that balance <strong>adherence to control signals</strong> with <strong>generative realism</strong>.<br></p>

<hr>

<h1 id="image-based-medical-reconstructions-revisited">Image-based medical reconstructions revisited</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-27-11-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-27-11-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-27-11-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-27-11.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>The same conditional generative techniques used for image editing translate to <strong>medical reconstruction tasks</strong>, where device measurements act as conditioning signals.<br></p>

<p>Implications:</p>
<ul>
  <li>Modeling the conditional distribution over plausible medical images given partial sensor measurements permits aggressive measurement reduction (e.g., fewer CT projections) while retaining diagnostically useful reconstructions.<br>
</li>
  <li>This is formally analogous to <strong>inpainting</strong> or <strong>super-resolution</strong> in visual domains and highlights cross-domain applicability of <strong>generative priors</strong>.<br>
</li>
</ul>

<p>Deployment caveat: successful clinical use requires careful validation to ensure <strong>safety</strong> and <strong>robustness to distributional shifts</strong>.<br></p>

<hr>

<h1 id="audio-generation-and-speech-models">Audio generation and speech models</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-29-44-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-29-44-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-29-44-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-29-44.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Generative modeling of <strong>audio</strong>, especially <strong>text-to-speech</strong>, has progressed from <strong>autoregressive waveform models</strong> (e.g., WaveNet) to more recent <strong>diffusion-</strong> and <strong>transformer-based</strong> systems that produce highly realistic, expressive speech.<br></p>

<p>Typical architectures and tasks:</p>
<ul>
  <li>Modern systems often predict sequences of audio tokens or parameters conditioned on text and use <strong>multi-stage architectures</strong> (acoustic model + vocoder) for high fidelity.<br>
</li>
  <li>These models enable inverse audio tasks such as <strong>audio super-resolution</strong> and <strong>restoration</strong> by conditioning on low-quality inputs.<br>
</li>
</ul>

<p>The techniques parallel image-domain methods in modeling <strong>sequential dependence</strong> and leveraging <strong>conditional generation</strong>.<br></p>

<hr>

<h1 id="large-language-models-and-text-generation">Large language models and text generation</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-32-14-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-32-14-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-32-14-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-32-14.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Large language models (LLMs)</strong> model probability distributions over token sequences and generate fluent text via <strong>autoregressive sampling</strong> conditioned on prompts.<br></p>

<p>Key aspects:</p>
<ul>
  <li>Training on massive corpora yields models that capture <strong>grammar, facts, and common-sense regularities</strong>, enabling prompt completion, question answering, translation, and code generation.<br>
</li>
  <li>LLM behavior can be interpreted as learning which continuations of a prompt are <strong>high-probability</strong> under the data distribution; conditioning lets these models perform diverse NLP tasks.<br>
</li>
</ul>

<p>Evaluation emphasizes <strong>coherence</strong>, <strong>factuality</strong>, and <strong>controllability</strong> of generated outputs.<br></p>

<hr>

<h1 id="conditional-generation-for-translation-and-code-synthesis">Conditional generation for translation and code synthesis</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-35-45-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-35-45-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-35-45-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-35-45.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Generative models that condition on <strong>structured or cross-modal inputs</strong> form the basis for <strong>machine translation</strong> and <strong>program synthesis</strong> by mapping between input modalities.<br></p>

<p>Examples:</p>
<ul>
  <li>In <strong>translation</strong>, a model generates target-language text conditioned on source-language input; improvements in generative modeling directly translate to better translation quality.<br>
</li>
  <li>For <strong>code synthesis</strong>, language models trained on code can generate syntactically and semantically coherent program fragments from natural-language descriptions, enabling autocompletion and developer assistance.<br>
</li>
</ul>

<p>These applications illustrate the versatility of <strong>conditional generation</strong> across structured output spaces.<br></p>

<hr>

<h1 id="video-generation-and-short-form-synthesis">Video generation and short-form synthesis</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-39-59-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-39-59-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-39-59-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-39-59.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Video synthesis</strong> treats a video as a temporal stack of image frames and extends image generative methods to capture coherent dynamics across time.<br></p>

<p>Current status and challenges:</p>
<ul>
  <li>Systems produce short, caption-conditioned clips with notable spatial quality and <strong>rudimentary temporal coherence</strong>; stitching or post-processing can extend these primitives to longer narratives.<br>
</li>
  <li>Video generation adds modeling challenges such as <strong>temporal consistency</strong>, <strong>motion modeling</strong>, and <strong>longer-range dependencies</strong>.<br>
</li>
</ul>

<p>Video generation benefits from <strong>multimodal conditioning</strong> (text, seed images, audio) and is an active area of ongoing progress with implications for content creation, simulation, and entertainment.<br></p>

<hr>

<h1 id="generative-models-for-decision-making-and-imitation-learning">Generative models for decision-making and imitation learning</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-42-58-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-42-58-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-42-58-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-42-58.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Generative techniques apply to <strong>sequential decision problems</strong> by modeling distributions over <strong>action sequences</strong> or trajectories that achieve desirable goals.<br></p>

<p>Connections and applications:</p>
<ul>
  <li>In <strong>imitation learning</strong>, models learn to generate behavior conditioned on observations by training on demonstrations, enabling policy synthesis for tasks like driving or manipulation.<br>
</li>
  <li>
<strong>Diffusion formulations</strong> and other generative priors can propose plausible trajectories that respect dynamics and constraints, facilitating planning and control.<br>
</li>
</ul>

<p>This perspective unifies <strong>generative sampling</strong> with <strong>policy generation</strong> and highlights cross-cutting methods between perception and control.<br></p>

<hr>

<h1 id="generative-design-for-molecules-and-scientific-applications">Generative design for molecules and scientific applications</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-45-29-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-45-29-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-45-29-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-45-29.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Generative models are increasingly used to propose <strong>molecular structures, protein sequences, and catalysts</strong> by learning distributions over chemical or biological objects with desirable properties.<br></p>

<p>Approaches and considerations:</p>
<ul>
  <li>Conditioning, <strong>objective-guided sampling</strong>, or <strong>latent-space optimization</strong> enables candidate design that targets binding affinity, structural stability, or catalytic activity.<br>
</li>
  <li>Model families (autoregressive, diffusion, latent-variable) are adapted to <strong>discrete</strong> and <strong>graph-structured</strong> domains, with attention to domain-specific representations and evaluation criteria.<br>
</li>
</ul>

<p>These applications illustrate generative modeling’s potential to accelerate discovery in <strong>chemistry, biology, and materials science</strong>.<br></p>

<hr>

<h1 id="risks-misuse-and-deepfakes">Risks, misuse, and deepfakes</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-48-29-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-48-29-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-48-29-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-48-29.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>High-quality generative systems create realistic synthetic content that can be difficult to distinguish from authentic material, raising concerns about <strong>misuse</strong> such as deepfakes and misinformation.<br></p>

<p>Mitigation strategies include:</p>
<ul>
  <li>Technical <strong>safeguards</strong> and <strong>provenance mechanisms</strong>.<br>
</li>
  <li>
<strong>Detection methods</strong> and complementary <strong>policy interventions</strong>.<br>
</li>
</ul>

<p>Responsible deployment requires evaluating <strong>societal impacts</strong>, understanding <strong>failure modes</strong>, and designing models with <strong>robustness</strong> and <strong>accountability</strong> in mind. Ethical considerations are integral to both research agendas and practical applications in generative modeling.<br></p>

<hr>

<h1 id="core-course-topics-representation-learning-and-inference">Core course topics: representation, learning, and inference</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-50-48-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-50-48-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-50-48-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-50-48.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>The course centers on three interrelated pillars:<br></p>

<ol>
  <li>
<strong>Representation of probability distributions</strong><br>
    <ul>
      <li>Scalable parameterizations of high-dimensional distributions using neural networks.<br>
</li>
      <li>Factorization strategies and latent-variable designs.<br>
</li>
    </ul>
  </li>
  <li>
<strong>Learning methods</strong> for fitting generative models to data<br>
    <ul>
      <li>Objective selection, divergence measures, and optimization methods across model families.<br>
</li>
    </ul>
  </li>
  <li>
<strong>Inference techniques</strong> for sampling and extracting latent representations<br>
    <ul>
      <li>Sampling algorithms, conditional generation, and latent-variable inversion.<br>
</li>
    </ul>
  </li>
</ol>

<p>Mastery of these pillars enables the design and analysis of generative systems across modalities.<br></p>

<hr>

<h1 id="models-covered-and-their-trade-offs">Models covered and their trade-offs</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-52-24-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-52-24-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-52-24-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-52-24.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>The curriculum covers major generative model classes and their trade-offs:<br></p>

<ul>
  <li>
<strong>Autoregressive and flow models</strong> with <strong>tractable likelihoods</strong>.<br>
</li>
  <li>
<strong>Latent-variable models</strong> trained with <strong>variational inference</strong>.<br>
</li>
  <li>
<strong>Implicit models</strong> (e.g., <strong>GANs</strong>) that favor efficient sampling but lack explicit likelihoods.<br>
</li>
  <li>
<strong>Energy-based and diffusion models</strong> that offer strong sample quality and theoretical connections.<br>
</li>
</ul>

<p>Each family exhibits different properties in terms of <strong>expressivity</strong>, <strong>ease of training</strong>, <strong>sampling efficiency</strong>, and <strong>likelihood access</strong>. The course examines training criteria (e.g., <strong>maximum likelihood</strong>, <strong>adversarial losses</strong>, <strong>score matching</strong>) and evaluation metrics appropriate to each class.<br></p>

<hr>

<h1 id="prerequisites-logistics-and-resources">Prerequisites, logistics, and resources</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-54-11-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-54-11-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-54-11-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-54-11.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Successful participation requires familiarity with:</p>
<ul>
  <li>
<strong>Basic probability, calculus, and linear algebra</strong>.<br>
</li>
  <li>Core <strong>machine learning concepts</strong>.<br>
</li>
  <li>Programming proficiency in <strong>Python</strong> and experience with deep learning frameworks such as <strong>PyTorch</strong>.<br>
</li>
</ul>

<p>Course support and resources:</p>
<ul>
  <li>Lecture notes and reading references (including the <strong>Deep Learning</strong> book).<br>
</li>
  <li>Staff support via teaching assistants and office hours; students should monitor the course website for updates.<br>
</li>
</ul>

<p>Background materials and review content are provided, but substantial prior exposure to <strong>probabilistic modeling</strong> and <strong>optimization</strong> is recommended. Practical assignments and projects require computational resources and basic cloud familiarity.<br></p>

<hr>

<h1 id="grading-structure-homeworks-and-project-expectations">Grading structure, homeworks, and project expectations</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs236-2023/frames/lec01/00-56-16-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs236-2023/frames/lec01/00-56-16-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs236-2023/frames/lec01/00-56-16-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs236-2023/frames/lec01/00-56-16.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Assessments include:</p>
<ul>
  <li>Multiple homework assignments combining <strong>theory</strong> and <strong>programming</strong>.<br>
</li>
  <li>An in-person <strong>midterm</strong>.<br>
</li>
  <li>A substantial <strong>team-based project</strong> that constitutes a significant portion of the grade.<br>
</li>
</ul>

<p>Project structure and deliverables:</p>
<ol>
  <li>
<strong>Proposal</strong><br>
</li>
  <li>
<strong>Progress report</strong><br>
</li>
  <li>
<strong>Poster</strong><br>
</li>
  <li>
<strong>Final report</strong><br>
</li>
</ol>

<p>Projects typically involve applying or extending generative models to new datasets, comparing methods, or contributing methodological improvements. The project emphasizes hands-on experimentation, potential for publishable results, and exploration of open research questions. Limited cloud credits and suggested project ideas are made available to support student work.<br></p>

<hr>


    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec06/">MIT 6.S184 - Lecture 6 - Diffusion for Protein Generation</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec05/">MIT 6.S184 - Lecture 5 - Diffusion for Robotics</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec04/">MIT 6.S184 - Lecture 4 - Building an Image Generator</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec03/">MIT 6.S184 - Lecture 3 - Training Flow and Diffusion Models</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec02/">MIT 6.S184 - Lecture 2 -  Constructing a Training Target</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
