<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>CS336 Lecture 14 - Data - Part 2 | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="AI Summary of CS336 Lecture">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2025/cs336-lec14/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->
<!-- Page/Post style -->
<style type="text/css">
  
</style>


<div class="post">

  <header class="post-header">
    <h1 class="post-title">CS336 Lecture 14 - Data - Part 2</h1>
    <p class="post-meta">December 8, 2025</p>
    <p class="post-tags">
      <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>
        ·  
        <a href="/blog/tag/genai">
          <i class="fas fa-hashtag fa-sm"></i> genai</a>  
          <a href="/blog/tag/llm">
          <i class="fas fa-hashtag fa-sm"></i> llm</a>  
          <a href="/blog/tag/tutorial">
          <i class="fas fa-hashtag fa-sm"></i> tutorial</a>  
          <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#lecture-overview-and-objectives">Lecture overview and objectives</a></li>
<li class="toc-entry toc-h1"><a href="#filtering-primitive-target-set-selection-from-raw-data">Filtering primitive: target set selection from raw data</a></li>
<li class="toc-entry toc-h1"><a href="#n-gram-statistical-language-models-for-fast-scoring">N-gram (statistical) language models for fast scoring</a></li>
<li class="toc-entry toc-h1"><a href="#using-n-gram-perplexity-for-dataset-filtering-ccnet-example">Using n-gram perplexity for dataset filtering (CCNet example)</a></li>
<li class="toc-entry toc-h1"><a href="#fasttext-linear-classifiers-with-hashed-n-gram-features-for-filtering">FastText linear classifiers with hashed n-gram features for filtering</a></li>
<li class="toc-entry toc-h1"><a href="#importance-resampling-and-distributional-data-selection">Importance resampling and distributional data selection</a></li>
<li class="toc-entry toc-h1"><a href="#unified-scoring-recipe-for-model-based-filtering">Unified scoring recipe for model-based filtering</a></li>
<li class="toc-entry toc-h1"><a href="#limitations-of-local-statistical-filters-and-adversarial-risks">Limitations of local statistical filters and adversarial risks</a></li>
<li class="toc-entry toc-h1"><a href="#language-identification-with-fasttext-for-corpus-selection">Language identification with FastText for corpus selection</a></li>
<li class="toc-entry toc-h1"><a href="#domain-specific-data-curation-case-study-openwebmath">Domain-specific data curation case study: OpenWebMath</a></li>
<li class="toc-entry toc-h1"><a href="#quality-filtering-strategies-and-synthetic-labeling">Quality filtering strategies and synthetic labeling</a></li>
<li class="toc-entry toc-h1"><a href="#toxicity-filtering-with-annotated-datasets-and-lightweight-classifiers">Toxicity filtering with annotated datasets and lightweight classifiers</a></li>
<li class="toc-entry toc-h1"><a href="#deduplication-exact-and-near-duplicate-categories-and-motivations">Deduplication: exact and near-duplicate categories and motivations</a></li>
<li class="toc-entry toc-h1"><a href="#design-space-and-hashing-primitives-for-scalable-deduplication">Design space and hashing primitives for scalable deduplication</a></li>
<li class="toc-entry toc-h1"><a href="#bloom-filter-approximate-set-membership-for-exact-duplication-detection">Bloom filter approximate set membership for exact-duplication detection</a></li>
<li class="toc-entry toc-h1"><a href="#similarity-measures-minhash-and-probabilistic-reduction-of-jaccard">Similarity measures, MinHash and probabilistic reduction of Jaccard</a></li>
<li class="toc-entry toc-h1"><a href="#locality-sensitive-hashing-lsh-with-banding-to-amplify-thresholds">Locality-Sensitive Hashing (LSH) with banding to amplify thresholds</a></li>
<li class="toc-entry toc-h1"><a href="#practical-considerations-embeddings-for-paraphrase-sensitive-deduplication-and-duplicate-handling-policies">Practical considerations: embeddings for paraphrase-sensitive deduplication and duplicate handling policies</a></li>
<li class="toc-entry toc-h1"><a href="#lecture-summary-and-next-steps">Lecture summary and next steps</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <div style="display: flex; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/9Cd0THLS1t0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
    </iframe>
</div>

<h1 id="lecture-overview-and-objectives">Lecture overview and objectives</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-00-46-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-00-46-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-00-46-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-00-46.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>This lecture presents a detailed treatment of <strong>data collection</strong>, <strong>preprocessing</strong>, <strong>quality filtering</strong>, and <strong>deduplication</strong> techniques used to prepare <strong>large web-scale corpora</strong> for <strong>language model training</strong>.<br></p>

<p>It frames the problem as extracting a <strong>high-quality target subset</strong> from massive raw sources and outlines the lecture plan:<br></p>

<ol>
  <li>
<strong>Review model-based filtering algorithms</strong> — survey approaches that score or classify documents for inclusion.<br>
</li>
  <li>
<strong>Show how a single primitive supports multiple filtering tasks</strong> — demonstrate reuse of core operations across different filters.<br>
</li>
  <li>
<strong>Describe algorithms for exact and near-duplicate detection</strong> — cover methods for identifying identical and similar documents at scale.<br>
</li>
</ol>

<p>The discussion emphasizes practical constraints:</p>
<ul>
  <li>
<strong>Compute cost</strong> and the need to minimize expensive operations<br>
</li>
  <li>
<strong>Scalability to web-scale data</strong> and engineering trade-offs for throughput and storage<br>
</li>
  <li>Preference for <strong>fast, approximate methods</strong> over costly <strong>per-document model inference</strong> when processing billions of documents<br>
</li>
</ul>

<p>The presentation positions the material as <strong>algorithmic building blocks</strong> for <strong>production data pipelines</strong>, not a purely theoretical treatment — focusing on techniques that are practical, efficient, and deployable at web scale.<br></p>

<hr>

<h1 id="filtering-primitive-target-set-selection-from-raw-data">Filtering primitive: target set selection from raw data</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-02-06-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-02-06-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-02-06-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-02-06.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Filtering for model training is cast as selecting a subset <strong>T’</strong> from a large raw dataset <strong>R</strong> that is similar to a small, high-quality target dataset <strong>T</strong>.<br>
The primitive must <strong>generalize beyond exact copies of T</strong> and execute at <strong>web-scale</strong> under strict performance constraints.<br></p>

<p>The selection workflow (typical implementation):<br></p>
<ol>
  <li>Fit one or more <strong>models</strong> on <strong>T</strong> and/or <strong>R</strong> to capture relevance or quality signals.<br>
</li>
  <li>Use those models to produce a <strong>per-document score</strong> (the <strong>scoring function</strong>).<br>
</li>
  <li>Convert scores into a subset <strong>T’</strong> via <strong>thresholding</strong> or <strong>stochastic sampling</strong>.<br>
</li>
</ol>

<p>Two primary operational requirements:<br></p>
<ul>
  <li>
<strong>Statistical generalization</strong> from a limited <strong>T</strong> — the filter must identify useful, non-identical examples that match the target distribution.<br>
</li>
  <li>
<strong>Computational efficiency</strong> sufficient to process <strong>billions of web documents</strong> — the method must meet strict throughput and cost constraints.<br>
</li>
</ul>

<p>These requirements drive the compute vs. selection-quality trade-off:<br></p>
<ul>
  <li>
<strong>Lightweight statistical models</strong> — low compute, fast at scale, sometimes weaker selection fidelity.<br>
</li>
  <li>
<strong>Linear classifiers</strong> — middle ground in cost and accuracy for many problems.<br>
</li>
  <li>
<strong>Neural methods</strong> — higher selection quality but much higher compute and infrastructure demands.<br>
</li>
</ul>

<p>The filtering abstraction therefore guides method choice by balancing <strong>selection quality</strong> against <strong>scalability and cost</strong> for web-scale dataset curation.<br></p>

<hr>

<h1 id="n-gram-statistical-language-models-for-fast-scoring">N-gram (statistical) language models for fast scoring</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-04-01-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-04-01-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-04-01-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-04-01.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>N-gram language models</strong> estimate token <strong>conditional probabilities</strong> by counting <strong>n-gram</strong> occurrences and normalizing by <strong>(n−1)-gram</strong> context counts—this yields a <strong>maximum likelihood estimate</strong> for local sequential structure.<br></p>

<ol>
  <li>Count occurrences of each <strong>n-gram</strong>.</li>
  <li>Divide by the count of the corresponding <strong>(n−1)-gram</strong> context to obtain the conditional probability.<br>
This is the MLE for short-range dependencies.<br>
</li>
</ol>

<p>Practical implementations use <strong>smoothing/backoff</strong> or <strong>interpolation</strong> to address data sparsity as n grows:</p>
<ul>
  <li>Common techniques include <strong>Kneser–Ney</strong> and <strong>CANLM</strong>.</li>
  <li>These methods enable <strong>nonzero probability</strong> for unseen n-grams by leveraging <strong>lower-order statistics</strong> (e.g., backing off to smaller n).<br>
</li>
</ul>

<p>Advantages:</p>
<ul>
  <li>
<strong>Computationally efficient</strong> to train and evaluate relative to large neural models.</li>
  <li>Produce per-document <strong>perplexity</strong> scores that serve as a proxy for how well data matches a target corpus.<br>
</li>
</ul>

<p>Limitations:</p>
<ul>
  <li>
<strong>Myopic locality</strong> — evaluates only short contexts, so long-range dependencies are not captured.</li>
  <li>Vulnerable to <strong>adversarially constructed high-probability but low-quality</strong> examples.</li>
  <li>
<strong>Reduced expressivity</strong> compared with <strong>contextual neural models</strong>, which can model richer, longer-range structure.</li>
</ul>

<hr>

<h1 id="using-n-gram-perplexity-for-dataset-filtering-ccnet-example">Using n-gram perplexity for dataset filtering (CCNet example)</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-06-48-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-06-48-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-06-48-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-06-48.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Perplexity</strong> computed from an <strong>n-gram model</strong> provides a scalar quality score for paragraphs or documents.<br>
<strong>Low perplexity</strong> indicates a high likelihood under the target distribution and is commonly used to rank raw text data.<br></p>

<p>A practical pipeline for filtering text by perplexity typically works as follows:<br></p>
<ol>
  <li>Score each passage with an <strong>n-gram perplexity</strong> measure.<br>
</li>
  <li>Sort passages by <strong>increasing perplexity</strong> (lower = better).<br>
</li>
  <li>Retain a top fraction of passages (e.g., the top one‑third) as training data or a curated corpus.<br>
</li>
</ol>

<p>This simple heuristic has been effective for creating domain-aligned corpora such as <strong>CCNet</strong> and early <strong>LLaMA</strong> training splits.<br></p>

<p>Example outcomes and caveats:<br></p>
<ul>
  <li>Well-formed <strong>Wikipedia</strong> content generally receives <strong>relatively low perplexity</strong>.<br>
</li>
  <li>
<strong>Gibberish</strong> or badly formed text typically receives <strong>very high perplexity</strong>.<br>
</li>
  <li>However, there are <strong>edge-cases</strong> caused by <strong>n-gram limitations</strong> where scores can mislead (e.g., rare but valid constructions or repeated local patterns).<br>
</li>
</ul>

<p>Practical trade-offs:<br></p>
<ul>
  <li>Principal benefit: <strong>speed and simplicity</strong> — easy to compute at corpus scale and cheap to apply.<br>
</li>
  <li>Principal drawback: <strong>coarseness</strong> and susceptibility to <strong>local-context artifacts</strong>, which can lead to misranking in some cases.</li>
</ul>

<hr>

<h1 id="fasttext-linear-classifiers-with-hashed-n-gram-features-for-filtering">FastText linear classifiers with hashed n-gram features for filtering</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-10-56-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-10-56-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-10-56-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-10-56.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>FastText</strong> implements a <strong>near-linear bag-of-(hashed)-n-grams classifier</strong> that maps <strong>high-dimensional sparse token/ngram feature vectors</strong> into a <strong>lower-dimensional embedding space</strong>, then applies a <strong>linear classifier</strong>—yielding a fast and memory-efficient text classifier.<br></p>

<ul>
  <li>
<strong>Hashed n-grams</strong>: Hashing n-grams into a <strong>fixed number of bins</strong> (e.g., <strong>10 million</strong>) bounds vocabulary growth and controls model size.<br>
    <ul>
      <li>
<strong>Collisions</strong> occur, but are often tolerable in aggregate learning and are <strong>implicitly handled by optimization</strong>.<br>
</li>
    </ul>
  </li>
  <li>
    <p><strong>Embedding + linear classification</strong>: The model projects sparse token/ngram features into a compact embedding space and runs a linear classifier from that space, enabling both <strong>speed</strong> and <strong>memory efficiency</strong> without storing massive vocabularies.<br></p>
  </li>
  <li>
    <p><strong>Use cases and scaling</strong>: The architecture scales well for <strong>binary or multi-class filtering tasks</strong> (e.g., <strong>language ID</strong>, <strong>quality</strong>, <strong>toxicity</strong>) and is especially attractive when throughput and resource constraints matter.<br></p>
  </li>
  <li>
    <p><strong>Expressiveness vs speed trade-off</strong>: FastText trades some expressive power for <strong>orders-of-magnitude speed improvements</strong> compared to <strong>deep contextual models</strong>.<br></p>
  </li>
  <li>
<strong>Practical pipeline trade-off</strong>: The central decision for filtering pipelines is <strong>compute per-example versus selection quality</strong>:
    <ol>
      <li>
<strong>Faster linear models</strong> let you process vastly more raw data for the same compute budget.<br>
</li>
      <li>
<strong>Larger or deeper models</strong> increase per-document cost and may be suboptimal if compute is limited relative to data volume.<br>
</li>
    </ol>
  </li>
</ul>

<hr>

<h1 id="importance-resampling-and-distributional-data-selection">Importance resampling and distributional data selection</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-16-23-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-16-23-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-16-23-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-16-23.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Importance resampling</strong> treats the target as a distribution <strong>P</strong> and the raw dataset as a proposal distribution <strong>Q</strong>, estimating <strong>importance weights w(x) = P(x)/Q(x)</strong> to resample raw items proportionally to how well they match the target distribution.<br></p>

<p>When the target dataset is too small to fit a full generative model, lightweight <strong>hashed n-gram probability estimators</strong> or other tractable <strong>density approximations</strong> are used to estimate <strong>P</strong> and <strong>Q</strong>, producing <strong>per-document weights</strong> that prioritize <strong>diversity</strong> and <strong>distributional matching</strong> rather than binary classification.<br></p>

<p>How it works (high-level steps):<br></p>
<ol>
  <li>Estimate the target density <strong>P(x)</strong> and the proposal density <strong>Q(x)</strong> (e.g., with hashed unigram/ngram models or small generative approximations).<br>
</li>
  <li>Compute <strong>importance weights w(x) = P(x)/Q(x)</strong> for each raw item/document.<br>
</li>
  <li>Resample items proportionally to those weights to produce a dataset that better matches the target distribution.<br>
</li>
</ol>

<p>Key properties and trade-offs:<br></p>
<ul>
  <li>Provides a <strong>theoretical grounding</strong> for sampling data that matches a desired target distribution.<br>
</li>
  <li>Often yields better <strong>diversity</strong> and smoother <strong>distributional matching</strong> than discriminative <strong>accept/reject classifiers</strong>.<br>
</li>
  <li>Requires <strong>reliable density estimates or approximations</strong>; performance depends on the quality of P and Q estimators.<br>
</li>
</ul>

<p>Practical notes:<br></p>
<ul>
  <li>Common implementations use <strong>hashed unigram/ngram models</strong> or small, tractable generative approximations to estimate densities.<br>
</li>
  <li>The resulting <strong>resampled datasets</strong> are typically fed into downstream model training to better align training data with the target distribution.<br>
</li>
</ul>

<hr>

<h1 id="unified-scoring-recipe-for-model-based-filtering">Unified scoring recipe for model-based filtering</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-20-26-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-20-26-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-20-26-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-20-26.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>All practical filtering approaches share a common pipeline:<br></p>

<ol>
  <li>
<strong>Estimate models or scoring functions</strong> from <strong>T</strong> and/or <strong>R</strong>.<br>
</li>
  <li>
<strong>Compute a per-document score</strong> using those models.<br>
</li>
  <li>
<strong>Retain documents</strong> based on a <strong>threshold</strong> or <strong>probabilistic sampling rule</strong> to form <strong>T’</strong>.<br>
</li>
</ol>

<p><strong>Scoring functions</strong> can take several forms:<br></p>
<ul>
  <li>
<strong>Generative</strong> — use <strong>per-token probability</strong> or <strong>perplexity</strong> as the score.<br>
</li>
  <li>
<strong>Discriminative</strong> — estimate the <strong>probability that a sample comes from T rather than R</strong>.<br>
</li>
  <li>
<strong>Importance weights</strong> — use the <strong>ratio of two generative models</strong>.<br>
Each approach produces different trade-offs for <strong>diversity</strong> and <strong>precision</strong>.<br>
</li>
</ul>

<p><strong>Thresholding</strong> strategies:<br></p>
<ul>
  <li>
<strong>Deterministic thresholding</strong> — apply a fixed cutoff to retain items.<br>
</li>
  <li>
<strong>Stochastic thresholding</strong> — sample around the cutoff to control dataset <strong>size</strong> and <strong>variance</strong>.<br>
</li>
</ul>

<p>All methods benefit from improved <strong>modeling fidelity</strong> (for example, <strong>higher-order n-grams</strong> or <strong>neural models</strong>) within available compute constraints.<br></p>

<p>This abstraction enables <strong>interchangeable implementation choices</strong> across languages, domains, and quality objectives, while emphasizing <strong>scalability</strong> and <strong>reproducibility</strong>.<br></p>

<hr>

<h1 id="limitations-of-local-statistical-filters-and-adversarial-risks">Limitations of local statistical filters and adversarial risks</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-22-43-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-22-43-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-22-43-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-22-43.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Local-context filters</strong>, such as <strong>n-gram models</strong>, primarily evaluate <strong>short-range coherence</strong> and <strong>grammaticality</strong>—so they can be <strong>gamed</strong> by manipulations that preserve local statistics but break overall quality.<br></p>

<ul>
  <li>Examples of attacks or failure modes:
    <ul>
      <li>
<strong>Reorderings</strong> that keep n-gram counts but destroy document-level flow</li>
      <li>
<strong>Paraphrases</strong> that change global meaning while retaining local patterns</li>
      <li>
<strong>Adversarially constructed sequences</strong> that preserve n-gram statistics yet lack <strong>global coherence</strong> or <strong>factual correctness</strong><br>
</li>
    </ul>
  </li>
</ul>

<p>Increasing <strong>n</strong> makes these filters more sensitive to larger context, but this comes with clear trade-offs:<br></p>
<ol>
  <li>Benefit: better sensitivity to <strong>larger context</strong> and reduced susceptibility to some local attacks.</li>
  <li>Cost: rapidly increasing <strong>sparsity</strong> and <strong>compute costs</strong> as n grows.<br>
</li>
</ol>

<p>By contrast, <strong>discriminative classifiers</strong> trained on <strong>higher-level features</strong> or <strong>neural representations</strong> can capture more semantics and detect issues beyond local patterns.<br></p>
<ul>
  <li>Pros: better at modeling document-level meaning and factual inconsistencies</li>
  <li>Cons: substantially <strong>costlier to run at web scale</strong> and harder to deploy as a first-pass filter<br>
</li>
</ul>

<p>In practice, teams combine these tools pragmatically:<br></p>
<ul>
  <li>Use <strong>model-based filters</strong> (including n-gram checks) to remove <strong>gross nonsense</strong> and obviously low-quality pages</li>
  <li>Tolerate some residual errors or address them via <strong>downstream curation</strong> and <strong>human evaluation</strong><br>
</li>
</ul>

<p>The engineering posture is a pragmatic trade-off: balance the risks of <strong>false accepts</strong> and <strong>false rejects</strong> against available <strong>processing capacity</strong> and the intended role of the filtered data in <strong>training pipelines</strong>.</p>

<hr>

<h1 id="language-identification-with-fasttext-for-corpus-selection">Language identification with FastText for corpus selection</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-26-24-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-26-24-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-26-24-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-26-24.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Language identification</strong> is a focused application of <strong>model-based filtering</strong>: a <strong>classifier</strong> predicts document language and filters raw data to a target language to conserve compute and improve per-language performance.<br></p>

<ul>
  <li>
<strong>FastText</strong> provides <strong>pre-trained multi-language classifiers</strong> that operate on <strong>hashed n-gram features</strong>.<br>
</li>
  <li>These classifiers produce <strong>per-document language probabilities</strong> that can be <strong>thresholded</strong> (e.g., keep English if P(English) &gt; 0.5) to construct <strong>monolingual corpora</strong>.<br>
</li>
</ul>

<p><strong>Practical workflow:</strong><br></p>
<ol>
  <li>Run the classifier to obtain <strong>per-document language probabilities</strong>.<br>
</li>
  <li>Apply a <strong>threshold</strong> to decide inclusion (example: keep if P(target) &gt; 0.5).<br>
</li>
  <li>Add <strong>post-processing heuristics</strong> and tune thresholds based on <strong>sentence length</strong> and <strong>domain</strong> to reduce false positives/negatives.<br>
</li>
</ol>

<p><strong>Challenges and limitations:</strong><br></p>
<ul>
  <li>
<strong>Short sentences</strong>, <strong>code-mixed text</strong>, <strong>dialects</strong>, and <strong>low-resource languages</strong> reduce automatic language ID reliability.<br>
</li>
  <li>Thresholds and heuristics must be tuned for <strong>sentence length</strong> and <strong>domain</strong> to maintain precision.<br>
</li>
</ul>

<p><strong>Why this matters:</strong><br></p>
<ul>
  <li>
<strong>Language-specific filtering</strong> prevents dilution of the compute budget across unwanted languages.<br>
</li>
  <li>It is especially important in <strong>compute-limited multilingual training regimes</strong> where focusing resources on target languages improves per-language performance.<br>
</li>
</ul>

<hr>

<h1 id="domain-specific-data-curation-case-study-openwebmath">Domain-specific data curation case study: OpenWebMath</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-29-37-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-29-37-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-29-37-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-29-37.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>OpenWebMath</strong> demonstrates targeted <strong>domain curation</strong> by treating <strong>mathematical writing</strong> as a distinct style and building a specialized corpus through a multi-stage pipeline.<br></p>

<ol>
  <li>
<strong>Rule-based prefilters</strong>: apply syntactic heuristics to identify obvious mathematical content.<br>
</li>
  <li>
<strong>Perplexity-based selection</strong>: use a <strong>CANLM</strong> model trained on a proof dataset (<strong>ProofPile</strong>) to score documents by how well they fit mathematical language patterns.<br>
</li>
  <li>
<strong>Discriminative classification</strong>: run a <strong>FastText</strong> classifier trained specifically to identify mathematical text and refine selection.<br>
</li>
  <li>
<strong>Adaptive thresholds</strong>: set different acceptance thresholds depending on whether a document passed the rule-based math identification, yielding stricter or looser inclusion criteria as appropriate.<br>
</li>
</ol>

<ul>
  <li>These steps combine <strong>syntactic heuristics</strong>, <strong>n-gram density models</strong> (via CANLM), and <strong>discriminative classification</strong> to efficiently gather domain data.<br>
</li>
  <li>The result is a <strong>curated corpus of high-density mathematical content</strong> (e.g., <strong>15 billion tokens</strong>) that is highly focused compared with generic web-scale corpora.<br>
</li>
</ul>

<p>Impact and takeaways:<br></p>
<ul>
  <li>Training on this targeted corpus yields <strong>significant downstream improvements on math-specific tasks</strong> compared with training on much larger generic corpora.<br>
</li>
  <li>The case illustrates that combining simple heuristics with language-model scoring and fast classifiers can produce <strong>data-efficient</strong> collections for specialized models.<br>
</li>
  <li>Effective domain curation improves <strong>sample efficiency</strong> and <strong>task performance</strong>, especially when <strong>model capacity</strong> and <strong>compute</strong> are constrained.</li>
</ul>

<hr>

<h1 id="quality-filtering-strategies-and-synthetic-labeling">Quality filtering strategies and synthetic labeling</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-32-48-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-32-48-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-32-48-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-32-48.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Quality filtering is implemented via <strong>positive/negative examples</strong> drawn from <strong>curated sources (positives)</strong> and <strong>broad web crawl (negatives)</strong> to train classifiers that score documents by <strong>educational value</strong>, <strong>textbook-like quality</strong>, or <strong>topical relevance</strong>.<br></p>

<p>Approaches include:<br></p>
<ul>
  <li>Training <strong>linear classifiers</strong> on high-quality sources (for example, <strong>non-CommonCrawl</strong> content and <strong>Wikipedia-referenced pages</strong>).<br>
</li>
  <li>Using <strong>synthesized labeled sets</strong> generated by a strong model (e.g., <strong>prompting GPT-4</strong> to label documents) to produce training data for a fast downstream classifier (for example, a <strong>random forest</strong> on <strong>precomputed embeddings</strong>).<br>
</li>
</ul>

<p>This is commonly organized as a <strong>two-stage distillation</strong> process:<br></p>
<ol>
  <li>A <strong>large model</strong> (teacher) labels or ranks documents to produce high-quality semantic labels.<br>
</li>
  <li>A <strong>lightweight classifier</strong> (student) is trained on those labels and precomputed features to enable <strong>high-throughput</strong>, low-cost inference.<br>
</li>
</ol>

<p>Benefits:<br></p>
<ul>
  <li>Enables <strong>high-throughput filtering</strong> while preserving stronger <strong>semantic criteria</strong> than simple heuristics.<br>
</li>
  <li>Keeps <strong>inference costs low</strong> by deploying efficient downstream classifiers.<br>
</li>
  <li>Empirical results indicate this approach can substantially improve <strong>downstream training efficiency</strong> and <strong>evaluation metrics</strong> on specialized tasks compared with <strong>unfiltered</strong> or <strong>naively curated</strong> data.<br>
</li>
</ul>

<hr>

<h1 id="toxicity-filtering-with-annotated-datasets-and-lightweight-classifiers">Toxicity filtering with annotated datasets and lightweight classifiers</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-36-10-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-36-10-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-36-10-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-36-10.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Toxicity filtering</strong> uses curated, labeled datasets to train classifiers that detect unwanted content categories.<br></p>

<ul>
  <li>Common datasets: <strong>Jigsaw Toxic Comments</strong> (and similar curated corpora).<br>
</li>
  <li>Typical labeled categories: <strong>toxic</strong>, <strong>severe toxic</strong>, <strong>obscene</strong>, <strong>threat</strong>, <strong>insult</strong>, <strong>hate speech</strong>.<br>
</li>
</ul>

<p><strong>Lightweight classifiers</strong> (for example, <strong>FastText</strong>) are commonly trained on these labels to produce <strong>per-document probabilities</strong> for each safety-related category—enabling efficient, large-scale screening of web data.<br></p>

<ol>
  <li>
<strong>Train</strong> on curated labeled data to predict the target safety categories and output per-document probability scores.<br>
</li>
  <li>
<strong>Apply</strong> models at scale to remove or downweight content that exceeds predefined thresholds.<br>
</li>
  <li>
<strong>Mitigate</strong> remaining risk by combining automated flags with human review, rule-based checks, and post-hoc mitigation strategies.<br>
</li>
</ol>

<p>Practical deployments usually set <strong>conservative thresholds</strong> to prioritize reducing unsafe content while acknowledging classifier limitations:<br></p>

<ul>
  <li>Classifier imperfections are common on <strong>short utterances</strong>.<br>
</li>
  <li>Performance degrades with <strong>ambiguous context</strong>.<br>
</li>
  <li>Labels and judgments can vary due to <strong>cultural variance in annotations</strong>.<br>
</li>
</ul>

<p>Overall, toxicity filters are one component of a broader <strong>content-safety pipeline</strong> and are typically integrated with human oversight, deterministic rules, and additional mitigation layers to achieve robust safety outcomes.</p>

<hr>

<h1 id="deduplication-exact-and-near-duplicate-categories-and-motivations">Deduplication: exact and near-duplicate categories and motivations</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-39-23-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-39-23-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-39-23-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-39-23.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Deduplication</strong> addresses both <strong>exact duplicates</strong> (identical content mirrored across URLs) and <strong>near-duplicates</strong> (texts differing by a few tokens due to copies, edits, or templating) that otherwise waste <strong>training tokens</strong> and increase <strong>memorization</strong> risk.<br></p>

<p><strong>Exact duplicates</strong> often arise from <strong>site mirroring</strong> and <strong>distributed hosting</strong>, producing enormous redundant repetition of identical text that <strong>distorts sampling during pretraining</strong> and overweights repeated content.<br></p>

<p><strong>Near-duplicates</strong> include <strong>license text</strong>, <strong>templated pages</strong>, and <strong>lightly edited copies</strong> — these variations provide little additional signal despite consuming tokens.<br></p>

<p>Removing or downsampling duplicates improves <strong>training efficiency</strong> and helps mitigate <strong>memorization-related risks</strong> (e.g., <strong>copyright leakage</strong>, <strong>privacy</strong>), while still allowing sufficient repetition for <strong>mid-training regimes</strong> where multiple epochs over high-quality sources may be desired.<br></p>

<p>Key <strong>deduplication design choices</strong>:<br></p>
<ul>
  <li>
<strong>Unit of comparison</strong> — choose the granularity to compare: <strong>sentence</strong>, <strong>paragraph</strong>, or <strong>document</strong>.<br>
</li>
  <li>
<strong>Matching criterion</strong> — decide between <strong>exact match</strong> or a <strong>similarity threshold</strong> for near-duplicate detection.<br>
</li>
  <li>
<strong>Action</strong> — determine the post-match policy: <strong>keep one instance</strong>, <strong>cap counts</strong>, or apply other downsampling rules.<br>
</li>
</ul>

<hr>

<h1 id="design-space-and-hashing-primitives-for-scalable-deduplication">Design space and hashing primitives for scalable deduplication</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-43-57-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-43-57-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-43-57-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-43-57.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Scalable deduplication</strong> requires converting expensive <strong>pairwise similarity comparisons</strong> into fast <strong>unary operations</strong> via <strong>hashing</strong>—hash functions map items to compact values that enable grouping and approximate membership queries instead of performing quadratic pairwise comparisons.<br></p>

<p><strong>Hash-family tradeoffs:</strong><br></p>
<ul>
  <li>
<strong>Cryptographic hashes</strong>: minimize collision probability but are relatively <strong>slow</strong>.<br>
</li>
  <li>
<strong>Non-cryptographic hashes</strong> (e.g., <strong>MurmurHash</strong>): much <strong>faster</strong> and typically <strong>sufficient</strong> for large-scale deduplication tasks, at the cost of a higher collision probability.<br>
</li>
</ul>

<p><strong>Exact deduplication pipeline (MapReduce-style):</strong><br></p>
<ol>
  <li>
<strong>Canonicalize items</strong> so equivalent records have the same normalized form.<br>
</li>
  <li>Compute a <strong>hash</strong> for each canonicalized item.<br>
</li>
  <li>
<strong>Group items into hash bins</strong> by their hash value (shuffle stage).<br>
</li>
  <li>Keep a <strong>single representative per bin</strong> (reduce stage).<br>
This yields a <strong>high-precision</strong>, <strong>parallelizable</strong> pipeline that is straightforward to implement and memory-efficient.<br>
</li>
</ol>

<p><strong>Limitations:</strong><br></p>
<ul>
  <li>This exact, hash-bin approach <strong>does not capture near-duplicates</strong> that differ by small <strong>token edits</strong> or by <strong>templated substitutions</strong>—those cases require fuzzy or locality-sensitive techniques beyond simple hashing.<br>
</li>
</ul>

<hr>

<h1 id="bloom-filter-approximate-set-membership-for-exact-duplication-detection">Bloom filter approximate set membership for exact-duplication detection</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/00-51-57-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/00-51-57-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/00-51-57-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/00-51-57.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Bloom filter</strong>: a <strong>space-efficient probabilistic set representation</strong> for answering membership queries with <strong>zero false negatives</strong> and a <strong>controllable false positive rate</strong>.<br></p>

<p><strong>How it works (insertion &amp; query)</strong>:<br></p>
<ol>
  <li>
<strong>Insertion</strong>: hash each inserted item <strong>k</strong> times into an <strong>m-bit</strong> array and set the corresponding bits.<br>
</li>
  <li>
<strong>Query</strong>: check the same <strong>k</strong> bit positions; if any bit is 0, the answer is <strong>definitely “no”</strong> (no false negatives). If all are 1, the answer is <strong>“yes”</strong>, which may be a <strong>false positive</strong>.<br>
</li>
</ol>

<p>Key properties and trade-offs:<br></p>
<ul>
  <li>
<strong>False positives</strong> occur with probability that depends on <strong>m</strong>, <strong>k</strong>, and <strong>n</strong> (the number of inserted items).<br>
</li>
  <li>
<strong>Zero false negatives</strong> (membership misses do not occur).<br>
</li>
  <li>Supports <strong>streaming insertion</strong> and <strong>constant-time membership checks</strong> (O(k) hash checks, usually treated as constant).<br>
</li>
  <li>
<strong>Tunable memory vs. false-positive trade-off</strong>: increase <strong>m</strong> (bits) to reduce false positives, or adjust <strong>k</strong> to balance rates.<br>
</li>
  <li>Widely used for <strong>large-scale exact-duplication detection</strong> and other applications where occasional false positives are acceptable.<br>
</li>
</ul>

<p>Design guidance:<br></p>
<ul>
  <li>Use design formulas and approximations to select <strong>m</strong> and <strong>k</strong> for a target false-positive rate given expected dataset size <strong>n</strong>.<br>
</li>
  <li>A common rule-of-thumb for the <strong>optimal number of hash functions</strong> is <strong>k ≈ (m / n) ln 2</strong>.<br>
</li>
  <li>Choose <strong>m</strong> (bits) so that, with the optimal <strong>k</strong>, the false-positive probability meets your target (e.g., <strong>1e-5</strong>) given the expected <strong>n</strong>.<br>
</li>
</ul>

<hr>

<h1 id="similarity-measures-minhash-and-probabilistic-reduction-of-jaccard">Similarity measures, MinHash and probabilistic reduction of Jaccard</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/01-01-32-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/01-01-32-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/01-01-32-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/01-01-32.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Near-duplicate detection uses set similarity measures such as the <strong>Jaccard index</strong> (|A ∩ B| / |A ∪ B|).<br></p>

<p>A probabilistic reduction to unary sketches is provided by <strong>MinHash</strong>: repeated independent applications of a randomized hash family map a set to its <strong>minimum hashed element</strong>, and the resulting collision probability equals the <strong>Jaccard similarity</strong> between the original sets.<br></p>

<ol>
  <li>
<strong>Constructing a MinHash sketch</strong>:<br>
    <ol>
      <li>Choose k independent randomized hash functions from a hash family.<br>
</li>
      <li>For each hash, map the set to the element with the minimum hash value.<br>
</li>
      <li>Collect the k minima into a <strong>k‑coordinate sketch</strong> (k scalar values).<br>
</li>
    </ol>
  </li>
</ol>

<ul>
  <li>The fraction of matching coordinates between two MinHash sketches estimates the <strong>Jaccard similarity</strong>.<br>
</li>
  <li>
    <p>That estimator is <strong>unbiased</strong> and has a <strong>known variance</strong>, so accuracy improves predictably with k.<br></p>
  </li>
  <li>Practical implications:<br>
    <ul>
      <li>
<strong>Compact representation</strong>: sets are compressed into k scalars rather than full pairwise comparisons.<br>
</li>
      <li>
<strong>Linear-time sketching</strong>: large corpora can be sketched in time proportional to the data size.<br>
</li>
      <li>
<strong>Cheap comparisons</strong>: sketches can be compared quickly, forming the basis for scalable near-duplicate pipelines that avoid O(N^2) pairwise comparisons.<br>
</li>
    </ul>
  </li>
</ul>

<p><strong>MinHash</strong> is particularly effective for <strong>bag-of-shingled</strong> representations (token <strong>n-grams</strong>) that capture surface similarity between documents.</p>

<hr>

<h1 id="locality-sensitive-hashing-lsh-with-banding-to-amplify-thresholds">Locality-Sensitive Hashing (LSH) with banding to amplify thresholds</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/01-08-41-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/01-08-41-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/01-08-41-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/01-08-41.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Locality-Sensitive Hashing (LSH)</strong> sharpens <strong>MinHash</strong> collisions into a practical approximate neighbor-retrieval rule by partitioning <strong>k</strong> MinHash values into <strong>B</strong> bands of <strong>R</strong> hashes each and declaring a <strong>candidate match</strong> if any band is identical between two items.<br></p>

<p>The <strong>banding</strong> construction yields a tunable, <strong>sigmoid-like mapping</strong> from true similarity to <strong>collision probability</strong>:<br></p>
<ul>
  <li>Increasing <strong>R</strong> makes band equality rarer — the curve <strong>shifts right</strong> and <strong>sharpens</strong> (higher selectivity).<br>
</li>
  <li>Increasing <strong>B</strong> raises the chance of at least one band match — the curve <strong>shifts left</strong> (higher sensitivity).<br>
</li>
</ul>

<p>By selecting <strong>B</strong> and <strong>R</strong> appropriately you can concentrate collision probability around a chosen similarity threshold so that pairs above the threshold are very likely to be retrieved and pairs below are unlikely.<br></p>

<p>Typical retrieval workflow (sublinear via hash tables):<br></p>
<ol>
  <li>Compute <strong>k</strong> MinHash signatures for each item.<br>
</li>
  <li>Partition the signature into <strong>B</strong> bands of <strong>R</strong> hashes.<br>
</li>
  <li>Hash each band into a hash table (band signature → bucket).<br>
</li>
  <li>At query time, probe the band hash tables and union candidates from matching buckets; then verify candidates as needed.<br>
</li>
</ol>

<p>Practical pipelines use large <strong>k</strong> and tune <strong>B/R</strong> to match application-specific near-duplicate criteria (for example, ~<strong>0.99 Jaccard</strong> for strict paragraph deduplication), accepting <strong>probabilistic retrieval guarantees</strong> and trading off <strong>recall</strong> versus <strong>precision</strong> when choosing parameters.</p>

<hr>

<h1 id="practical-considerations-embeddings-for-paraphrase-sensitive-deduplication-and-duplicate-handling-policies">Practical considerations: embeddings for paraphrase-sensitive deduplication and duplicate handling policies</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/01-15-09-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/01-15-09-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/01-15-09-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/01-15-09.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Paraphrase-</strong> or <strong>semantics-sensitive deduplication</strong> requires <strong>dense embeddings</strong> and <strong>approximate nearest neighbor (ANN)</strong> search rather than surface n-gram methods like <strong>Jaccard/MinHash</strong>—this enables detection of semantically similar paraphrases but comes with higher <strong>computational cost</strong> for <strong>embedding generation</strong> and <strong>index maintenance</strong>.<br></p>

<p>Embedding-based LSH or ANN structures fit into the same high-level framework as <strong>MinHash LSH</strong>: compute a vector per document, then index/query to find neighbors above a similarity threshold. Key components and steps are:<br></p>

<ol>
  <li>
<strong>Vectorize each document</strong> into a dense embedding (semantic representation).<br>
</li>
  <li>
<strong>Build an index</strong> using methods such as <strong>product quantization</strong>, <strong>HNSW</strong>, or <strong>LSH</strong> to support fast neighbor queries.<br>
</li>
  <li>
<strong>Query for neighbors</strong> using a similarity metric (e.g., <strong>cosine similarity</strong>) and a chosen threshold to detect paraphrases/near-duplicates.<br>
</li>
  <li>
<strong>Tune hyperparameters</strong> (index size, PQ/graph settings, LSH bands, threshold) to trade <strong>recall</strong> for <strong>efficiency</strong> and storage costs.<br>
</li>
</ol>

<p>Policy choices about what to do with detected duplicates are important and depend on objectives:<br></p>

<ul>
  <li>
<strong>Full deduplication</strong>: remove all duplicates to maximize dataset uniqueness and reduce memorization risk.<br>
</li>
  <li>
<strong>Retain multiple occurrences</strong>: keep repeats when the source is genuinely high-quality or when <strong>multi-epoch training</strong> over the same data is desired.<br>
</li>
  <li>
<strong>Count-capping heuristics</strong>: instead of full elimination, apply caps (e.g., <strong>sqrt</strong> or <strong>log</strong> scaling of counts) to preserve useful signal while avoiding extreme overrepresentation.<br>
</li>
</ul>

<p>These design choices balance three main concerns:<br></p>

<ul>
  <li>
<strong>Dataset diversity</strong> (favoring deduplication),<br>
</li>
  <li>
<strong>Memorization risk</strong> (favoring stricter deduplication), and<br>
</li>
  <li>The <strong>intended training regimen</strong> (e.g., <strong>single-pass pretraining</strong> vs. <strong>multi-epoch fine-tuning</strong>), which may justify retaining some duplicates.<br>
</li>
</ul>

<p>Choose the embedding model, indexing method, similarity threshold, and deduplication policy together to meet your target trade-offs in quality, compute, and risk.</p>

<hr>

<h1 id="lecture-summary-and-next-steps">Lecture summary and next steps</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cs336-2025/frames/lec14/01-17-57-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cs336-2025/frames/lec14/01-17-57-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cs336-2025/frames/lec14/01-17-57-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cs336-2025/frames/lec14/01-17-57.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>The lecture consolidates algorithmic primitives for preparing training corpora:<br></p>

<ul>
  <li>
<strong>n-gram models</strong><br>
</li>
  <li>
<strong>fast linear classifiers</strong><br>
</li>
  <li>
<strong>importance resampling for filtering</strong><br>
</li>
  <li>
<strong>Hashing-based techniques</strong> for deduplication, including:
    <ul>
      <li>
<strong>exact hashing</strong><br>
</li>
      <li>
<strong>Bloom filters</strong><br>
</li>
      <li>
<strong>MinHash</strong><br>
</li>
      <li>
<strong>LSH</strong> (Locality-Sensitive Hashing)<br>
</li>
    </ul>
  </li>
</ul>

<p>Each primitive is characterized by three complementary aspects:<br></p>

<ul>
  <li>
<strong>Computational cost</strong> — runtime, memory, and scalability trade-offs<br>
</li>
  <li>
<strong>Statistical properties</strong> — bias, variance, and impact on distributional fidelity<br>
</li>
  <li>
<strong>Practical role</strong> — how the primitive contributes to extracting a <strong>high-quality target dataset</strong> from raw web data<br>
</li>
</ul>

<p>Practical pipelines combine these methods to perform concrete corpus-preparation tasks:<br></p>

<ol>
  <li>
<strong>Language identification</strong> — filter and route data by language<br>
</li>
  <li>
<strong>Quality and toxicity filtering</strong> — remove low-quality or harmful content<br>
</li>
  <li>
<strong>Targeted domain curation</strong> — select domain-specific subsets from broad web crawls<br>
</li>
  <li>
<strong>Exact and near-duplicate removal</strong> — eliminate redundant content using hashing and similarity techniques<br>
</li>
</ol>

<ul>
  <li>
<strong>Parameter tuning</strong> is applied across the pipeline to balance <strong>false-positive vs. recall</strong> and to meet <strong>compute constraints</strong> (e.g., memory, throughput).<br>
</li>
</ul>

<p>The next instructional unit transitions to <strong>reinforcement learning</strong> and <strong>alignment</strong> topics.</p>

<hr>


    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/nlp-foundation/">LLM Series - Part 1 - Important Concepts in NLP</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/diffusion-foundation/">The Foundations and Frontiers of Diffusion Models</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/thoughts/">Random Thoughts and Notes</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/cs336-lec09/">CS336 Lecture 9 - Scaling laws</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/cs336-lec01/">CS336 Lecture 1 - Overview and Tokenization</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
