<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Karpathy Series - Let's reproduce GPT-2 | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="AI Summary Lecture">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2025/karpathy-lec10/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->
<!-- Page/Post style -->
<style type="text/css">
  
</style>


<div class="post">

  <header class="post-header">
    <h1 class="post-title">Karpathy Series - Let's reproduce GPT-2</h1>
    <p class="post-meta">December 15, 2025</p>
    <p class="post-tags">
      <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>
        ·  
        <a href="/blog/tag/genai">
          <i class="fas fa-hashtag fa-sm"></i> genai</a>  
          <a href="/blog/tag/llm">
          <i class="fas fa-hashtag fa-sm"></i> llm</a>  
          <a href="/blog/tag/tutorial">
          <i class="fas fa-hashtag fa-sm"></i> tutorial</a>  
          <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#project-goal-reproduce-gpt-2-124m-model">Project goal: reproduce GPT-2 124M model</a></li>
<li class="toc-entry toc-h1"><a href="#hugging-face-conversion-used-to-obtain-pytorch-weights-and-state-dict">Hugging Face conversion used to obtain PyTorch weights and state dict</a></li>
<li class="toc-entry toc-h1"><a href="#token-and-positional-embeddings-shapes-and-semantics">Token and positional embeddings shapes and semantics</a></li>
<li class="toc-entry toc-h1"><a href="#verify-generation-from-released-gpt-2-weights">Verify generation from released GPT-2 weights</a></li>
<li class="toc-entry toc-h1"><a href="#gpt-2-architecture-differences-from-the-original-transformer">GPT-2 architecture differences from the original Transformer</a></li>
<li class="toc-entry toc-h1"><a href="#block-level-computation-pre-normalization-residuals-attention-vs-mlp">Block-level computation: pre-normalization, residuals, attention vs MLP</a></li>
<li class="toc-entry toc-h1"><a href="#mlp-design-and-the-gelugated-nonlinearity-choice">MLP design and the GELU/Gated nonlinearity choice</a></li>
<li class="toc-entry toc-h1"><a href="#multi-head-self-attention-implementation-and-tensor-reshaping-tricks">Multi-head self-attention implementation and tensor reshaping tricks</a></li>
<li class="toc-entry toc-h1"><a href="#loading-hugging-face-weights-into-custom-gpt-class-and-tf-pytorch-transpositions">Loading Hugging Face weights into custom GPT class and TF-&gt;PyTorch transpositions</a></li>
<li class="toc-entry toc-h1"><a href="#forward-pass-and-logits-shape-semantics">Forward pass and logits shape semantics</a></li>
<li class="toc-entry toc-h1"><a href="#sampling-loop-top-k-sampling-and-pipeline-differences">Sampling loop, top-k sampling, and pipeline differences</a></li>
<li class="toc-entry toc-h1"><a href="#device-autodetection-and-cross-backend-compatibility-cuda-mps-cpu">Device autodetection and cross-backend compatibility (CUDA, MPS, CPU)</a></li>
<li class="toc-entry toc-h1"><a href="#batch-shaping-for-transformer-training-converting-long-streams-to-b-x-t-tensors">Batch shaping for Transformer training: converting long streams to B x T tensors</a></li>
<li class="toc-entry toc-h1"><a href="#loss-computation-for-next-token-prediction-and-flattening-for-crossentropy">Loss computation for next-token prediction and flattening for CrossEntropy</a></li>
<li class="toc-entry toc-h1"><a href="#simple-optimization-loop-and-debugging-overfitting-a-single-batch">Simple optimization loop and debugging overfitting a single batch</a></li>
<li class="toc-entry toc-h1"><a href="#simple-sequential-data-loader-sharded-chunk-iteration">Simple sequential data loader (sharded chunk iteration)</a></li>
<li class="toc-entry toc-h1"><a href="#weight-tying-of-token-embeddings-and-lm-head-shared-embedding">Weight tying of token embeddings and LM head (shared embedding)</a></li>
<li class="toc-entry toc-h1"><a href="#initialization-conventions-fixed-std-and-residual-scaling-for-deep-stacks">Initialization conventions: fixed std and residual scaling for deep stacks</a></li>
<li class="toc-entry toc-h1"><a href="#floating-point-precision-tradeoffs-and-tf32-impact">Floating-point precision tradeoffs and TF32 impact</a></li>
<li class="toc-entry toc-h1"><a href="#mixed-precision-bf16-and-autocast-benefits">Mixed precision (BF16) and autocast benefits</a></li>
<li class="toc-entry toc-h1"><a href="#torchcompile-reducing-python-overhead-and-enabling-kernel-fusion">torch.compile: reducing Python overhead and enabling kernel fusion</a></li>
<li class="toc-entry toc-h1"><a href="#flashattention-fused-attention-kernel-that-avoids-materializing-full-attention-matrices">FlashAttention: fused attention kernel that avoids materializing full attention matrices</a></li>
<li class="toc-entry toc-h1"><a href="#padding-vocabulary-and-tensor-sizes-to-nice-multiples-for-cuda-kernels">Padding vocabulary and tensor sizes to ‘nice’ multiples for CUDA kernels</a></li>
<li class="toc-entry toc-h1"><a href="#optimizer-choices-adamw-fused-optimizer-kernels-and-parameter-grouping">Optimizer choices: AdamW, fused optimizer kernels, and parameter grouping</a></li>
<li class="toc-entry toc-h1"><a href="#gradient-clipping-and-learning-rate-scheduling-cosine-decay-with-warmup">Gradient clipping and learning-rate scheduling (cosine decay with warmup)</a></li>
<li class="toc-entry toc-h1"><a href="#gradual-batch-scaling-considerations-and-practical-omission">Gradual batch scaling considerations and practical omission</a></li>
<li class="toc-entry toc-h1"><a href="#gradient-accumulation-semantics-and-correct-loss-scaling">Gradient accumulation semantics and correct loss scaling</a></li>
<li class="toc-entry toc-h1"><a href="#distributed-data-parallel-ddp-fundamentals-and-synchronization-control">Distributed Data Parallel (DDP) fundamentals and synchronization control</a></li>
<li class="toc-entry toc-h1"><a href="#training-data-choices-and-high-quality-commoncrawl-subsets-finewebedu">Training data choices and high-quality CommonCrawl subsets (FineWeb/edu)</a></li>
<li class="toc-entry toc-h1"><a href="#training-runs-throughput-tuning-and-producing-checkpoints">Training runs, throughput tuning and producing checkpoints</a></li>
<li class="toc-entry toc-h1"><a href="#downstream-evaluation-validation-loss-h-swag-implementation-and-caveats">Downstream evaluation: validation loss, H-SWAG implementation and caveats</a></li>
<li class="toc-entry toc-h1"><a href="#production-considerations-logging-checkpoints-alternative-ccuda-implementations-and-summary">Production considerations: logging, checkpoints, alternative C/CUDA implementations and summary</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <div style="display: flex; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/l8pRSuU81PU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
    </iframe>
</div>

<h1 id="project-goal-reproduce-gpt-2-124m-model">Project goal: reproduce GPT-2 124M model</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-01-01-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-01-01-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-01-01-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-01-01.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Objective: reproduce the <strong>GPT-2 124M</strong> model (the smallest GPT-2 checkpoint) by implementing the model, loading reference weights, and training from scratch until validation and downstream metrics match or exceed the released checkpoint.<br></p>

<p>The reproduction relies on <strong>published papers</strong>, <strong>released weights</strong>, and <strong>Hugging Face conversions</strong> to ensure architectural fidelity, while using modern tooling for training and evaluation.<br></p>

<p>Target model specs to match exactly:</p>
<ul>
  <li>
<strong>12 Transformer layers</strong><br>
</li>
  <li>
<strong>Hidden dimension 768</strong><br>
</li>
  <li>
<strong>Vocabulary consistent with the GPT-2 tokenizer</strong><br>
</li>
</ul>

<p>Strict attention to <strong>hyperparameters</strong> and <strong>initialization</strong> is required to replicate performance.<br></p>

<hr>

<h1 id="hugging-face-conversion-used-to-obtain-pytorch-weights-and-state-dict">Hugging Face conversion used to obtain PyTorch weights and state dict</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-04-01-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-04-01-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-04-01-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-04-01.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Hugging Face Transformers</strong> provides a PyTorch implementation and converted state dictionaries that map the original TensorFlow GPT-2 weights into PyTorch tensors.<br></p>

<p>Practical uses:</p>
<ul>
  <li>Load a <strong>HF GPT2LMHeadModel</strong> and inspect its <strong>state_dict</strong> to learn parameter names and shapes.<br>
</li>
  <li>The state_dict reveals <strong>token embeddings</strong>, <strong>positional encodings</strong>, <strong>per-layer attention and MLP weights</strong>, and <strong>LM head</strong> weights.<br>
</li>
</ul>

<p>These raw tensors guide:</p>
<ul>
  <li>
<strong>Parameter initialization</strong> for a from-scratch model<br>
</li>
  <li>
<strong>Key/name mapping</strong> and any necessary <strong>transpositions</strong> from original formats<br>
</li>
</ul>

<p>Using the HF model simplifies access to the canonical <strong>124M parameters</strong> while enabling reimplementation and verification.<br></p>

<hr>

<h1 id="token-and-positional-embeddings-shapes-and-semantics">Token and positional embeddings shapes and semantics</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-08-40-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-08-40-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-08-40-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-08-40.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Token embeddings</strong> form a matrix of shape <strong>(vocab_size x d_model)</strong> — for GPT-2 this is typically <strong>50257 x 768</strong>, giving a <strong>768-dimensional</strong> vector per token.<br></p>

<p><strong>Positional embeddings</strong> are a learned table of length equal to the maximum context (e.g., <strong>1024 x 768</strong>) and are <strong>added</strong> to token embeddings before the Transformer blocks.<br></p>

<p>Key points:</p>
<ul>
  <li>Embeddings produce <strong>distributed representations</strong> for tokens and absolute positions.<br>
</li>
  <li>Per-row and per-column patterns can show <strong>sinusoidal-like structure</strong> and <strong>channel-specific activations</strong> that arise from optimization (not explicit sinusoidal initialization).<br>
</li>
  <li>Understanding these shapes is essential for <strong>exact parameter mapping</strong> and architecture reconstruction.<br>
</li>
</ul>

<hr>

<h1 id="verify-generation-from-released-gpt-2-weights">Verify generation from released GPT-2 weights</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-12-34-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-12-34-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-12-34-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-12-34.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Loading the official <strong>GPT-2 124M</strong> weights via Hugging Face and running the <strong>text-generation pipeline</strong> provides a functional correctness check.<br></p>

<p>What to expect and check:</p>
<ul>
  <li>Sampled continuations should be <strong>coherent</strong> and consistent with a pretrained LM.<br>
</li>
  <li>Differences in outputs can come from <strong>RNG state</strong>, <strong>sampling defaults</strong> (top-k/top-p), and <strong>tokenization choices</strong>.<br>
</li>
</ul>

<p>Why this matters:</p>
<ul>
  <li>Coherent generations confirm correct <strong>weight loading</strong> and <strong>token/position mapping</strong>.<br>
</li>
  <li>This establishes a baseline target for models <strong>retrained from scratch</strong> and provides an empirical comparison point.<br>
</li>
</ul>

<hr>

<h1 id="gpt-2-architecture-differences-from-the-original-transformer">GPT-2 architecture differences from the original Transformer</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-15-47-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-15-47-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-15-47-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-15-47.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>GPT-2</strong> is a <strong>decoder-only Transformer</strong> with two main departures from the original “Attention Is All You Need” design:<br></p>

<ul>
  <li>
<strong>Pre-norm vs post-norm</strong>: GPT-2 reshuffles where <strong>LayerNorm</strong> is placed (pre-norm layout).<br>
</li>
  <li>
<strong>Extra final LayerNorm</strong>: an additional final layer norm appears before the LM head.<br>
</li>
</ul>

<p>Other structural notes:</p>
<ul>
  <li>The model omits <strong>encoder-decoder cross-attention</strong> — it contains only <strong>masked self-attention</strong> and <strong>feed-forward</strong> sublayers repeated for the specified depth (e.g., 12 layers).<br>
</li>
</ul>

<p>Reimplementations must:</p>
<ul>
  <li>Mirror these structural differences exactly<br>
</li>
  <li>Follow the <strong>naming/schema</strong> used by reference implementations (e.g., Hugging Face) for exact parameter correspondence and easy weight loading.<br>
</li>
</ul>

<hr>

<h1 id="block-level-computation-pre-normalization-residuals-attention-vs-mlp">Block-level computation: pre-normalization, residuals, attention vs MLP</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-19-18-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-19-18-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-19-18-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-19-18.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Each Transformer block is composed of:</p>
<ol>
  <li>A <strong>pre-normalized attention sublayer</strong> with residual connection<br>
</li>
  <li>A <strong>pre-normalized MLP (feed-forward) sublayer</strong> with residual connection<br>
</li>
</ol>

<p>Functional roles:</p>
<ul>
  <li>
<strong>Attention</strong> is a reduce operation: weighted aggregation across tokens enabling inter-token communication.<br>
</li>
  <li>
<strong>MLP</strong> is a per-token map: processes each token independently to transform its representation.<br>
</li>
</ul>

<p>Implementation implications:</p>
<ul>
  <li>The <strong>pre-norm</strong> layout places LayerNorm before the sublayer transforms, which affects <strong>gradient flow</strong> and training dynamics.<br>
</li>
  <li>Careful implementation is required to match GPT-2’s training behavior and stability.<br>
</li>
</ul>

<hr>

<h1 id="mlp-design-and-the-gelugated-nonlinearity-choice">MLP design and the GELU/Gated nonlinearity choice</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-22-22-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-22-22-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-22-22-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-22-22.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>The <strong>MLP</strong> (feed-forward) consists of:</p>
<ul>
  <li>Two linear projections with a nonlinearity between them.<br>
</li>
</ul>

<p>Activation detail:</p>
<ul>
  <li>GPT-2 uses a <strong>GELU variant</strong> (an approximate GELU historically used in TensorFlow for performance).<br>
</li>
  <li>
<strong>GELU</strong> provides non-zero gradients in regions where ReLU would be exactly zero, mitigating the dead-ReLU issue and improving optimization stability.<br>
</li>
</ul>

<p>Reproduction guidance:</p>
<ul>
  <li>Use the same <strong>approximate activation</strong> (or exact GELU if hardware allows) because activation asymptotics and gradient behavior impact training dynamics and final performance.<br>
</li>
</ul>

<hr>

<h1 id="multi-head-self-attention-implementation-and-tensor-reshaping-tricks">Multi-head self-attention implementation and tensor reshaping tricks</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-25-35-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-25-35-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-25-35-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-25-35.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Multi-headed attention</strong> implementation steps:</p>
<ol>
  <li>Linearly project input to combined <strong>Q/K/V</strong> tensors.<br>
</li>
  <li>Reshape to separate <strong>head</strong> and <strong>batch</strong> dimensions.<br>
</li>
  <li>Perform batched <strong>scaled dot-product attention</strong> with <strong>causal masking</strong>.<br>
</li>
  <li>Concatenate head outputs and apply a final linear projection.<br>
</li>
</ol>

<p>Performance notes:</p>
<ul>
  <li>Efficient PyTorch implementations treat the <strong>head dimension</strong> as an additional batch dimension to use parallel kernels and reduce Python overhead.<br>
</li>
  <li>Ensure mathematical equivalence to per-head implementations is preserved.<br>
</li>
  <li>Matching <strong>naming</strong> and <strong>parameter layout</strong> to Hugging Face conventions simplifies weight transfer and ensures functional equivalence.<br>
</li>
</ul>

<hr>

<h1 id="loading-hugging-face-weights-into-custom-gpt-class-and-tf-pytorch-transpositions">Loading Hugging Face weights into custom GPT class and TF-&gt;PyTorch transpositions</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-30-21-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-30-21-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-30-21-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-30-21.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Transferring parameters from Hugging Face (or TF-origin) to a from-scratch PyTorch GPT class requires careful mapping and conversion:<br></p>

<p>Recommended procedure:</p>
<ul>
  <li>Iterate over HF <strong>state_dict</strong> keys and map them to local module names.<br>
</li>
  <li>Optionally ignore non-parameter buffers (e.g., static causal mask buffers).<br>
</li>
  <li>Identify matrices requiring <strong>transpose</strong> due to TF-to-PyTorch layout differences and apply transposition.<br>
</li>
  <li>Verify <strong>shape equality</strong> after mapping.<br>
</li>
</ul>

<p>Encapsulation:</p>
<ul>
  <li>Implement a robust <strong>from_pretrained</strong> class method that performs these conversions and returns a PyTorch model whose state tensors exactly match the reference numerics for generation and evaluation.<br>
</li>
</ul>

<hr>

<h1 id="forward-pass-and-logits-shape-semantics">Forward pass and logits shape semantics</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-36-23-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-36-23-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-36-23-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-36-23.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>The forward pass semantics:</p>
<ul>
  <li>Input: token indices shaped <strong>(B x T)</strong>.<br>
</li>
  <li>Output: logits shaped <strong>(B x T x V)</strong>, where <strong>V</strong> is vocabulary size.<br>
</li>
</ul>

<p>Computation flow:</p>
<ol>
  <li>Sum <strong>token</strong> and <strong>positional</strong> embeddings (positional broadcast across batch rows).<br>
</li>
  <li>Pass through the <strong>Transformer blocks</strong>.<br>
</li>
  <li>Apply the <strong>final layer norm</strong> and the <strong>LM head</strong> linear projection to produce logits.<br>
</li>
  <li>Convert logits to probabilities via <strong>softmax</strong> for sampling or use directly for <strong>cross-entropy</strong> loss.<br>
</li>
</ol>

<p>Implementation must ensure:</p>
<ul>
  <li>Correct tensor shapes and broadcasting.<br>
</li>
  <li>Device-consistent tensors to avoid runtime errors during forward and loss computation.<br>
</li>
</ul>

<hr>

<h1 id="sampling-loop-top-k-sampling-and-pipeline-differences">Sampling loop, top-k sampling, and pipeline differences</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-42-23-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-42-23-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-42-23-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-42-23.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Autoregressive generation pattern:</p>
<ol>
  <li>Loop and append one sampled token at a time, using only last-step logits to reduce computation.<br>
</li>
  <li>Apply <strong>top-k filtering</strong> (e.g., k=50), renormalize, and sample to avoid very rare tokens and improve coherence.<br>
</li>
</ol>

<p>Practical tips:</p>
<ul>
  <li>Use <strong>torch.no_grad</strong> to avoid saving intermediate tensors for backward passes.<br>
</li>
  <li>Carefully manage <strong>RNG seeds</strong> and torch.Generator objects to isolate sampling randomness from training RNG state.<br>
</li>
  <li>Differences in HF pipeline defaults (top-k, top-p, temperature) can cause the same seed to produce different outputs across implementations.<br>
</li>
</ul>

<hr>

<h1 id="device-autodetection-and-cross-backend-compatibility-cuda-mps-cpu">Device autodetection and cross-backend compatibility (CUDA, MPS, CPU)</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-48-19-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-48-19-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-48-19-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-48-19.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Training code should detect and use available devices (CUDA GPU, Apple MPS, or CPU) and move model tensors and inputs to the same device to avoid mismatches.<br></p>

<p>Best practices:</p>
<ul>
  <li>Use device-aware tensor creation (e.g., torch.arange(…, device=idx.device)) so forward logic stays device-agnostic.<br>
</li>
  <li>When GPUs are unavailable, code should still run on <strong>CPU</strong> or <strong>MPS</strong> for debugging (slower but functional).<br>
</li>
  <li>Log the chosen device and adapt batch sizes to fit memory constraints for reproducible behavior across hardware backends.<br>
</li>
</ul>

<hr>

<h1 id="batch-shaping-for-transformer-training-converting-long-streams-to-b-x-t-tensors">Batch shaping for Transformer training: converting long streams to B x T tensors</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-53-10-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-53-10-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-53-10-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-53-10.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Construct training batches from a token stream by reshaping contiguous token arrays into <strong>(B x T)</strong> tensors, where each row is a context sequence up to block size T.<br></p>

<p>Label construction:</p>
<ul>
  <li>Load an extra token per row (B*T + 1) and slice into inputs X (all except last) and targets Y (all except first) so each input position has a next-token label.<br>
</li>
</ul>

<p>Benefits:</p>
<ul>
  <li>Efficient batched training with B independent sequences for parallel computation.<br>
</li>
  <li>Ensures last-token targets are present for loss computation.<br>
</li>
</ul>

<hr>

<h1 id="loss-computation-for-next-token-prediction-and-flattening-for-crossentropy">Loss computation for next-token prediction and flattening for CrossEntropy</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/00-58-14-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/00-58-14-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/00-58-14-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/00-58-14.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>For language-model cross-entropy:</p>
<ul>
  <li>Flatten logits from <strong>(B x T x V)</strong> to <strong>(B<em>T x V)** and targets from **(B x T)** to **(B</em>T)</strong> because PyTorch’s F.cross_entropy expects 2D logits and 1D targets.<br>
</li>
</ul>

<p>Forward API:</p>
<ul>
  <li>When targets are provided, return both <strong>logits</strong> and <strong>loss</strong> from forward to centralize computation.<br>
</li>
</ul>

<p>Sanity checks:</p>
<ul>
  <li>Initial random-model loss approximates <strong>-log(1/V)</strong> (≈ ln(V); e.g., ~10.8 for V≈50k), which helps validate initialization.<br>
</li>
</ul>

<p>Care:</p>
<ul>
  <li>Correct flattening, masking out-of-range positions (if used), and reduction semantics are crucial to stable training.<br>
</li>
</ul>

<hr>

<h1 id="simple-optimization-loop-and-debugging-overfitting-a-single-batch">Simple optimization loop and debugging overfitting a single batch</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/01-03-40-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/01-03-40-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/01-03-40-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/01-03-40.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>A minimal training loop:</p>
<ol>
  <li>Create an optimizer (recommend <strong>AdamW</strong>).<br>
</li>
  <li>Zero gradients.<br>
</li>
  <li>Compute loss and call <strong>loss.backward()</strong>.<br>
</li>
  <li>Call <strong>optimizer.step()</strong> to update parameters.<br>
</li>
</ol>

<p>Debugging checks:</p>
<ul>
  <li>Verify the model can <strong>overfit a small batch</strong> — this confirms forward/loss/backward pathways are correct.<br>
</li>
  <li>Start without gradient accumulation to simplify debugging; initial LR defaults (e.g., 3e-4) are reasonable for quick overfit tests.<br>
</li>
</ul>

<p>Watch for device mismatches — ensure all buffers and tensors live on the same device.<br></p>

<hr>

<h1 id="simple-sequential-data-loader-sharded-chunk-iteration">Simple sequential data loader (sharded chunk iteration)</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/01-08-03-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/01-08-03-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/01-08-03-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/01-08-03.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>A minimal data loader approach:</p>
<ul>
  <li>Iterate through a tokenized corpus in fixed-size chunks of <strong>B*T</strong> tokens.<br>
</li>
  <li>Return (X, Y) pairs by advancing a read pointer by <strong>B*T</strong> each time and loop to the start when exhausted.<br>
</li>
</ul>

<p>Properties:</p>
<ul>
  <li>Deterministic, epoch-based iteration without replacement until a full pass completes.<br>
</li>
  <li>Sharding the corpus into fixed-size shards simplifies I/O and parallel processing.<br>
</li>
</ul>

<p>Extensions:</p>
<ul>
  <li>For multi-epoch training, shuffle document order and permute shards per epoch to avoid ordering effects.<br>
</li>
</ul>

<hr>

<h1 id="weight-tying-of-token-embeddings-and-lm-head-shared-embedding">Weight tying of token embeddings and LM head (shared embedding)</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/01-13-33-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/01-13-33-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/01-13-33-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/01-13-33.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Weight tying</strong> reuses the same matrix for input token embeddings and the output LM head projection (pre-softmax), yielding:</p>
<ul>
  <li>Substantial parameter savings and an <strong>inductive bias</strong> tying input/output representations.<br>
</li>
</ul>

<p>Implementation in PyTorch:</p>
<ul>
  <li>Assign the LM head weight tensor to <strong>reference the embedding weight tensor</strong> (share the same storage pointer) so gradients accumulate into the same parameter.<br>
</li>
</ul>

<p>Effects:</p>
<ul>
  <li>Reduces parameter count (e.g., ~40M saved in the 124M model).<br>
</li>
  <li>Often improves sample efficiency and generalization.<br>
</li>
</ul>

<hr>

<h1 id="initialization-conventions-fixed-std-and-residual-scaling-for-deep-stacks">Initialization conventions: fixed std and residual scaling for deep stacks</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/01-25-01-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/01-25-01-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/01-25-01-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/01-25-01.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>GPT-2 reference initializations and variance control:</p>
<ul>
  <li>Most linear weights use <strong>normal initialization with std=0.02</strong> and zero biases.<br>
</li>
  <li>Embedding stds: e.g., token embeddings <strong>0.02</strong>, position embeddings sometimes <strong>0.01</strong> in some codebases.<br>
</li>
</ul>

<p>Residual-sum scaling:</p>
<ul>
  <li>Scale-down residual block weights by <strong>1/sqrt(n)</strong> to compensate for variance growth in a sum-of-residuals architecture.<br>
</li>
  <li>Implement by multiplying initialization std by <strong>1/sqrt(2*L)</strong> where <strong>L</strong> is the number of Transformer layers (two residual contributions per layer).<br>
</li>
</ul>

<p>Why this matters:</p>
<ul>
  <li>These initialization details stabilize optimization and mirror original training dynamics.<br>
</li>
</ul>

<hr>

<h1 id="floating-point-precision-tradeoffs-and-tf32-impact">Floating-point precision tradeoffs and TF32 impact</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/01-35-34-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/01-35-34-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/01-35-34-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/01-35-34.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Modern GPU precisions overview:</p>
<ul>
  <li>
<strong>FP32</strong>: baseline full precision, stable but limited throughput.<br>
</li>
  <li>
<strong>TF32</strong>: a cropped-mantissa FP32 variant on Ampere that executes faster on tensor cores by truncating some mantissa bits while preserving exponent range.<br>
</li>
</ul>

<p>Practical notes:</p>
<ul>
  <li>Enable TF32 in PyTorch (e.g., torch.set_float32_matmul_precision(‘high’)) to transparently use faster tensor-core kernels.<br>
</li>
  <li>Gains depend on whether workloads are compute-bound vs memory-bound; expect modest numerical impact but potentially large throughput improvements.<br>
</li>
</ul>

<hr>

<h1 id="mixed-precision-bf16-and-autocast-benefits">Mixed precision (BF16) and autocast benefits</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/01-42-40-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/01-42-40-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/01-42-40-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/01-42-40.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>BFloat16 (BF16)</strong> reduces storage and memory transfer cost by truncating mantissa while preserving exponent range, avoiding many of FP16’s numerical issues.<br></p>

<p>Best practice:</p>
<ul>
  <li>Use <strong>torch.autocast</strong> to lower eligible ops (matmuls, convolutions) to BF16 while keeping sensitive ops (layernorm, softmax, loss) in FP32.<br>
</li>
</ul>

<p>Requirements and benefits:</p>
<ul>
  <li>Requires hardware support (e.g., Ampere GPUs).<br>
</li>
  <li>Often obviates explicit gradient scaling and yields substantial throughput and memory improvements when used carefully.<br>
</li>
</ul>

<hr>

<h1 id="torchcompile-reducing-python-overhead-and-enabling-kernel-fusion">torch.compile: reducing Python overhead and enabling kernel fusion</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/01-50-24-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/01-50-24-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/01-50-24-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/01-50-24.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>torch.compile</strong> (PyTorch compilation) analyzes the model graph and generates optimized kernels to reduce Python overhead and enable operator/kernel fusion.<br></p>

<p>Benefits:</p>
<ul>
  <li>Removes repeated operator dispatch, fuses elementwise sequences, and can reduce global memory round-trips.<br>
</li>
  <li>Typically yields multi-fold speedups for repeated training iterations after an upfront compilation cost.<br>
</li>
</ul>

<hr>

<h1 id="flashattention-fused-attention-kernel-that-avoids-materializing-full-attention-matrices">FlashAttention: fused attention kernel that avoids materializing full attention matrices</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/01-57-01-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/01-57-01-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/01-57-01-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/01-57-01.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>FlashAttention</strong> is a fused GPU kernel for masked scaled-dot-product attention that avoids materializing the full T x T attention matrix in HBM.<br></p>

<p>How it works and why it helps:</p>
<ul>
  <li>Uses an online softmax normalization trick and block-wise accumulation to reduce expensive HBM reads/writes.<br>
</li>
  <li>Orchestrates shared-memory usage and scaling to compute attention in streaming blocks.<br>
</li>
  <li>Preserves functional semantics for causal attention while lowering memory footprint and improving runtime compared to naive attention implementations.<br>
</li>
</ul>

<hr>

<h1 id="padding-vocabulary-and-tensor-sizes-to-nice-multiples-for-cuda-kernels">Padding vocabulary and tensor sizes to ‘nice’ multiples for CUDA kernels</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/02-05-53-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/02-05-53-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/02-05-53-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/02-05-53.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Hardware kernel considerations:</p>
<ul>
  <li>Many CUDA kernels and tensor-core implementations are optimized for tile sizes and powers-of-two factors.<br>
</li>
  <li>Awkward dimensions (e.g., vocab size <strong>50257</strong>) can trigger slow boundary kernels and reduce throughput.<br>
</li>
</ul>

<p>Mitigation:</p>
<ul>
  <li>
<strong>Pad the vocabulary</strong> to a nearby friendly number (e.g., <strong>50304</strong>) to align internal loops with preferred tile sizes.<br>
Trade-offs:</li>
  <li>Small extra memory used for padded rows; functionally benign if token indices never reference padded rows.<br>
</li>
  <li>Optimizer must learn to drive unused-token logits down, which is usually negligible cost.<br>
</li>
</ul>

<hr>

<h1 id="optimizer-choices-adamw-fused-optimizer-kernels-and-parameter-grouping">Optimizer choices: AdamW, fused optimizer kernels, and parameter grouping</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/02-17-40-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/02-17-40-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/02-17-40-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/02-17-40.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>AdamW</strong> (Adam with decoupled weight decay) is the recommended optimizer for Transformer training due to adaptive moments and per-parameter scaling.<br></p>

<p>Performance tips:</p>
<ul>
  <li>Use <strong>fused implementations</strong> when available to reduce kernel-launch overhead by consolidating updates into single kernels.<br>
</li>
  <li>Apply <strong>parameter grouping</strong> to separate parameters that should receive weight decay (e.g., 2D weight matrices, embeddings) from those that should not (biases, LayerNorm gain/bias).<br>
</li>
</ul>

<p>Result:</p>
<ul>
  <li>Better optimization behavior and improved runtime when grouped and fused updates are used.<br>
</li>
</ul>

<hr>

<h1 id="gradient-clipping-and-learning-rate-scheduling-cosine-decay-with-warmup">Gradient clipping and learning-rate scheduling (cosine decay with warmup)</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/02-29-00-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/02-29-00-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/02-29-00-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/02-29-00.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Stability and scheduling:</p>
<ul>
  <li>
<strong>Clip global gradient norm</strong> (e.g., to 1.0) to prevent runaway updates from outlier batches.<br>
</li>
  <li>Use a <strong>linear warmup</strong> followed by <strong>cosine decay</strong>: ramp LR from near zero to peak over a warmup token budget, then decay via cosine to a lower fraction (e.g., 10%) across a token horizon.<br>
</li>
</ul>

<p>Implementation:</p>
<ul>
  <li>Make warmup steps and cosine decay configurable to reproduce reference regimes and allow experimentation.<br>
</li>
</ul>

<hr>

<h1 id="gradual-batch-scaling-considerations-and-practical-omission">Gradual batch scaling considerations and practical omission</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/02-40-00-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/02-40-00-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/02-40-00-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/02-40-00.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Batch-size strategies:</p>
<ul>
  <li>Large-scale papers sometimes recommend <strong>ramping batch size</strong> early for optimizer stability, but this complicates bookkeeping and token-based scheduling.<br>
</li>
  <li>For single-node GPU constraints, <strong>gradient accumulation</strong> is an effective practical alternative to simulate larger global batch sizes while keeping micro-batches small.<br>
</li>
</ul>

<p>Recommendation:</p>
<ul>
  <li>For reproducible and simpler experiments, prefer <strong>fixed micro-batch sizes</strong> with gradient accumulation unless infrastructure supports dynamic batch scheduling.<br>
</li>
</ul>

<hr>

<h1 id="gradient-accumulation-semantics-and-correct-loss-scaling">Gradient accumulation semantics and correct loss scaling</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/02-53-30-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/02-53-30-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/02-53-30-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/02-53-30.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Gradient accumulation mechanics:</p>
<ul>
  <li>Sum per-micro-batch gradients across multiple forward/backward steps to emulate a larger batch.<br>
</li>
  <li>Because many PyTorch losses perform mean reduction over the micro-batch, scale the per-step loss by <strong>1 / grad_accum_steps</strong> before backward so summed gradients equal a single large-batch gradient.<br>
</li>
</ul>

<p>Correct pattern:</p>
<ol>
  <li>loss = loss / grad_accum_steps<br>
</li>
  <li>loss.backward() each micro-step<br>
</li>
  <li>optimizer.step() only after accumulation is complete<br>
</li>
</ol>

<p>Failure to scale yields gradients larger by grad_accum_steps and incorrect updates.<br></p>

<hr>

<h1 id="distributed-data-parallel-ddp-fundamentals-and-synchronization-control">Distributed Data Parallel (DDP) fundamentals and synchronization control</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/03-10-30-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/03-10-30-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/03-10-30-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/03-10-30.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p><strong>Distributed Data Parallel (DDP)</strong> patterns:</p>
<ul>
  <li>Run one process per GPU; each process computes local gradients on its data shard and then gradients are <strong>all-reduced</strong> (averaged) across processes before optimizer.step().<br>
</li>
</ul>

<p>Gradient accumulation with DDP:</p>
<ul>
  <li>Use <strong>no_sync</strong> context to avoid synchronizing on every micro-step during accumulation so only the final micro-step triggers communication.<br>
</li>
</ul>

<p>Operational necessities:</p>
<ul>
  <li>Initialize process <strong>ranks</strong>, <strong>world size</strong>, <strong>local rank</strong>, and device mapping correctly and destroy process groups on exit for robust DDP training.<br>
</li>
</ul>

<hr>

<h1 id="training-data-choices-and-high-quality-commoncrawl-subsets-finewebedu">Training data choices and high-quality CommonCrawl subsets (FineWeb/edu)</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/03-32-00-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/03-32-00-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/03-32-00-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/03-32-00.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Datasets and preprocessing for reproductions:</p>
<ul>
  <li>Public reproductions use curated mixtures built from <strong>CommonCrawl</strong> (OpenWebText, RedPajama, FineWeb) plus filtered sources (Wikipedia, books, GitHub).<br>
</li>
  <li>High-quality filtered subsets (e.g., <strong>FineWeb EDU</strong>) provide dense, high-information text for language-generalization metrics.<br>
</li>
</ul>

<p>Practical processing:</p>
<ul>
  <li>Tokenize at scale and shard into fixed-size files (e.g., <strong>100M-token shards</strong>) for streaming and parallel loading.<br>
</li>
  <li>Careful <strong>deduplication</strong>, <strong>language filtering</strong>, and <strong>per-epoch shuffling</strong> are crucial to avoid dataset bias and leakage.<br>
</li>
</ul>

<hr>

<h1 id="training-runs-throughput-tuning-and-producing-checkpoints">Training runs, throughput tuning and producing checkpoints</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/03-51-50-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/03-51-50-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/03-51-50-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/03-51-50.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Combine optimizations to maximize throughput:</p>
<ul>
  <li>Use <strong>BF16/autocast</strong>, <strong>torch.compile</strong>, <strong>FlashAttention</strong>, <strong>fused AdamW</strong>, <strong>padded dimensions</strong>, <strong>DDP</strong>, and <strong>gradient accumulation</strong> to increase tokens-per-second.<br>
</li>
</ul>

<p>Operational monitoring:</p>
<ul>
  <li>Measure <strong>tokens/sec</strong>, wall time per step, and validation intervals to estimate training budget in hours for a target token count.<br>
</li>
  <li>Regularly checkpoint model and optimizer state and persist RNG seeds for exact resume behavior.<br>
</li>
</ul>

<p>Outcome:</p>
<ul>
  <li>Empirical runs with these optimizations achieved successful convergence and downstream gains in modest compute budgets.<br>
</li>
</ul>

<hr>

<h1 id="downstream-evaluation-validation-loss-h-swag-implementation-and-caveats">Downstream evaluation: validation loss, H-SWAG implementation and caveats</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/04-00-32-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/04-00-32-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/04-00-32-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/04-00-32.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Evaluation strategy:</p>
<ul>
  <li>Compute held-out <strong>validation next-token loss</strong> and run downstream multiple-choice-style benchmarks (e.g., <strong>H-SWAG</strong>) by converting each question into candidate continuations and scoring average per-token log-probabilities.<br>
</li>
</ul>

<p>Distributed evaluation:</p>
<ul>
  <li>Shard evaluation across DDP ranks, aggregate counts with <strong>all-reduce</strong>, and report global accuracy.<br>
</li>
</ul>

<p>Interpretation caveats:</p>
<ul>
  <li>Differences in training data distributions, possible test contamination from large scraped corpora, and limitations of older benchmarks (H-SWAG is largely solved by modern LMs) mean multiple held-out tasks should be used for robust comparison.<br>
</li>
</ul>

<hr>

<h1 id="production-considerations-logging-checkpoints-alternative-ccuda-implementations-and-summary">Production considerations: logging, checkpoints, alternative C/CUDA implementations and summary</h1>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/karpathy/frames/lec10/04-01-25-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/karpathy/frames/lec10/04-01-25-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/karpathy/frames/lec10/04-01-25-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/karpathy/frames/lec10/04-01-25.jpg" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<p>Operational best practices:</p>
<ul>
  <li>Structured logging of training and validation metrics.<br>
</li>
  <li>Periodic checkpointing (model + optimizer states) and reproducible seeds.<br>
</li>
</ul>

<p>Advanced options:</p>
<ul>
  <li>Lower-level implementations (e.g., a dedicated C/CUDA lm.C) can improve startup and per-step throughput but require careful numerical parity checks versus PyTorch prototypes.<br>
</li>
</ul>

<p>Conclusion:</p>
<ul>
  <li>With modern tooling and hardware, a faithful <strong>GPT-2 124M</strong> reproduction (implementation, training, and evaluation) is feasible on modest compute budgets.<br>
</li>
  <li>Recommended extensions: epoch shuffling, improved dataset handling, and compilation fixes for generation to make the reproduction robust and production-ready.<br>
</li>
</ul>

<hr>


    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec06/">MIT 6.S184 - Lecture 6 - Diffusion for Protein Generation</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec05/">MIT 6.S184 - Lecture 5 - Diffusion for Robotics</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec04/">MIT 6.S184 - Lecture 4 - Building an Image Generator</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec03/">MIT 6.S184 - Lecture 3 - Training Flow and Diffusion Models</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec02/">MIT 6.S184 - Lecture 2 -  Constructing a Training Target</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
