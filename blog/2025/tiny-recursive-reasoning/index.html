<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Less is More - Recursive Reasoning with Tiny Networks | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="Researcher in Generative AI and Trustworthy AI
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2025/tiny-recursive-reasoning/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->
<!-- Page/Post style -->
<style type="text/css">
  
</style>


<div class="post">

  <header class="post-header">
    <h1 class="post-title">Less is More - Recursive Reasoning with Tiny Networks</h1>
    <p class="post-meta">October 14, 2025</p>
    <p class="post-tags">
      <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>
        ·  
        <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          <a href="/blog/tag/genai">
          <i class="fas fa-hashtag fa-sm"></i> genai</a>  
          <a href="/blog/tag/llm">
          <i class="fas fa-hashtag fa-sm"></i> llm</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#about-the-paper">About the paper</a></li>
<li class="toc-entry toc-h2">
<a href="#implementation">Implementation</a>
<ul>
<li class="toc-entry toc-h3"><a href="#data-preparation">Data preparation</a></li>
<li class="toc-entry toc-h3">
<a href="#main-process">Main process</a>
<ul>
<li class="toc-entry toc-h4"><a href="#data-flow">Data Flow</a></li>
<li class="toc-entry toc-h4"><a href="#q-learning">Q-Learning</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#applying-to-relation-extraction-problem">Applying to Relation Extraction problem</a>
<ul>
<li class="toc-entry toc-h3"><a href="#relation-extraction-re">Relation Extraction (RE)</a></li>
<li class="toc-entry toc-h3">
<a href="#biored-dataset">BioRED Dataset</a>
<ul>
<li class="toc-entry toc-h4"><a href="#data-format">Data Format</a></li>
<li class="toc-entry toc-h4"><a href="#entity-types">Entity Types</a></li>
<li class="toc-entry toc-h4"><a href="#relation-types">Relation Types</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#data-processing">Data Processing</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#references">References</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <h2 id="about-the-paper">About the paper</h2>

<h2 id="implementation">Implementation</h2>

<h3 id="data-preparation">Data preparation</h3>

<h3 id="main-process">Main process</h3>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2025-tiny-recursive-reasoning/2025-10-15-14-08-38-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2025-tiny-recursive-reasoning/2025-10-15-14-08-38-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2025-tiny-recursive-reasoning/2025-10-15-14-08-38-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2025-tiny-recursive-reasoning/2025-10-15-14-08-38.png" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption text-center">
    The architecture of the Tiny Recursion Model (TRM) and its processing pipeline. Given an input x (a question), a current prediction y and a latent z, In each reasoning cycle, there are two phases: the first phase is to recursively update latent z given (x, y, z) (i.e., f(x+y, z)) and the second phase is to update the prediction y given (y, z) (i.e., f(y, z)). The whole reasoning process involves multiple cycles of these two phases. In term of terminology, y is the high-level state z-H and z is the low-level state z-L in HRM.
</div>

<p>The model is fascinating and quite complex. It’s a recursive reasoning architecture with adaptive computation time (ACT), two interacting hidden states \(z_L\) and \(z_H\) and halting logic via Q-learning.</p>

<h4 id="data-flow">Data Flow</h4>

<p>The model maintains two levels of latent states:</p>

<ul>
  <li>\(z_H\): High-level state with shape <code class="language-plaintext highlighter-rouge">[batch_size, seq_len + puzzle_emb_len, hidden_size]</code> (i.e., the output \(y\) in this paper)</li>
  <li>\(z_L\): Low-level state with the same shape as \(z_H\) (i.e., the output \(z\) in this paper)</li>
</ul>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────┐
│                        Forward Pass                          │
└─────────────────────────────────────────────────────────────┘

Input: batch = {inputs, puzzle_identifiers, targets}
       carry = {z_H, z_L, steps, halted, current_data}<span class="sb">

                         ↓
           ┌─────────────────────────┐
           │  Reset carry if halted  │
           │  z_H = H_init           │
           │  z_L = L_init           │
           └─────────────────────────┘
                         ↓
           ┌─────────────────────────┐
           │  Input Embeddings       │
           │  tokens + puzzle + pos  │
           └─────────────────────────┘
                         ↓
           ┌─────────────────────────────────────┐
           │  Recursive Reasoning (no grad)      │
           │  ┌─────────────────────────────┐    │
           │  │ For h in range(H_cycles-1): │    │
           │  │   For l in range(L_cycles): │    │
           │  │     z_L ← L(z_L, z_H + x)   │    │
           │  │   z_H ← L(z_H, z_L)         │    │
           │  └─────────────────────────────┘    │
           └─────────────────────────────────────┘
                         ↓
           ┌─────────────────────────────────────┐
           │  Final Reasoning Cycle (with grad)  │
           │  For l in range(L_cycles):          │
           │    z_L ← L(z_L, z_H + x)            │
           │  z_H ← L(z_H, z_L)                  │
           └─────────────────────────────────────┘
                         ↓
           ┌─────────────────────────┐
           │  Output Generation      │
           │  logits = lm_head(z_H)  │
           │  q_halt = q_head(z_H₀)  │
           └─────────────────────────┘
                         ↓
           ┌─────────────────────────┐
           │  Halting Decision       │
           │  (ACT mechanism)        │
           └─────────────────────────┘
                         ↓
</span>Output: new_carry = {z_H', z_L', steps+1, halted', current_data}
        outputs = {logits, q_halt_logits, q_continue_logits}
</code></pre></div></div>

<h4 id="q-learning">Q-Learning</h4>

<p><strong>Q-Learning</strong> is a reinforcement learning algorithm that learns to make decisions by estimating the quality <strong>Q-value</strong> of taking specific actions in specific states.
More specifically, if \(Q(state, action)\) is the expected future reward for taking <code class="language-plaintext highlighter-rouge">action</code> in <code class="language-plaintext highlighter-rouge">state</code>, then the Q-value of the optimal policy can be iteratively updated by the following Bellman equation:</p>

<p>\(Q(s, a) = Q(s, a) + \alpha [r + \gamma \max_{a'} Q(s', a') - Q(s, a)]\)
where \(r\) is the reward for taking action \(a\) in state \(s\), \(\gamma\) is the discount factor, \(\alpha\) is the learning rate, \(s'\) is the next state, and \(a'\) is the next action.</p>

<p>The Q-value of the optimal policy is the maximum Q-value of all possible actions in all possible states.</p>

\[Q^*(s, a) = \max_{a'} Q(s, a')\]

<p><strong>Q-Learning in TRM</strong></p>

<p>In TRM, the Q-learning is used to learn the halting policy, i.e., when to stop the reasoning process. More specifically, there are two actions need to be considered:</p>

<ul>
  <li>
<strong>Halt</strong>: Stop reasoning and return the output answer.</li>
  <li>
<strong>Continue</strong>: perform one more reasoning cycle.</li>
</ul>

<p>In the implementation, the Q-value is the output of the <code class="language-plaintext highlighter-rouge">q_head</code> of the model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">self</span><span class="p">.</span><span class="n">q_head</span> <span class="o">=</span> <span class="nc">CastedLinear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># 2 actions: halt and continue
</span><span class="n">q_logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">q_head</span><span class="p">(</span><span class="n">z_H</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="c1"># Using the first token of the high-level state as the state representation
</span><span class="n">q_halt_logits</span> <span class="o">=</span> <span class="n">q_logits</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># Q(state, halt)
</span><span class="n">q_continue_logits</span> <span class="o">=</span> <span class="n">q_logits</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1"># Q(state, continue)
</span></code></pre></div></div>

<p>The <strong>halting logic</strong> is implemented as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">no_ACT_continue</span><span class="p">:</span>
    <span class="n">halted</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_halt_logits</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># Halt if Q(halt) is positive
</span><span class="k">else</span><span class="p">:</span>
    <span class="n">halted</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_halt_logits</span> <span class="o">&gt;</span> <span class="n">q_continue_logits</span><span class="p">)</span> <span class="c1"># Halt if Q(halt) is greater than Q(continue)
</span></code></pre></div></div>

<p><strong>Q-Learning Loss</strong></p>

<p>The Q-learning loss is defined in the <code class="language-plaintext highlighter-rouge">ACTLossHead</code> class as below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">q_halt_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">binary_cross_entropy_with_logits</span><span class="p">(</span>
    <span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">q_halt_logits</span><span class="sh">"</span><span class="p">],</span>        <span class="c1"># Predicted: should we halt?
</span>    <span class="n">seq_is_correct</span><span class="p">.</span><span class="nf">to</span><span class="p">(...),</span>          <span class="c1"># Target: 1 if sequence is correct, 0 otherwise
</span>    <span class="n">reduction</span><span class="o">=</span><span class="sh">"</span><span class="s">sum</span><span class="sh">"</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Where <code class="language-plaintext highlighter-rouge">seq_is_correct</code> is the target for the Q-learning loss, <code class="language-plaintext highlighter-rouge">1</code> if the model’s prediction is completely correct (all tokens match), <code class="language-plaintext highlighter-rouge">0</code> otherwise.
As noted, <code class="language-plaintext highlighter-rouge">seq_is_correct</code> is binary, either all tokens are correct or the sequence is wrong.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Token-level correctness
</span><span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">!=</span> <span class="n">IGNORE_LABEL_ID</span><span class="p">)</span>  <span class="c1"># Valid positions
</span><span class="n">is_correct</span> <span class="o">=</span> <span class="n">mask</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">logits</span><span class="sh">"</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># Sequence-level correctness (ALL tokens must be correct)
</span><span class="n">loss_counts</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Number of valid tokens per sequence
</span><span class="n">seq_is_correct</span> <span class="o">=</span> <span class="n">is_correct</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">loss_counts</span>  <span class="c1"># Boolean: all tokens correct?
</span></code></pre></div></div>

<p><strong>Continue Loss</strong></p>

<p>In addition, the authors also proposed to use the <strong>Q-Continue Loss</strong> (bootstrapped Q-values) (The question <code class="language-plaintext highlighter-rouge">Should we continue?</code> instead of <code class="language-plaintext highlighter-rouge">Should we halt?</code>).
However, as noted by the authors, while the <code class="language-plaintext highlighter-rouge">Q-continue</code> loss fits Q-learning, but seems totally unnecessary as the <code class="language-plaintext highlighter-rouge">Q-halt</code> loss is enough to learn the halting policy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="sh">"</span><span class="s">target_q_continue</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
    <span class="n">q_continue_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">binary_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">q_continue_logits</span><span class="sh">"</span><span class="p">],</span>  <span class="c1"># Predicted: should we continue?
</span>        <span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">target_q_continue</span><span class="sh">"</span><span class="p">],</span>  <span class="c1"># Target: bootstrapped Q-value from next state
</span>        <span class="n">reduction</span><span class="o">=</span><span class="sh">"</span><span class="s">sum</span><span class="sh">"</span>
    <span class="p">)</span>
</code></pre></div></div>

<p>where <code class="language-plaintext highlighter-rouge">target_q_continue</code> is the bootstrapped Q-value from the next state.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">target_q_continue</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="n">next_q_halt</span><span class="p">,</span> <span class="n">next_q_continue</span><span class="p">))</span>
</code></pre></div></div>

<p><strong>Total loss</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">total_loss</span> <span class="o">=</span> <span class="n">lm_loss</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">q_halt_loss</span> <span class="o">+</span> <span class="n">q_continue_loss</span><span class="p">)</span>
</code></pre></div></div>

<p>where <code class="language-plaintext highlighter-rouge">lm_loss</code> is the standard cross-entropy on token predictions.</p>

<p><strong>Training Dynamics of Q-Learning</strong></p>

<p><strong>Early phase: Init Q-head</strong></p>

<p>The Q-head is initialized to (almost) zero for faster learning during bootstrapping, i.e., never halts early (always uses max steps).
This forces the model to learn basic language understanding before adapting to the reasoning task.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Q head special init
# Init Q to (almost) zero for faster learning during bootstrapping
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">self</span><span class="p">.</span><span class="n">q_head</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>
    <span class="n">self</span><span class="p">.</span><span class="n">q_head</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="nf">fill_</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># type: ignore
</span></code></pre></div></div>

<p><strong>Phase 2: Learning to halt</strong></p>

<p>As language understanding improves, <code class="language-plaintext highlighter-rouge">seq_is_correct</code> becomes more frequent and reliable, <strong>Q-head</strong> starts to learn correlation between reasoning state and correctness, 
resulting in the model learning to halt early.</p>

<p><strong>Phase 3: Exploration Refinement</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Force trying different step counts
</span><span class="n">min_halt_steps</span> <span class="o">=</span> <span class="nf">random_int</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">halt_max_steps</span><span class="p">)</span> <span class="k">with</span> <span class="n">probability</span> <span class="n">ε</span>
</code></pre></div></div>

<p>The model <strong>exploration</strong> prevents the model always halts at the same step, thus leading to overfitting. This helps to discover optimal reasoning depth for different problems.</p>

<h2 id="applying-to-relation-extraction-problem">Applying to Relation Extraction problem</h2>

<h3 id="relation-extraction-re">Relation Extraction (RE)</h3>

<p>Relation Extraction (RE) is a core task in Natural Language Processing (NLP) that involves identifying and classifying semantic relationships between entities mentioned in text. 
For example, given the sentence <code class="language-plaintext highlighter-rouge">"John Smith is a patient of Dr. Emily Johnson"</code>, an RE system should detect the relationship between <code class="language-plaintext highlighter-rouge">John Smith</code> and <code class="language-plaintext highlighter-rouge">Dr. Emily Johnson</code> as <code class="language-plaintext highlighter-rouge">"patient of"</code>. 
Similarly, in the sentence <code class="language-plaintext highlighter-rouge">"Aspirin is used to treat headache"</code>, the identified relationship is <code class="language-plaintext highlighter-rouge">"used to treat"</code> between two entities <code class="language-plaintext highlighter-rouge">Aspirin</code> and <code class="language-plaintext highlighter-rouge">headache</code>.</p>

<p>The set of possible relationships is typically predefined and fixed for a given task. 
Importantly, the label <code class="language-plaintext highlighter-rouge">"no relation"</code> is also a valid category, indicating that no meaningful semantic link exists between the mentioned entities.</p>

<p>Traditional approaches to RE include rule-based methods, feature-based classifiers, and neural architectures leveraging contextual embeddings such as BERT. 
Recent advances, however, have explored formulating RE as a question answering (QA) problem, giving rise to methods such as QA4RE.</p>

<h3 id="biored-dataset">BioRED Dataset</h3>

<p>The dataset used in this demo is the <a href="https://github.com/ncbi/BioRED" rel="external nofollow noopener" target="_blank">BioRED dataset</a>. BioRED is a first-of-its-kind biomedical RE corpus with multiple entity types (e.g., gene/protein, disease, chemical) and relation pairs (e.g., gene-disease; chemical-chemical) at the document level, on a set of 600 PubMed abstracts.
The data, pretrained models (for the RE task) and annotation guidelines are provided in the link: <a href="https://ftp.ncbi.nlm.nih.gov/pub/lu/BioRED/" rel="external nofollow noopener" target="_blank">https://ftp.ncbi.nlm.nih.gov/pub/lu/BioRED/</a>.</p>

<h4 id="data-format">Data Format</h4>

<p>The BioRED dataset adopts the <a href="https://www.ncbi.nlm.nih.gov/research/pubtator" rel="external nofollow noopener" target="_blank">PubTator</a> format, a structured, plain-text representation commonly used for biomedical text annotations. Each document—typically a PubMed abstract—contains both text and text-bound annotations describing entities and relations. The format includes the following components:</p>

<ul>
  <li>
<strong>PMID:</strong> The PubMed identifier, followed by the document title and abstract text.</li>
  <li>
<strong>Entity annotations:</strong> Each entity is represented as <code class="language-plaintext highlighter-rouge">PMID \t start-index \t end-index \t text-span \t entity_type \t normalized_id</code>.</li>
  <li>
<strong>Relation annotations:</strong> Each relation is encoded as <code class="language-plaintext highlighter-rouge">PMID \t relation-type \t normalized_id1 \t normalized_id2 \t novelty</code>.</li>
</ul>

<p>An example of the PubTator-formatted document is shown below:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Example of PubTator-formatted document

15485686|t|A novel SCN5A mutation manifests as a ...

15485686|a|OBJECTIVE: Congenital long QT syndrome (LQTS) ...

15485686 8 13 SCN5A GeneOrGeneProduct 6331

15485686 56 72 long QT syndrome DiseaseOrPhenotypicFeature D008133

15485686 Association D001919 6331 Novel

15485686 Positive_Correlation D001919 p|SUB|V|1763|M Novel
</code></pre></div></div>

<p>Each document \(S\) may contain multiple entities \(E_i\) and relations \(R_{ij}\) between them. Importantly, no entity pair \((E_i, E_j)\) has more than one relation in the dataset—each pair is associated with at most a single relation \(R_{ij}\).</p>

<p>Thus, the task in BioRED can be defined as: given a document \(S\) and a set of entities \(E\), extract all relations \(R_{ij}\) that hold between entity pairs \((E_i, E_j)\) within the text.</p>

<h4 id="entity-types">Entity Types</h4>

<p>BioRED defines six entity types (five major biomedical categories and one infrequent type, <em>Cell Line</em>), each normalized to an external biomedical knowledge base. The entity taxonomy is summarized in the table below.</p>

<table>
  <thead>
    <tr>
      <th><strong>Entity Type</strong></th>
      <th><strong>Examples</strong></th>
      <th><strong>Normalization Source</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Gene (Protein)</td>
      <td>ABCA1, CYP2D6, BMP</td>
      <td>NCBI Gene</td>
    </tr>
    <tr>
      <td>Variant (Residue)</td>
      <td>S276T, rs2234671, c.435C&gt;G</td>
      <td>dbSNP</td>
    </tr>
    <tr>
      <td>Species</td>
      <td>
<em>Homo sapiens</em>, <em>E. coli</em>
</td>
      <td>NCBI Taxonomy</td>
    </tr>
    <tr>
      <td>Disease (Symptom)</td>
      <td>Hypertension, Alzheimer’s disease</td>
      <td>MEDIC (MeSH + OMIM)</td>
    </tr>
    <tr>
      <td>Chemical</td>
      <td>Terbutaline, Acetaminophen</td>
      <td>MeSH: Chemicals and Drugs</td>
    </tr>
    <tr>
      <td>Cell Line</td>
      <td>MCF7/AdrR</td>
      <td>Cellosaurus</td>
    </tr>
  </tbody>
</table>

<p><em>Entity types in BioRED and their corresponding normalization sources.</em></p>

<h4 id="relation-types">Relation Types</h4>

<p>BioRED defines a comprehensive set of pairwise relations between concept types. Each relation is explicitly typed—either directional or non-directional—and falls into one of three major semantic categories: 
<strong>Positive Correlation</strong>, <strong>Negative Correlation</strong>, or <strong>Association</strong>. 
In addition to these, several specialized relation types capture more specific biomedical interactions, including <strong>Bind</strong>, <strong>Co-treatment</strong>, <strong>Comparison</strong>, <strong>Drug Interaction</strong>, and <strong>Conversion</strong>.</p>

<p>During dataset preprocessing, a special category labeled <strong>None</strong> is added to represent negative examples, denoting entity pairs with no annotated relationship.</p>

<div class="row mt-3 text-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2025-tiny-recursive-reasoning/relations-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2025-tiny-recursive-reasoning/relations-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2025-tiny-recursive-reasoning/relations-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2025-tiny-recursive-reasoning/relations.png" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption text-center">
    Relations annotated in the BioRED corpus. (A) Major categories of relation types. (B) Mapping between concept pairs and relation types. Line thickness represents relative frequency of occurrence.
</div>

<h3 id="data-processing">Data Processing</h3>

<p>In order to apply the TRM to the RE task, we need to convert the BioRED dataset into the format that can be used by the TRM.
However, there are three main challenges making it is not straightforward:</p>

<ul>
  <li>Variable Text Length. The current TRM expects a fixed length input (i.e., for the Sudoku puzzle, the input is a 9x9 grid), but biomedical texts vary greatly in length. We need to set a larger sequence length and truncate/padding the texts if necessary.</li>
  <li>Classification vs Generation task. The TRM is designed for the generation task, while the original RE task is a classification task. One of the approaches can be used is to convert the RE task into a multiple-choice generation task, where the model needs to generate the relation type options for the given entity pairs.</li>
  <li>Entity awareness. Unlike the Sudoku puzzle, the input in RE task contains the full text of the document and the entity pairs. In the dataset, one document may contain multiple entity pairs with multiple relations between them. Therefore, in order to answer specific relation type for a specific entity pair, the model needs to be aware of that entity pair, distinguish it from other entity pairs. Some potential solutions can be: adding special marker tokens around entities, use entity type embedding or create position-aware prompts. In this demon, we use the simplest solution, that is, adding special marker tokens around entities and move the two entities to the beginning of the input sequence.</li>
</ul>

<p>The input format is shown below:</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input sequence:
[CLS] <span class="nt">&lt;E1&gt;</span> entity1_text <span class="nt">&lt;/E1&gt;</span> [SEP] <span class="nt">&lt;E2&gt;</span> entity2_text <span class="nt">&lt;/E2&gt;</span> [SEP] 
full_text [SEP]
Options: A) Association B) PositiveCorrelation C) ... [SEP]

Label sequence:
[-100, -100, ..., -100, A, -100, -100, ...]
                        ↑
                   Only supervise answer token
</code></pre></div></div>

<h2 id="references">References</h2>

<p>[1] Jolicoeur-Martineau, Alexia. “Less is More: Recursive Reasoning with Tiny Networks.” arXiv preprint arXiv:2510.04871 (2025).</p>

<p>[2] Luo, Ling, et al. “BioRED: a rich biomedical relation extraction dataset.” Briefings in Bioinformatics 23.5 (2022): bbac282.</p>

<!-- mkdir -p assets/img/2025-tiny-recursive-reasoning/ -->
<!-- mv _posts/2025-10-15-*.png assets/img/2025-tiny-recursive-reasoning/ -->

    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/nlp-foundation/">LLM Series - Part 1 - Important Concepts in NLP</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/diffusion-foundation/">Foundation of Diffusion Models</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/thoughts/">Random Thoughts and Notes</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/unlearn-llms/">Unlearning LLMs</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/deepseek/">DeepSeek-R1</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
