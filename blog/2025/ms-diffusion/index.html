<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>MS-Diffusion - Multi-subject Zero-shot Image Personalization with Layout Guidance (ICLR 2025) | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="Researcher in Generative AI and Trustworthy AI
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2025/ms-diffusion/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->
<!-- Page/Post style -->
<style type="text/css">
  
</style>


<div class="post">

  <header class="post-header">
    <h1 class="post-title">MS-Diffusion - Multi-subject Zero-shot Image Personalization with Layout Guidance (ICLR 2025)</h1>
    <p class="post-meta">March 15, 2025</p>
    <p class="post-tags">
      <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>
        ·  
        <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          <a href="/blog/tag/genai">
          <i class="fas fa-hashtag fa-sm"></i> genai</a>  
          <a href="/blog/tag/diffusion">
          <i class="fas fa-hashtag fa-sm"></i> diffusion</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#key-contributions">Key contributions</a></li>
<li class="toc-entry toc-h2"><a href="#background-stable-diffusion-with-image-prompt">Background: Stable Diffusion with Image Prompt</a></li>
<li class="toc-entry toc-h2">
<a href="#proposed-method">Proposed Method</a>
<ul>
<li class="toc-entry toc-h3"><a href="#grounding-resampler">Grounding Resampler</a></li>
<li class="toc-entry toc-h3"><a href="#data-construction">Data Construction</a></li>
<li class="toc-entry toc-h3"><a href="#multi-subject-cross-attention">Multi-subject Cross-attention</a></li>
</ul>
</li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <p>Link to the paper: <a href="https://openreview.net/forum?id=PJqP0wyQek" rel="external nofollow noopener" target="_blank">MS-Diffusion: Multi-subject Zero-shot Image Personalization with Layout Guidance</a></p>

<p>Link to github: <a href="https://github.com/MS-Diffusion/MS-Diffusion" rel="external nofollow noopener" target="_blank">MS-Diffusion</a></p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2025-ms-diffusion/2025-03-19-11-52-11-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2025-ms-diffusion/2025-03-19-11-52-11-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2025-ms-diffusion/2025-03-19-11-52-11-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2025-ms-diffusion/2025-03-19-11-52-11.png" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<h2 id="key-contributions">Key contributions</h2>

<p><strong>Challenges</strong></p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2025-ms-diffusion/2025-03-19-11-56-18-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2025-ms-diffusion/2025-03-19-11-56-18-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2025-ms-diffusion/2025-03-19-11-56-18-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2025-ms-diffusion/2025-03-19-11-56-18.png" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<p>Personalizing with multiple subjects is challenging, specifically:</p>

<ul>
  <li>
<strong>Subject neglect</strong>: one or more subjects are not properly represented in the generated image.</li>
  <li>
<strong>Subject overcontrol</strong>: The output does not match with the input prompt (e.g., “a dog and a cat on the beach” - but the output is not on the beach). The appearance or placement of a subject is unduly influenced by its reference image, potentially overriding the textual prompt or other subject conditions.</li>
  <li>
<strong>Subject-subject conflict</strong>:  where the interaction between multiple subjects in the generated image is unrealistic or undesirable, i.e., two similar dog and cat.</li>
</ul>

<p>The reasons for these challenges are:</p>

<ul>
  <li>
<strong>Difficulty in feature representation</strong>: compare to text embedding, image embedding are generally <strong>sparser and contain more information</strong>, making their projection into the condition space more difficult. The pooled output from the image encoder can omit many details (discussed in Section 3.4 of the paper). This can lead to a loss of granular details of individual subjects.</li>
  <li>
<strong>Complexity of Multi-subject interaction and control</strong>: Ensuring that the generated image aligns with the textual prompt while maintaining the correct placement and appearance of each subject is challenging.</li>
</ul>

<p><strong>Contributions</strong></p>

<ul>
  <li>
<strong>Grounding Resampler</strong>: A modified cross-attention layer that uses concatenated image and text embeddings as the condition embedding.</li>
  <li>
<strong>Data Construction</strong>: A data construction pipeline to collect a large amount of data with multiple subjects in the same image.</li>
  <li>
<strong>Multi-subject Cross-attention with Masks</strong>: A modified cross-attention layer that uses subject-specific masks to guide the model to pay attention to the subject.</li>
</ul>

<h2 id="background-stable-diffusion-with-image-prompt">Background: Stable Diffusion with Image Prompt</h2>

<p>Beyond controlling the generation process using text prompt, there is a hot topic in the community to control using image information/layout/prompt - which has a huge potential in applications, e.g., image inpainting, image-to-image generation, etc. In the standard Stable Diffusion, the condition embedding \(c_t\) is just a text embedding \(c_t = E_t(y)\) where \(y\) is the text prompt and \(E_t\) is a pre-trained text encoder such as CLIP.
IP-Adapter [1] proposes to use an additional image encoder to extract the image embedding from a reference image \(c_i = E_i(x)\) and then project it into the original condition space.
The objective function for IP-Adapter is:</p>

\[\mathcal{L}_{IP} = \mathbb{E}_{z, c, \epsilon, t} \left[ \mid \mid \epsilon - \epsilon_\theta(z_t \mid c_i, c_t, t) \mid \mid_2^2 \right]\]

<p>The cross-attention layer is also modified from the one in Stable Diffusion to include the image embedding \(c_i\) as a condition.</p>

\[\text{Attention}(Q, K_i, K_t, V_i, V_t) = \lambda \text{softmax}\left(\frac{QK_i^T}{\sqrt{d}} + c_i\right)V_i + \text{softmax}\left(\frac{QK_t^T}{\sqrt{d}}\right)V_t\]

<p>where \(Q=z W_Q\), \(K_i = c_i W_K^i\), \(K_t = c_t W_K^t\), \(V_i = c_i W_V^i\), \(V_t = c_t W_V^t\), and \(W_Q\), \(W_K^i\), \(W_K^t\), \(W_V^i\), \(W_V^t\) are the weights of the linear layers.
The model becomes the original Stable Diffusion when \(\lambda = 0\).</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/diffusion-foundation/2025-03-20-07-02-10-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/diffusion-foundation/2025-03-20-07-02-10-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/diffusion-foundation/2025-03-20-07-02-10-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/diffusion-foundation/2025-03-20-07-02-10.png" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<h2 id="proposed-method">Proposed Method</h2>

<h3 id="grounding-resampler">Grounding Resampler</h3>

\[\text{RSAttn} = \text{softmax}\left( \frac{Q(f_q) K^T([c_i, c_q])}{\sqrt{d}} \right) V([c_i, c_q])\]

<p>where \(c_q\) is the learnable query feature, \(c_i\) is the image embedding.</p>

<p>My interpretation:</p>

<ul>
  <li>The grounding resampler is a modified cross-attention layer that uses the image embedding and the learnable query feature to generate the attention score.</li>
  <li>Compared to the previous IP-Adapter which uses the image and text embeddings <strong>separately</strong>, the \(\text{RSAttn}\) uses the concatenation of the two embeddings as the unified condition embedding.</li>
</ul>

<h3 id="data-construction">Data Construction</h3>

<p>The authors propose a data construction pipeline to <strong>collect</strong> a large amount of <strong>data with multiple subjects</strong> in the same image.
\(c_q\) was initialized by the <strong>text embedding</strong> of the entities (e.g., “dog”, “cat”, “beach”) and then optimized during training.
\(c_i\) is the <strong>image embedding</strong> of corresponding subject - detected by an <strong>additional object detector</strong>.</p>

<p>To prevent the model becoming overfitted/dependent on the grounding tokens (e.g., “dog”, “cat”) during inference <strong>(?)</strong>, the authors proposed to randomly replace these tokens with the original learnable queries in the training <strong>(?)</strong>.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2025-ms-diffusion/2025-03-20-07-14-27-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2025-ms-diffusion/2025-03-20-07-14-27-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2025-ms-diffusion/2025-03-20-07-14-27-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2025-ms-diffusion/2025-03-20-07-14-27.png" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<h3 id="multi-subject-cross-attention">Multi-subject Cross-attention</h3>

<p>The idea is to <strong>incorporate attention masks within cross-attention layers</strong> to focus on the relevant subjects and exclude other irrelevant in the text prompt and visual prompt.</p>

\[\mathbf{M}_j(x, y) = \begin{cases}
0 &amp; \text{if } [x, y] \in B_j \\
-\infty &amp; \text{if } [x, y] \notin B_j
\end{cases}\]

<p>Here, \(B_j\) denotes the coordinate set of <strong>bounding boxes related to the \(j\)th subject</strong>. By this means, the conditional image latent \(\hat{\mathbf{z}}_{img}\) is derived through:</p>

\[\hat{\mathbf{z}}_{img} = \text{Softmax}\left(\frac{\mathbf{Q}\mathbf{K}_i^\top}{\sqrt{d}} + \mathbf{M}\right)\mathbf{V}_i\]

<p>Herein, \(\mathbf{M}\) represents the concatenation of all subject-specific masks, \(\text{Concat}(\mathbf{M}_0,\ldots,\mathbf{M}_n)\). In this way, the model ensures each subject to be represented in a certain area, thus resolving the issues of subject neglect and conflict.</p>

<p><strong>Mask for Background</strong></p>

\[\mathbf{M}_{bg}(x, y) = \begin{cases}
1 &amp; \text{if } [x, y] \in B_{bg} \\
0 &amp; \text{if } [x, y] \notin B_{bg} \text{ a.k.a. subjects}
\end{cases}\]

<p>The mask for background is a matrix of the same size as the image, with the value of \(1\) for the background and \(0\) for the subjects.</p>

\[\mathbf{z}_{img} = (1 - \mathbf{M}_{bg}) \odot \mathbf{z}_{img}\]

<p>Where \(\odot\) is the element-wise multiplication. This operation ensures that the background is removed from the image latent.
As the authors mentioned, this approach is to ensure that text conditions predominate over areas lacking of any guided information (a.k.a. background).</p>

<p><strong>My interpretation:</strong></p>

<ul>
  <li>The mask \(\mathbf{M}\) is a matrix of the same size as the image, with the value of \(-\infty\) for the background and \(0\) for the subject.</li>
  <li>The mask is added to the attention score matrix \(\mathbf{Q}\mathbf{K}_i^\top\) to <strong>guide the model to pay attention to the subject</strong>.</li>
</ul>

<p><strong>Question</strong>: Where the \(\mathbf{z}_{img}\) is used? The authors did not use a consistent notations throughout the paper.</p>

<!-- mkdir -p assets/img/2025-ms-diffusion/ -->
<!-- mv _posts/2025-03-20-*.png assets/img/2025-ms-diffusion/ -->

    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/nlp-foundation/">LLM Series - Part 1 - Important Concepts in NLP</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/erasing-concepts/">Fake Taylor Swift and the Adversarial Game of Concept Erasure and Injection</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/unlearn-llms/">Unlearning LLMs</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/thoughts/">Random Thoughts and Notes</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/deepseek/">DeepSeek-R1</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
