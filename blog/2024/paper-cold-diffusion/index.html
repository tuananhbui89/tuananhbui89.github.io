<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Cold Diffusion - Inverting Arbitrary Image Transforms Without Noise | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="Can we replace the Gaussian noise in the degradation process with an image transformation operation">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2024/paper-cold-diffusion/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->
<!-- Page/Post style -->
<style type="text/css">
  
</style>


<div class="post">

  <header class="post-header">
    <h1 class="post-title">Cold Diffusion - Inverting Arbitrary Image Transforms Without Noise</h1>
    <p class="post-meta">April 19, 2024</p>
    <p class="post-tags">
      <a href="/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a>
        ·  
        <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          <a href="/blog/tag/tml">
          <i class="fas fa-hashtag fa-sm"></i> tml</a>  
          <a href="/blog/tag/diffusion">
          <i class="fas fa-hashtag fa-sm"></i> diffusion</a>  
          <a href="/blog/tag/genai">
          <i class="fas fa-hashtag fa-sm"></i> genai</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#about-the-paper">About the paper</a></li>
<li class="toc-entry toc-h2">
<a href="#method">Method</a>
<ul>
<li class="toc-entry toc-h3"><a href="#what-is-the-cold-diffusion-model">What is the cold diffusion model?</a></li>
<li class="toc-entry toc-h3"><a href="#how-to-sampling">How to sampling?</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#reflectionthoughts">Reflection/Thoughts</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <h2 id="about-the-paper">About the paper</h2>

<ul>
  <li>Accepted to NeurIPS 2023.</li>
  <li>From Tom Goldstein’s group at University of Maryland. Tom and his postdoc Micah Goldblum are two favorite leading researchers of mine. His group has published many interesting, creative and trendy (of course <img class="emoji" title=":joy:" alt=":joy:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png" height="20" width="20">) papers in the field of ML, particullary in Trustworthy Machine Learning. Recently, his group won the best paper award at ICML 2023 for the watermarking on LLM paper. So good.</li>
  <li>Link to the paper: <a href="https://arxiv.org/abs/2208.09392" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2208.09392</a>
</li>
  <li>Github: <a href="https://github.com/arpitbansal297/Cold-Diffusion-Models" rel="external nofollow noopener" target="_blank">https://github.com/arpitbansal297/Cold-Diffusion-Models</a>
</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/202403/cold-diffusion-example-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/202403/cold-diffusion-example-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/202403/cold-diffusion-example-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/202403/cold-diffusion-example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<p>Many papers on diffusion models primarily focus on the diffusion/degradation process through the addition of Gaussian noise. This method involves introducing small amounts of Gaussian noise to an image during the forward diffusion process, gradually resulting in a heavily noised image. Conceptually, this noising process can be likened to a random walk on a manifold if we consider the data space as such. The objective of a diffusion model is to effectively reverse this degradation process, aiming to reconstruct the original image from its noised version.</p>

<p>In this paper, the authors posed an intriguing question: <strong><em>“Can we replace the Gaussian noise in the degradation process with an image transformation operation, such as blurring, pixelation, or masking?”</em></strong>.
Surprisingly, this work demonstrated that it is indeed possible. The authors proposed a generalized diffusion model, termed <strong><em>Cold Diffusion</em></strong>, that can employ arbitrary image transformations in the degradation process. The model is trained to invert these transformations and recover the original image. By using some generation tricks, the model not only can recover the original image but also can generate new/novel images. 
This work opens up a new direction for diffusion models, allowing them to be applied to a broader range of image transformations beyond Gaussian noise.</p>

<h2 id="method">Method</h2>

<h3 id="what-is-the-cold-diffusion-model">What is the cold diffusion model?</h3>

<p>The proposed cold diffusion model presents a straightforward mathematical formulation (I still wonder why they called it “cold” <img class="emoji" title=":joy:" alt=":joy:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png" height="20" width="20">).
Given an input image \(x\) and a transformation function \(D\), the reverse process is parameterized by a neural network \(R_\theta\):</p>

\[\underset{\theta}{\min} \mathbb{E}_{x \sim \mathcal{X}} \| R_\theta(D(x,t),t) - x \|\]

<p>To train the standard diffusion models such as DDPM, the high level idea is to match the predicted noise with the true noise added at particular diffusion step.
However, in the cold diffusion model, the above objective is actually more similar to the autoencoder, i.e., the model is trained to minimize the difference between the input image and the recovered image. The difference to the autoencoder is that the degradation process is done by a transformation function \(D\) not by an encoder, and more importantly, is done through a series of steps, not just one step.
To me, the more similar to the diffusion model might be the paper <a href="https://arxiv.org/abs/2209.05442" rel="external nofollow noopener" target="_blank">Soft Diffusion: Score Matching for General Corruptions</a>.</p>

<h3 id="how-to-sampling">How to sampling?</h3>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/202403/cold-diffusion-algorithm-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/202403/cold-diffusion-algorithm-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/202403/cold-diffusion-algorithm-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/202403/cold-diffusion-algorithm.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<p>Naively, after training the cold diffusion model, we can sample the image as the algorithm 1 above, i.e., at each step, we apply diffusion inversion (read more about it <a href="https://tuananhbui89.github.io/blog/2023/diffusion-tutorial-p2/#diffusion-inversion">here</a>) to predict the original image from current step \(\hat{x}_0 = R(x_s, s)\), then apply the transformation function \(D\) to get the next step \(x_{s-1} = D(\hat{x}_0, s-1)\), and so on.
It is worth noting that in the standard diffusion model, the initial image \(x_T\) is sampled from a Gaussian distribution; however,
in this cold diffusion model, the initial image (they called it “a degraded sample”) is sampled from the final step of the degradation process, i.e., \(x_T = D(x_0, T)\).
It is make sense to me because there is no mathematical formulation for the degradation process unlike as in the standard one, where \(x_T \sim \mathcal{N}(0, I)\). (Refer to Section 5.2 in the paper).</p>

<p>So the author proposed some tricks to improve the sampling process:</p>

<ul>
  <li>Using Algorithm 2 instead of Algorithm 1 to mitigate the compounding error from the imperfect inversion function \(R_\theta\). It is based on the approximation \(D(x,s) \approx x + s . e(x) + HOT\), where \(e(x)\) is the gradient of the transformation function \(D\) at \(x\), but be considered as a constant vector (not dependent on \(s\), questionable to me). The HOT term is the higher order terms that can be ignored. But this trick is just to help the recovery process, not the generation or introducing better diversity/novelty to the generated images.</li>
  <li>The key trick to improve the diversity is to add a small amount of noise in each sample \(x_T\).</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/202403/cold-diffusion-sample-trick-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/202403/cold-diffusion-sample-trick-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/202403/cold-diffusion-sample-trick-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/202403/cold-diffusion-sample-trick.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/202403/cold-diffusion-meme-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/202403/cold-diffusion-meme-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/202403/cold-diffusion-meme-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/202403/cold-diffusion-meme.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<h2 id="reflectionthoughts">Reflection/Thoughts</h2>

<p>So after the success of this paper, we might ask “What is the core of the diffusion model that makes it work?” To me, there are few key components:</p>

<ul>
  <li>The two opposite processes: degradation and recovery. Interestingly, the degradation process can be done by a wide range of operations, even with animorphosis operators, that adds a random animal image to the original image. At the end of the degradation process, the image is still a valid image (clean and clear under human eyes). Therefore, to me, the final goal of the degradation process is to remove totally the information of the original image, not to make the image unrecognizable (nothing to do with human preception here). Mathematically, \(I(x, D(x,t)) \to 0\) when \(t\) becomes larger, where \(I\) is the mutual information between \(x\) and \(D(x,t)\).</li>
  <li>The iterative process: the diffusion/degradation process is done through a series of steps, not just one step.</li>
  <li>What is the source of stochasticity which decides the novelty of the generated images?</li>
</ul>

    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec06/">MIT 6.S184 - Lecture 6 - Diffusion for Protein Generation</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec05/">MIT 6.S184 - Lecture 5 - Diffusion for Robotics</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec04/">MIT 6.S184 - Lecture 4 - Building an Image Generator</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec03/">MIT 6.S184 - Lecture 3 - Training Flow and Diffusion Models</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mit-6s184-lec02/">MIT 6.S184 - Lecture 2 -  Constructing a Training Target</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
