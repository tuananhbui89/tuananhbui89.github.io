<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>What is Safety Checker in Stable Diffusion | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="Researcher in Generative AI and Trustworthy AI
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://tuananhbui89.github.io/blog/2024/safety-checker/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->
<!-- Page/Post style -->
<style type="text/css">
  
</style>


<div class="post">

  <header class="post-header">
    <h1 class="post-title">What is Safety Checker in Stable Diffusion</h1>
    <p class="post-meta">December 18, 2024</p>
    <p class="post-tags">
      <a href="/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a>
        ·  
        <a href="/blog/tag/reading">
          <i class="fas fa-hashtag fa-sm"></i> reading</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="table-of-contents">
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2">
<a href="#approaches-to-prevent-unwanted-content-in-generative-models">Approaches to Prevent Unwanted Content in Generative Models</a>
<ul>
<li class="toc-entry toc-h3"><a href="#pre-training">Pre-training</a></li>
<li class="toc-entry toc-h3"><a href="#post-training">Post-training</a></li>
<li class="toc-entry toc-h3"><a href="#fine-tuning-or-concepts-unlearning">Fine-tuning or Concepts Unlearning</a></li>
<li class="toc-entry toc-h3"><a href="#self-protection-with-unlearnable-invisible-masks">Self-protection with Unlearnable Invisible Masks</a></li>
<li class="toc-entry toc-h3"><a href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#what-the-heck-is-safety-checker">What the heck is Safety Checker?</a>
<ul>
<li class="toc-entry toc-h3"><a href="#how-to-use-the-safety-checker-in-the-ldm-library">How to use the Safety Checker in the ldm library</a></li>
<li class="toc-entry toc-h3"><a href="#key-components">Key Components</a></li>
<li class="toc-entry toc-h3"><a href="#the-detection-process">The Detection Process</a></li>
<li class="toc-entry toc-h3"><a href="#how-to-get-the-selfconcept_embeds">How to get the self.concept_embeds?</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#how-to-bypass-the-safety-checker">How to bypass the Safety Checker?</a></li>
<li class="toc-entry toc-h2"><a href="#conclusion">Conclusion</a></li>
</ul>
    </div>
    <hr>
    
    <div id="markdown-content">
      <p>With the rapid development of generative AI models, the risk of misuse-generated content has become critical. In this post, I will discuss four main approaches to preventing unwanted content in foundation models and then dive into the implementation of the Safety Checker, the most popular and practical approach used in real-world GenAI applications such as Stable Diffusion or Midjourney.</p>

<h2 id="approaches-to-prevent-unwanted-content-in-generative-models">Approaches to Prevent Unwanted Content in Generative Models</h2>

<p>Preventing unwanted content generated by foundation models, such as Stable Diffusion, involves several strategies. Below, we explore four main approaches:</p>

<h3 id="pre-training">Pre-training</h3>

<p>This approach involves filtering out unwanted content and retraining the model from scratch. While effective, it is prohibitively expensive. For instance, as noted in <a href="https://www.databricks.com/blog/stable-diffusion-2" rel="external nofollow noopener" target="_blank">this blog post</a>, training a Stable Diffusion-level model from scratch with MosaicML costs approximately $50,000.
This estimate excludes data preprocessing costs, making it economically unfeasible for frequent updates.</p>

<p>Major updates or retraining may occur in response to significant ethical concerns, but they are not suitable for addressing frequent issues like user-generated reports. For example, after the incident involving fake explicit images of Taylor Swift, other celebrities requested similar protections as reported in <a href="https://variety.com/vip/celebrity-reps-fighting-flood-unauthorized-ai-content-1236149088/" rel="external nofollow noopener" target="_blank">this article</a>. Or another example, <a href="https://www.siliconrepublic.com/machines/fairly-trained-ai-training-data" rel="external nofollow noopener" target="_blank">a recent statement signed by more than 13,000 creatives</a> from around the world, including famous actors, singers and authors, warning artificial intelligence (AI) companies that the unlicensed use of their work to train generative AI models is a “major, unjust threat” to their livelihoods. Addressing these cases through pre-training would be highly impractical.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/safety_checker/training_cost-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/safety_checker/training_cost-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/safety_checker/training_cost-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/safety_checker/training_cost.png" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption text-center">
    The cost of training a Stable-Diffusion level model from scratch.
</div>

<h3 id="post-training">Post-training</h3>

<p>In this approach, inappropriate content is detected and censored in the generated output by a safety checker deployed by the model’s developer. Post-training is more economical compared to pre-training, requiring minimal effort or changes to the model’s development pipeline.
For instance, a safety checker—discussed in the next section—relies on embedding similarity matching (e.g., using CLIP or multimodal embeddings). These systems can be updated quickly in response to user requests.
This method is particularly effective for closed-source models like OpenAI’s or MidJourney’s, where users access the model only via API, therefore, should have higher priorities to be focused on in addressing user’s requests.</p>

<p>However, for open-source models like Stable Diffusion, where users have access to model parameters and source code, this approach can be bypassed with a few lines of code as shown in the figure below, making it ineffective.
Even closed-source models are vulnerable to recent <a href="https://github.com/yueliu1999/Awesome-Jailbreak-on-LLMs?tab=readme-ov-file#black-box-attack" rel="external nofollow noopener" target="_blank">black-box jailbreak techniques</a>, which exploit the transferability of adversarial examples between surrogate and target models (e.g., between open-source models like Stable Diffusion and closed-source models like Dall-E).</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/safety_checker/bypass_nsfw-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/safety_checker/bypass_nsfw-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/safety_checker/bypass_nsfw-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/safety_checker/bypass_nsfw.png" class="img-fluid rounded z-depth-1" width="600" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption text-center">
    Bypassing the NSFW detector of Stable Diffusion.
</div>

<h3 id="fine-tuning-or-concepts-unlearning">Fine-tuning or Concepts Unlearning</h3>

<p>The goal of fine-tuning is to adjust the model’s parameters to “unlearn” its ability to generate unwanted content. Conceptually, the model retains the capability to generate such content, but access to this capability becomes hidden, making it difficult for public users to exploit. From a research perspective, this approach is robust, reliable, and presents numerous opportunities for exploration. Practically, fine-tuning is also efficient, requiring only a few thousand iterations—a process that typically completes within a few hours—without needing additional data (e.g., our methods :D).</p>

<h3 id="self-protection-with-unlearnable-invisible-masks">Self-protection with Unlearnable Invisible Masks</h3>

<p>Unlike the previous three approaches, which are developer-centric, this method is user-centric. The idea is users add an unlearnable invisible mask to their personal data before publishing it publicly, e.g., through a default setting in camera app (entrepreneur idea alert :D).
Even if the data is collected by a model, the mask prevents the model from learning the personal data, thereby hindering it from generating related content. This approach has garnered attention from the research community, with notable works like <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Towards_Efficient_Data_Free_Black-Box_Adversarial_Attack_CVPR_2022_paper.html" rel="external nofollow noopener" target="_blank">MIST</a>, <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.html" rel="external nofollow noopener" target="_blank">Anti-Dreambooth</a>, <a href="https://arxiv.org/pdf/2310.02401" rel="external nofollow noopener" target="_blank">FT-Shield</a>, or <a href="https://openreview.net/pdf?id=lroEEGApa4" rel="external nofollow noopener" target="_blank">Meta-Cloak</a>. It could be a million dollar idea if it works, but unfortunately, to the best of my knowledge, even the SOTA methods are still be bypassed by transformation-based or auto-encoder based jailbreak techniques.</p>

<h3 id="summary">Summary</h3>

<p>For open-source models like Stable Diffusion, the fine-tuning approach offers the most promise and economic viability. On the other hand, for closed-source models like OpenAI or MidJourney, post-training methods are the most efficient and should take precedence.</p>

<p>In the next section, we delve deeper into the mechanics of the Safety Checker. The implementation for this module can be found in the <a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/safety_checker.py" rel="external nofollow noopener" target="_blank">diffusers library (version 0.32.0 as the time of writing)</a>.</p>

<h2 id="what-the-heck-is-safety-checker">What the heck is Safety Checker?</h2>

<p>The <code class="language-plaintext highlighter-rouge">StableDiffusionSafetyChecker</code> module is designed to detect NSFW (Not Safe For Work) or inappropriate content in generated images. In the case a NSFW content is detected, the safety action will be taken, i.e., the output images will be censored and a warning message will be returned.</p>

<p>Below is the implementation of this module in the diffusers library for readers’ convenience</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">CLIPConfig</span><span class="p">,</span> <span class="n">CLIPVisionModel</span><span class="p">,</span> <span class="n">PreTrainedModel</span>

<span class="kn">from</span> <span class="n">...utils</span> <span class="kn">import</span> <span class="n">logging</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="nf">get_logger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">cosine_distance</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">text_embeds</span><span class="p">):</span>
    <span class="n">normalized_image_embeds</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">)</span>
    <span class="n">normalized_text_embeds</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">text_embeds</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">normalized_image_embeds</span><span class="p">,</span> <span class="n">normalized_text_embeds</span><span class="p">.</span><span class="nf">t</span><span class="p">())</span>


<span class="k">class</span> <span class="nc">StableDiffusionSafetyChecker</span><span class="p">(</span><span class="n">PreTrainedModel</span><span class="p">):</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">CLIPConfig</span>
    <span class="n">main_input_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">clip_input</span><span class="sh">"</span>

    <span class="n">_no_split_modules</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">CLIPEncoderLayer</span><span class="sh">"</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CLIPConfig</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">vision_model</span> <span class="o">=</span> <span class="nc">CLIPVisionModel</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">vision_config</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">visual_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">vision_config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">projection_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">concept_embeds</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">projection_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">special_care_embeds</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">projection_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">concept_embeds_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">17</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">special_care_embeds_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">clip_input</span><span class="p">,</span> <span class="n">images</span><span class="p">):</span>
        <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">vision_model</span><span class="p">(</span><span class="n">clip_input</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pooled_output
</span>        <span class="n">image_embeds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">visual_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>

        <span class="c1"># we always cast to float32 as this does not cause significant overhead and is compatible with bfloat16
</span>        <span class="n">special_cos_dist</span> <span class="o">=</span> <span class="nf">cosine_distance</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">special_care_embeds</span><span class="p">).</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">float</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
        <span class="n">cos_dist</span> <span class="o">=</span> <span class="nf">cosine_distance</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">concept_embeds</span><span class="p">).</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">float</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>

        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">image_embeds</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">result_img</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">special_scores</span><span class="sh">"</span><span class="p">:</span> <span class="p">{},</span> <span class="sh">"</span><span class="s">special_care</span><span class="sh">"</span><span class="p">:</span> <span class="p">[],</span> <span class="sh">"</span><span class="s">concept_scores</span><span class="sh">"</span><span class="p">:</span> <span class="p">{},</span> <span class="sh">"</span><span class="s">bad_concepts</span><span class="sh">"</span><span class="p">:</span> <span class="p">[]}</span>

            <span class="c1"># increase this value to create a stronger `nfsw` filter
</span>            <span class="c1"># at the cost of increasing the possibility of filtering benign images
</span>            <span class="n">adjustment</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="k">for</span> <span class="n">concept_idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">special_cos_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                <span class="n">concept_cos</span> <span class="o">=</span> <span class="n">special_cos_dist</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">concept_idx</span><span class="p">]</span>
                <span class="n">concept_threshold</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">special_care_embeds_weights</span><span class="p">[</span><span class="n">concept_idx</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>
                <span class="n">result_img</span><span class="p">[</span><span class="sh">"</span><span class="s">special_scores</span><span class="sh">"</span><span class="p">][</span><span class="n">concept_idx</span><span class="p">]</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="n">concept_cos</span> <span class="o">-</span> <span class="n">concept_threshold</span> <span class="o">+</span> <span class="n">adjustment</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">result_img</span><span class="p">[</span><span class="sh">"</span><span class="s">special_scores</span><span class="sh">"</span><span class="p">][</span><span class="n">concept_idx</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">result_img</span><span class="p">[</span><span class="sh">"</span><span class="s">special_care</span><span class="sh">"</span><span class="p">].</span><span class="nf">append</span><span class="p">({</span><span class="n">concept_idx</span><span class="p">,</span> <span class="n">result_img</span><span class="p">[</span><span class="sh">"</span><span class="s">special_scores</span><span class="sh">"</span><span class="p">][</span><span class="n">concept_idx</span><span class="p">]})</span>
                    <span class="n">adjustment</span> <span class="o">=</span> <span class="mf">0.01</span>

            <span class="k">for</span> <span class="n">concept_idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">cos_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                <span class="n">concept_cos</span> <span class="o">=</span> <span class="n">cos_dist</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">concept_idx</span><span class="p">]</span>
                <span class="n">concept_threshold</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">concept_embeds_weights</span><span class="p">[</span><span class="n">concept_idx</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>
                <span class="n">result_img</span><span class="p">[</span><span class="sh">"</span><span class="s">concept_scores</span><span class="sh">"</span><span class="p">][</span><span class="n">concept_idx</span><span class="p">]</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="n">concept_cos</span> <span class="o">-</span> <span class="n">concept_threshold</span> <span class="o">+</span> <span class="n">adjustment</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">result_img</span><span class="p">[</span><span class="sh">"</span><span class="s">concept_scores</span><span class="sh">"</span><span class="p">][</span><span class="n">concept_idx</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">result_img</span><span class="p">[</span><span class="sh">"</span><span class="s">bad_concepts</span><span class="sh">"</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">concept_idx</span><span class="p">)</span>

            <span class="n">result</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">result_img</span><span class="p">)</span>

        <span class="n">has_nsfw_concepts</span> <span class="o">=</span> <span class="p">[</span><span class="nf">len</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="sh">"</span><span class="s">bad_concepts</span><span class="sh">"</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">result</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">has_nsfw_concepts</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">has_nsfw_concept</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">is_tensor</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="ow">or</span> <span class="n">torch</span><span class="p">.</span><span class="nf">is_tensor</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>  <span class="c1"># black image
</span>                <span class="k">else</span><span class="p">:</span>
                    <span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># black image
</span>
        <span class="k">if</span> <span class="nf">any</span><span class="p">(</span><span class="n">has_nsfw_concepts</span><span class="p">):</span>
            <span class="n">logger</span><span class="p">.</span><span class="nf">warning</span><span class="p">(</span>
                <span class="sh">"</span><span class="s">Potential NSFW content was detected in one or more images. A black image will be returned instead.</span><span class="sh">"</span>
                <span class="sh">"</span><span class="s"> Try again with a different prompt and/or seed.</span><span class="sh">"</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">has_nsfw_concepts</span>
</code></pre></div></div>

<p>and how this module is used in the Stable Diffusion pipeline, e.g., in this file <a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">pipelines/stable_diffusion/pipeline_stable_diffusion.py</code></a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_safety_checker</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">safety_checker</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">is_tensor</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
            <span class="n">feature_extractor_input</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">image_processor</span><span class="p">.</span><span class="nf">postprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="sh">"</span><span class="s">pil</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feature_extractor_input</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">image_processor</span><span class="p">.</span><span class="nf">numpy_to_pil</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">safety_checker_input</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">feature_extractor</span><span class="p">(</span><span class="n">feature_extractor_input</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">safety_checker</span><span class="p">(</span>
            <span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">clip_input</span><span class="o">=</span><span class="n">safety_checker_input</span><span class="p">.</span><span class="n">pixel_values</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span>
</code></pre></div></div>

<h3 id="how-to-use-the-safety-checker-in-the-ldm-library">How to use the Safety Checker in the <code class="language-plaintext highlighter-rouge">ldm</code> library</h3>

<p>in the <code class="language-plaintext highlighter-rouge">ldm</code> library, the <code class="language-plaintext highlighter-rouge">safety_checker</code> is first loaded from pre-trained checkpoint which is converted from the <code class="language-plaintext highlighter-rouge">diffusers</code> library, and then passed to the <code class="language-plaintext highlighter-rouge">StableDiffusionPipeline</code> class,
e.g., in this file <a href="https://github.com/CompVis/stable-diffusion/blob/main/scripts/txt2img.py" rel="external nofollow noopener" target="_blank">https://github.com/CompVis/stable-diffusion/blob/main/scripts/txt2img.py</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">diffusers</span> <span class="kn">import</span> <span class="n">StableDiffusionSafetyChecker</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoFeatureExtractor</span>

<span class="c1"># load safety model
</span><span class="n">safety_model_id</span> <span class="o">=</span> <span class="sh">"</span><span class="s">CompVis/stable-diffusion-safety-checker</span><span class="sh">"</span>
<span class="n">safety_feature_extractor</span> <span class="o">=</span> <span class="n">AutoFeatureExtractor</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">safety_model_id</span><span class="p">)</span>
<span class="n">safety_checker</span> <span class="o">=</span> <span class="n">StableDiffusionSafetyChecker</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">safety_model_id</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">check_safety</span><span class="p">(</span><span class="n">x_image</span><span class="p">):</span>
    <span class="n">safety_checker_input</span> <span class="o">=</span> <span class="nf">safety_feature_extractor</span><span class="p">(</span><span class="nf">numpy_to_pil</span><span class="p">(</span><span class="n">x_image</span><span class="p">),</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">x_checked_image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="nf">safety_checker</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">x_image</span><span class="p">,</span> <span class="n">clip_input</span><span class="o">=</span><span class="n">safety_checker_input</span><span class="p">.</span><span class="n">pixel_values</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">x_checked_image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">has_nsfw_concept</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">has_nsfw_concept</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">has_nsfw_concept</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">x_checked_image</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nf">load_replacement</span><span class="p">(</span><span class="n">x_checked_image</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x_checked_image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span>

<span class="bp">...</span>
<span class="n">x_checked_image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="nf">check_safety</span><span class="p">(</span><span class="n">x_samples_ddim</span><span class="p">)</span>
<span class="bp">...</span>
</code></pre></div></div>

<h3 id="key-components">Key Components</h3>

<ul>
  <li>CLIP Vision Model: Uses a pretrained CLIP vision encoder to extract features from images</li>
  <li>Visual Projection Layer: Projects the CLIP features into a specific embedding space</li>
  <li>Two sets of learned concept embeddings:
    <ul>
      <li>
<code class="language-plaintext highlighter-rouge">concept_embeds</code>: 17 different concepts (presumably NSFW concepts)</li>
      <li>
<code class="language-plaintext highlighter-rouge">special_care_embeds</code>: 3 special concepts that require extra attention</li>
      <li>These embeddings are preloaded and marked as non-trainable (<code class="language-plaintext highlighter-rouge">requires_grad=False</code>).</li>
    </ul>
  </li>
  <li>Corresponding weights for both types of embeddings:
    <ul>
      <li>
<code class="language-plaintext highlighter-rouge">concept_embeds_weights</code>: 17 weights for the 17 concepts</li>
      <li>
<code class="language-plaintext highlighter-rouge">special_care_embeds_weights</code>: 3 weights for the 3 special concepts</li>
      <li>These weights determine how strictly the model filters specific concepts.</li>
    </ul>
  </li>
</ul>

<h3 id="the-detection-process">The Detection Process</h3>

<p><strong>Step 1: Input Processing</strong></p>

<ul>
  <li>The input <code class="language-plaintext highlighter-rouge">clip_input</code> is processed by the vision model to extract pooled features (<code class="language-plaintext highlighter-rouge">pooled_output</code>).</li>
  <li>The pooled features are projected into a lower-dimensional embedding space using <code class="language-plaintext highlighter-rouge">visual_projection</code>.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pooled_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">vision_model</span><span class="p">(</span><span class="n">clip_input</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">image_embeds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">visual_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Step 2: Cosine Similarity Calculation</strong></p>

<ul>
  <li>Cosine distances between the image embeddings and:
    <ul>
      <li>Special Care Embeddings (special_cos_dist).</li>
      <li>General Concept Embeddings (cos_dist).</li>
    </ul>
  </li>
  <li>These distances help determine how closely the input image matches undesirable concepts.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">special_cos_dist</span> <span class="o">=</span> <span class="nf">cosine_distance</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">special_care_embeds</span><span class="p">)</span>
<span class="n">cos_dist</span> <span class="o">=</span> <span class="nf">cosine_distance</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">concept_embeds</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Step 3: Threshold Detection</strong></p>

<ul>
  <li>Compares similarities against learned thresholds (embed_weights)</li>
  <li>Uses an adjustment factor (0.01) if special care concepts are detected</li>
  <li>Marks images as NSFW if they exceed thresholds</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">round</span><span class="p">(</span><span class="n">concept_cos</span> <span class="o">-</span> <span class="n">concept_threshold</span> <span class="o">+</span> <span class="n">adjustment</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</code></pre></div></div>

<p><strong>Step 4: Safety Action</strong></p>

<ul>
  <li>If NSFW content is detected, replaces the image with a black image (zeros)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">has_nsfw_concept</span><span class="p">:</span>
    <span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
</code></pre></div></div>

<h3 id="how-to-get-the-selfconcept_embeds">How to get the <code class="language-plaintext highlighter-rouge">self.concept_embeds</code>?</h3>

<p>The <code class="language-plaintext highlighter-rouge">concept_embeds</code> are initialized as parameters in the model but their actual values are loaded from a pre-trained checkpoint. The code shown only has placeholder initialization:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">self</span><span class="p">.</span><span class="n">concept_embeds</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">projection_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">self</span><span class="p">.</span><span class="n">special_care_embeds</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">projection_dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">self</span><span class="p">.</span><span class="n">concept_embeds_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">17</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">self</span><span class="p">.</span><span class="n">special_care_embeds_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p>The actual concept embeddings come from the safety checker model checkpoint that ships with Stable Diffusion. You can find this model on the HuggingFace Hub as <a href="https://huggingface.co/CompVis/stable-diffusion-safety-checker" rel="external nofollow noopener" target="_blank">CompVis/stable-diffusion-safety-checker</a>.</p>

<p><strong>To get the actual values</strong>, you would need to load the safety checker model (defined in <a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">convert_from_ckpt.py</code></a>) and then access the embeddings:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">diffusers</span> <span class="kn">import</span> <span class="n">StableDiffusionSafetyChecker</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">CLIPFeatureExtractor</span>

<span class="n">safety_checker</span> <span class="o">=</span> <span class="n">StableDiffusionSafetyChecker</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">CompVis/stable-diffusion-safety-checker</span><span class="sh">"</span><span class="p">)</span>

<span class="n">concept_embeds</span> <span class="o">=</span> <span class="n">safety_checker</span><span class="p">.</span><span class="n">concept_embeds</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
<span class="n">special_care_embeds</span> <span class="o">=</span> <span class="n">safety_checker</span><span class="p">.</span><span class="n">special_care_embeds</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="how-to-bypass-the-safety-checker">How to bypass the Safety Checker?</h2>

<p>After reading the code, it is very simple to bypass the Safety Checker by simply set <code class="language-plaintext highlighter-rouge">has_nsfw_concepts</code> always to <code class="language-plaintext highlighter-rouge">False</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">has_nsfw_concepts</span> <span class="o">=</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>In this post, we have discussed the Safety Checker in Stable Diffusion, its implementation, and how to bypass it. We have also provided a detailed explanation of the detection process and the key components of the Safety Checker.
I believe that understanding this module in greater detail can lead to some interesting research ideas, for example, how to quickly update the Safety Checker to detect new NSFW concepts or how to bypass the Safety Checker without modifying the code or can we use this module as a surrogate for other NSFW detection models.</p>

<p>Thank you for reading!</p>

    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/nlp-foundation/">LLM Series - Part 1 - Important Concepts in NLP</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/diffusion-foundation/">Foundation of Diffusion Models</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/thoughts/">Random Thoughts and Notes</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/erasing-concepts/">Fake Taylor Swift and the Adversarial Game of Concept Erasure and Injection</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/f4t/">About me</a>
  </li>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
