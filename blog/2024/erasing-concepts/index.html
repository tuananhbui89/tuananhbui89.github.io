<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Fake Taylor Swift and the Adversarial Game of Concept Erasure and Injection | Tuan-Anh  Bui</title>
    <meta name="author" content="Tuan-Anh  Bui">
    <meta name="description" content="How to stop generating na*ed Taylor Swift">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="http://localhost:4000/blog/2024/erasing-concepts/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "Fake Taylor Swift and the Adversarial Game of Concept Erasure and Injection",
      "description": "How to stop generating na*ed Taylor Swift",
      "published": "February 8, 2024",
      "authors": [
        {
          "author": "Tuan-Anh Bui",
          "authorURL": "https://tuananhbui89.github.io/",
          "affiliations": [
            {
              "name": "Monash University",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tuan-Anh </span>Bui</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/"></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>Fake Taylor Swift and the Adversarial Game of Concept Erasure and Injection</h1>
        <p>How to stop generating na*ed Taylor Swift</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#introduction">Introduction</a></div>
            <div><a href="#erasing-concepts-from-diffusion-models">Erasing Concepts from Diffusion Models</a></div>
            <ul>
              <li><a href="#summary-esd">Summary ESD</a></li>
              <li><a href="#central-optimization-problem">Central Optimization Problem</a></li>
              <li><a href="#final-objective-function">Final Objective Function</a></li>
              
            </ul>
<div><a href="#editing-implicit-assumptions-in-text-to-image-diffusion-models-time">Editing Implicit Assumptions in Text-to-Image Diffusion Models (TIME)</a></div>
            <ul>
              <li><a href="#summary-time">Summary TIME</a></li>
              <li><a href="#central-optimization-problem">Central Optimization Problem</a></li>
              <li><a href="#pros-and-cons">Pros and Cons</a></li>
              
            </ul>
<div><a href="#unified-concept-editing-in-diffusion-models">Unified Concept Editing in Diffusion Models</a></div>
            <ul>
              <li><a href="#summary-uce">Summary UCE</a></li>
              <li><a href="#central-optimization-problem">Central Optimization Problem</a></li>
              <li><a href="#pros-and-cons">Pros and Cons</a></li>
              
            </ul>
<div><a href="#circumventing-concept-erasure-methods-for-text-to-image-generative-models">Circumventing Concept Erasure Methods For Text-to-Image Generative Models</a></div>
            <ul>
              <li><a href="#summary">Summary</a></li>
              
            </ul>
          </nav>
        </d-contents>

        <!-- Pre-intro. Story heading. Summarising the story flow -->

<h2 id="introduction">Introduction</h2>

<!-- Taylor Swift incident and the raise of sexualized generated images -->

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/erasing_concepts/taylor-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/erasing_concepts/taylor-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/erasing_concepts/taylor-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/erasing_concepts/taylor.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<p>Recently, X (Twitter) had been flooded with <strong>sexually explicit</strong> AI-generated images of Taylor Swift, shared by many X users. As reported by <a href="https://www.theverge.com/2024/1/25/24050334/x-twitter-taylor-swift-ai-fake-images-trending" rel="external nofollow noopener" target="_blank">The Verge</a>, <em>“One of the most prominent examples on X attracted more than 45 million views, 24,000 reposts, and hundreds of thousands of likes and bookmarks before the verified user who shared the images had their account suspended for violating platform policy. The post remained live on the platform for about 17 hours before its removal”</em>.
Soon after, X had to block the searches for Taylor Swift as the last resort to prevent the spread of these images (Ref to <a href="https://www.theverge.com/2024/1/27/24052841/taylor-swift-search-blocked-x-twitter-ai-images" rel="external nofollow noopener" target="_blank">The Verge</a>).</p>

<p>While this incident has certainly raised public awareness about the threat of AI-generated content, including the spread of misinformation, racism, and sexism, the general public might think such incidents only happen to famous figures like Taylor Swift and may not take it personally. However, that is not the case. With recent advancements in personalized AI-generated content, led by the Dreambooth project <d-cite key="ruiz2023dreambooth"></d-cite>, it has become very easy and efficient to customize or personalize generated content with just a few sample images of a person. Therefore, generating sexually explicit images of any individual, not just Taylor Swift, is alarmingly easy.
In fact, this is already occurring, as reported <a href="https://apnews.com/article/generative-ai-illegal-images-child-abuse-3081a81fa79e2a39b67c11201cfd085f" rel="external nofollow noopener" target="_blank">here</a> and <a href="https://lifehacker.com/evil-week-you-can-make-personalized-porn-images-with-a-1850978902" rel="external nofollow noopener" target="_blank">here</a> and you might find plenty of similar reports even without trying.</p>

<p><strong>Naive approaches to prevent unwanted concepts</strong></p>

<p>There are several naive approaches aimed at preventing the generation of unwanted content, but none have proven fully effective, particularly with the release of generative models like Stable Diffusion, which come complete with source code and pre-trained models accessible to the public. For instance:</p>

<ul>
  <li>
    <p>Implementing a Not-Safe-For-Work (NSFW) detector to filter out harmful content. This approach is practically the most effective, and it is commonly deployed by models’ developers like OpenAI (owner of Dall-E), StabilityAI (owner of Stable Diffusion), and Midjourney Inc (owner of Midjourney). However, with the open-source nature of the Stable Diffusion model, the NSFW detector can be easily bypassed by modifying the source code, for instance, by modifying this <a href="https://github.com/huggingface/diffusers/blob/7c8cab313e4c66a813d146bcf92023b0489a2369/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L551" rel="external nofollow noopener" target="_blank">line</a> in the Huggingface library. For closed-source models like Dall-E, there are still ways to bypass these filters, as demonstrated in the paper <a href="https://www.technologyreview.com/2023/11/17/1083593/text-to-image-ai-models-can-be-tricked-into-generating-disturbing-images" rel="external nofollow noopener" target="_blank">“SneakyPrompt: Jailbreaking Text-to-image Generative Models”</a> <d-cite key="yang2024sneakyprompt"></d-cite>. They utilized a technique similar to the Boundary Attack <d-cite key="brendel2017decision"></d-cite> to search for adversarial prompts that look like garbled nonsense to us but that AI models learn to recognize as hidden requests for disturbing images by querying the model many times and adjusting the prompt based on the model’s responses.</p>
  </li>
  <li>
    <p>Modifying the text encoder to transform text embeddings of harmful concepts into a zero vector or a random vector. This approach means that a prompt such as “naked Taylor Swift” would result in a random image, rather than something sexually explicit. However, the ease of accessing and replacing the pre-trained models makes this method unreliable.</p>
  </li>
  <li>
    <p>Excluding all training data containing harmful content and retraining the model from scratch. This method was employed by the Stable Diffusion team in their <a href="https://github.com/Stability-AI/stablediffusion" rel="external nofollow noopener" target="_blank">version 2.0</a>, which utilized 150,000 GPU-hours to process the 5-billion-image LAION dataset. Despite this effort, the quality of generated images declined, and the model wasn’t entirely sanitized, as highlighted in the ESD paper <d-cite key="gandikota2023erasing"></d-cite>. The reduction in image quality led to <a href="https://thealgorithmicbridge.substack.com/p/stable-diffusion-2-is-not-what-users" rel="external nofollow noopener" target="_blank">dissatisfaction within the AI community</a>, prompting a return to less restrictive NSFW training data in <a href="https://github.com/Stability-AI/stablediffusion" rel="external nofollow noopener" target="_blank">version 2.1</a> <img class="emoji" title=":joy:" alt=":joy:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png" height="20" width="20">.</p>
  </li>
</ul>

<p>To date, the most effective strategy on sanitizing the open-source models like Stable Diffusion is to sanitize the generator (i.e., UNet) in the diffusion model after training on raw, unfiltered data and before its public release. This approach is demonstrated somewhat effectively in the ESD paper <d-cite key="gandikota2023erasing"></d-cite>, which I will cover in the next section.</p>

<p><strong>The new adversarial game</strong></p>

<p>The adversarial game between attackers and defenders have been well-known in the field of AI,  tracing back to the pioneering work on adversarial examples by Szegedy et al. (2013) <d-cite key="szegedy2013intriguing"></d-cite> or even earlier studies by Biggio et al. (2008) <d-cite key="biggio2018wild"></d-cite>.
Previously, these battles are most prevalent in areas of discriminative models like image classification, object detection, etc, where attackers aim to generate adversarial examples to alter the model’s predictions, while defenders strive to prevent the model from being fooled by these adversarial examples. (If you are interested in this topic, you can read <a href="https://tuananhbui89.github.io/blog/2023/showcases/" rel="external nofollow noopener" target="_blank">my tutorials on Adversarial Machine Learning here</a>).</p>

<p>However, with the rise of generative models capable of producing high-quality outputs, and not only by researchers but also by being decentralized to the public, the scope of adversarial games has broadened. This expansion introduces a myriad of new challenges and scenarios within the realm of generative models. For instance, as discussed in a <a href="https://tuananhbui89.github.io/blog/2023/watermark-diffusion/" rel="external nofollow noopener" target="_blank">previous post</a>, I introduced an adversarial game involving watermarking, pitting concept owners (e.g., artists seeking to safeguard their creations) against concept synthesizers (individuals utilizing generative models to replicate specific artworks).</p>

<p>In this post, I will delve into a new adversarial game that pits concept erasers (individuals aiming to eliminate harmful or unwanted content such as sexually explicit material, violence, racism, sexism, or personalized concepts like Taylor Swift) against concept injectors (those who wish to introduce new concepts or restore previously erased ones).</p>

<p>Specifically, I will introduce some notable works from the two parties include the following:</p>

<ul>
  <li>
<strong>Erasing harmful concepts</strong>: Erasing Concepts from Diffusion Models (ESD) <d-cite key="gandikota2023erasing"></d-cite>, Editing Implicit Assumptions in Text-to-Image Diffusion Models (TIME) <d-cite key="orgad2023editing"></d-cite>, Unified Concept Editing in Diffusion Models (UCE) <d-cite key="gandikota2024unified"></d-cite>.</li>
  <li>
<strong>Injecting or recover harmful concepts</strong>: Circumventing Concept Erasure Methods For Text-to-Image Generative Models <d-cite key="gandikota2024unified"></d-cite>.</li>
  <li>
<strong>Anti personalization</strong>: Anti-Dreambooth <d-cite key="van2023anti"></d-cite> and Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis <d-cite key="ma2023generative"></d-cite> (introduced in the previous post <a href="https://tuananhbui89.github.io/blog/2023/anti-personalization/" rel="external nofollow noopener" target="_blank">here</a>).</li>
</ul>

<p>The post might be a bit long and technical, but I hope it will provide you with a brief understanding on the technicalities of these works. For the general public, I hope it will raise awareness about the potential of AI to generate unwanted concepts and the urgent need on research to prevent the generation of unwanted concepts.</p>

<!-- TakeAway Conclusion -->

<p><strong>Takeaway conclusion</strong></p>

<ul>
  <li>The recent incident of AI-generated sexual explicit images of Taylor Swift has raised a lot of concerns about the potential of AI to generate unwanted concepts and the urgent need on research to prevent the generation of unwanted concepts.</li>
  <li>There is an initial research on the adversarial games between concept erasers and concept injectors. The concept erasers try to erase unwanted concepts while the concept injectors try to inject new concepts or recover the erased concepts.</li>
  <li>While the concept erasers have shown some initial success in erasing unwanted concepts, the concept injectors have also shown that it is easy to circumvent the concept erasers.</li>
</ul>

<h2 id="erasing-concepts-from-diffusion-models">Erasing Concepts from Diffusion Models</h2>
<d-cite key="gandikota2023erasing"></d-cite>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2309/erasing_concepts/examples-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2309/erasing_concepts/examples-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2309/erasing_concepts/examples-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2309/erasing_concepts/examples.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Examples of erasing nudity, Van Gogh style or an objects from a Stable Diffusion model (Image source: <a href="https://erasing.baulab.info/" rel="external nofollow noopener" target="_blank">Gandikota et al. (2023)</a>).
</div>

<ul>
  <li>Project page: <a href="https://erasing.baulab.info/" rel="external nofollow noopener" target="_blank">https://erasing.baulab.info/</a>
</li>
</ul>

<h3 id="summary-esd">Summary ESD</h3>

<ul>
  <li>
<strong>Goal</strong>: ESD aims to erase harmful concepts such as nudity, violence, or specific artist styles like “Van Gogh” from the generative models such as Stable Diffusion while maintaining the quality of the generated images for other concepts.</li>
  <li>
<strong>Approach</strong>: The authors proposed to alter the guiding signal regarding the concept to be erased to the one regarding the “null” concept (i.e., a neural prompt like “A photo”, “A person”), i.e., \(\epsilon_\theta(z_t, c, t) \to \epsilon_\theta(z_t, c_{null}, t)\). The approach varies depending on whether the concept is directly expressible (such as “truck” or “dog”) or more abstract (like “nudity”). For direct concepts, modifications to the cross-attention layers of the diffusion model prove more effective, whereas abstract concepts necessitate adjustments to different layers for successful removal.</li>
</ul>

<h3 id="central-optimization-problem">Central Optimization Problem</h3>

<p>The central optimization problem is to reduce  the probability of generating an image \(x\) according to the likelihood that is described by the concept, scaled by a power factor \(\eta\).</p>

\[P_\theta(x) \propto \frac{P_{\theta^*}(x)}{P_{\theta^*}(c \mid x)^\eta}\]

<p>where \(P_{\theta^*}(x)\) is the distribution generated by the original model \(\theta^*\) and \(P_{\theta^*}(c \mid x)\) is the probability of the concept \(c\) given the image \(x\). The power factor \(\eta\) controls the strength of the concept erasure. A larger \(\eta\) means a stronger erasure. \(\theta\) is the parameters of the model after unlearning the concept \(c\).</p>

<p>It can be interpreted as: if the concept \(c\) is present in the image \(x\) in which \(P_{\theta^*} (c \mid x)\) is high, then the likelihood of the image \(x\) under the new model \(P_{\theta} (x)\) will be reduced.
While if the concept \(c\) is not present in the image \(x\) in which \(P_{\theta^*} (c \mid x)\) is low, then the likelihood of the image \(x\) under the new model \(P_{\theta} (x)\) will be increased.</p>

<p>Because of the Bayes’ rule, the likelihood of the concept \(c\) given the image \(x\) can be rewritten as follows:</p>

\[P_{\theta^*} (c \mid x) = \frac{P_{\theta^*} (x \mid c) P_{\theta^*} (c)}{P_{\theta^*} (x)}\]

<p>Therefore, the above equation can be rewritten when taking the derivative w.r.t. \(x\) as follows (you might need to rotate your phone to see the full equation <img class="emoji" title=":joy:" alt=":joy:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png" height="20" width="20">):</p>

\[\nabla_{x} \log P_{\theta} (x) \propto \nabla_{x} \log P_{\theta^*} (x) - \eta \nabla_{x} \log P_{\theta^*} (c \mid x)\]

\[\nabla_{x} \log P_{\theta} (x) \propto \nabla_{x} \log P_{\theta^*} (x) - \eta (\nabla_{x} \log P_{\theta^*} (x \mid c) + \nabla_{x} \log P_{\theta^*} (c) - \nabla_{x} \log P_{\theta^*} (x))\]

\[\nabla_{x} \log P_{\theta} (x) \propto \nabla_{x} \log P_{\theta^*} (x) - \eta (\nabla_{x} \log P_{\theta^*} (x \mid c) - \nabla_{x} \log P_{\theta^*} (x))\]

<p>Because in the diffusion model, each step has been approximated to a Gaussian distribution, therefore, the gradient of the log-likelihood is computed as follows:</p>

\[\nabla_{x} \log P_{\theta^*} (x) = \frac{1}{\sigma^2} (x - \mu)\]

<p>where \(\mu\) is the mean of the diffusion model, \(\sigma\) is the standard deviation of the diffusion model, and \(c\) is the concept.
Based on the repameterization trick, the gradient of the log-likelihood is correlated with the noise \(\epsilon\) at each step as follows (linking between DDPM <d-cite key="ho2020denoising"></d-cite> and the score-based matching <d-cite key="song2020score"></d-cite>):</p>

\[\epsilon_{\theta}(x_t,t) \propto \epsilon_{\theta^*} (x_t,t) - \eta (\epsilon_{\theta^*}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t))\]

<p>where \(\epsilon_{\theta}(x_t,t)\) is the noise at step \(t\) of the diffusion model after unlearning the concept \(c\).
Finally, to fine-tune the diffusion model from pretrained model \(\theta^*\) to new cleaned model \(\theta\), the authors proposed to minimize the following loss function:</p>

\[\mathcal{L}(\theta) = \mathbb{E}_{x_0 \sim \mathcal{D}} \left[ \sum_{t=0}^{T-1} \left\| \epsilon_{\theta}(x_t,t) - \epsilon_{\theta^*} (x_t,t) + \eta (\epsilon_{\theta^*}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t)) \right\|^2 \right]\]

<p>where \(x_0\) is the input image sampled from data distribution \(\mathcal{D}\), \(T\) is the number of steps of the diffusion model.</p>

<p>Instead of recursively sampling the noise \(\epsilon_{\theta}(x_t,t)\) at every step, we can sample the time step \(t \sim \mathcal{U}(0, T-1)\) and then sample the noise \(\epsilon_{\theta}(x_t,t)\) at that time step.
Therefore, the loss function can be rewritten as follows:</p>

\[\mathcal{L}(\theta) = \mathbb{E}_{x_0 \sim \mathcal{D}} \left[ \left\| \epsilon_{\theta}(x_t,t) - \epsilon_{\theta^*} (x_t,t) + \eta (\epsilon_{\theta^*}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t)) \right\|^2 \right]\]

<p>where \(t \sim \mathcal{U}(0, T-1)\).</p>

<h3 id="final-objective-function">Final Objective Function</h3>

<p>However, in the paper, instead of using the above loss function, the author proposed to use the following loss function:</p>

\[\mathcal{L}(\theta) = \mathbb{E}_{x_0 \sim \mathcal{D}} \left[  \left\| \epsilon_{\theta}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t) + \eta (\epsilon_{\theta^*}(x_t,c,t) - \epsilon_{\theta^*} (x_t,t)) \right\|^2 \right]\]

<p>where \(t \sim \mathcal{U}(0, T-1)\).</p>

<p>The difference between the two loss functions is that the first loss function is computed based on the unconditional noise \(\epsilon_{\theta}(x_t,t)\) at the time step \(t\) while the second loss function is computed based on the noise \(\epsilon_{\theta}(x_t,c,t)\) at the time step \(t\) conditioned on the concept \(c\).</p>

<p><strong>Interpretation of the loss function</strong>: By minimizing the above loss function, we try to force the conditional noise \(\epsilon_{\theta}(x_t,c,t)\) to be close to the unconditional noise \(\epsilon_{\theta^*} (x_t,t)\) of the original model. Because the noise \(\epsilon_{\theta^*} (x_t,t)\) is the signal to guide the diffusion model to generate the image \(x_{t-1}\) (recall the denoising equation \(x_{t-1} = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_{\theta^*} (x_t,t)) + \sigma_t z\)), therefore, by forcing the conditional noise \(\epsilon_{\theta}(x_t,c,t)\) to be close to the unconditional noise \(\epsilon_{\theta^*} (x_t,t)\), we try to force the diffusion model to generate the image \(x_{t-1}\) close to the image generated without the concept \(c\).</p>

<p><strong>Note</strong>: In the above objective function, \(x_t\) is the image from the training set \(\mathcal{D}\) at time step \(t\). However, as mentioned in the paper “We exploit the model’s knowledge of the concept to synthesize training samples, thereby eliminating the need for data collection”. Therefore, in the implementation, \(x_t\) is the image generated by the fine-tuned model at time step \(t\).</p>

<h2 id="editing-implicit-assumptions-in-text-to-image-diffusion-models-time">Editing Implicit Assumptions in Text-to-Image Diffusion Models (TIME)</h2>
<d-cite key="orgad2023editing"></d-cite>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/erasing_concepts/Time%20-%20fig1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/erasing_concepts/Time%20-%20fig1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/erasing_concepts/Time%20-%20fig1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/erasing_concepts/Time%20-%20fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<p>Paper: <a href="https://arxiv.org/abs/2303.08084" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2303.08084</a></p>

<p>Code: <a href="https://github.com/bahjat-kawar/time-diffusion" rel="external nofollow noopener" target="_blank">https://github.com/bahjat-kawar/time-diffusion</a></p>

<h3 id="summary-time">Summary TIME</h3>

<ul>
  <li>
<strong>Goal</strong>: receives an under-specified “source” prompt (e.g., “A pack of roses”), which is requested to be well-aligned with a “destination” prompt (e.g., “A pack of blue roses”) containing an attribute that the user wants to promote (e.g., “blue roses”). After the editing, the model should change its behavior on only related prompts (e.g., image generated by a prompt “A field of roses” will be changed to red roses) while not affecting the characteristics or perceptual quality in the generation of different concepts (e.g., image generated by a prompt “A poppy field” will not be changed) (Ref to the figure above).</li>
  <li>
<strong>Implications</strong>: The change is expected to manifest in generated images for related concepts, while not affecting the characteristics or perceptual quality in the generation of different ones. This would allow us to fix incorrect, biased, or outdated assumptions that text-to-image models may make. For example, gender bias with the concept “doctor” or “teacher”. This method can also be used to erase harmful concepts such as “nudity” or “gun” from the model by mapping them to “safe/neutrual” concept like “flower” or “cat” or “null”.</li>
  <li>
<strong>Important</strong> this approach edits the projection matrices in the <strong>cross-attention</strong> layers to map the source prompt close to the destination, without substantially deviating from the original weights. Because these matrices <strong>operate on textual data</strong> irrespective of the diffusion process or the image contents, they constitute a compelling location for editing a model based on textual prompts.</li>
</ul>

<h3 id="central-optimization-problem-1">Central Optimization Problem</h3>

<p>Given a pretrain layer \(W^{*}\), a set of concepts to be edited \(E\) (i.e., “roses”, “doctor”, “nudity”), the goal is to find a new layer \(W\) that is close to \(W^{*}\) but does not contain any concept in \(E\).</p>

<p>To do that, <d-cite key="orgad2023editing"></d-cite> proposed to use the following optimization problem:</p>

\[\underset{W}{\min} \sum_{c_i \in E} \| W c_i - v_i^* \|^2_2 + \lambda \| W - W^{*} \|^2_2\]

<p>where \(v_i^*\) is the targeted vector for concept \(c_i\).</p>

<p>As derived in <d-cite key="orgad2023editing"></d-cite>, the solution of this optimization problem is:</p>

\[W = \left( \sum_{c_i \in E} v_i^* c_i^T + \lambda W^{*}  \right) \left( \sum_{c_i \in E} c_i c_i^T + \lambda \mathbb{I} \right)^{-1}\]

<p>By defining \(v^*\) differently, the authors proposed 3 types of editing:</p>

<ul>
  <li>
<strong>Erasing/Moderation</strong>: Choose \(v^* = W c^*\), where \(c^*\) is the targeted concept different from the concepts to be earased \(c_i \in E\)$. For example, harmful concept like “nudity” or “gun” can be erased to “safe/neutrual” concept like “flower” or “cat”, or artistic concept like “Kelly Mckernan” or “Van Gogh” to “non-artistic” concept like “art” or “ “.</li>
  <li>
<strong>Debiasing</strong>: Choose \(v^* = W (c_i + \sum_{t=1}^p \alpha_t a_t)\) where \(c_i\) is “doctor” and \(a_t\) is attributes that we want to distribute across such as “white”, “asian”, “black”. By this way, the original concept “doctor” no longer only associated with “white” but also with “asian” and “black”.</li>
</ul>

<h3 id="pros-and-cons">Pros and Cons</h3>

<p><strong>Pros:</strong></p>

<ul>
  <li>It does not require training or finetuning, it can be applied in parallel for all cross-attention layers, and it modifies only a small portion of the diffusion model weights while leaving the language model unchanged. When applied on the publicly available Stable Diffusion, TIME edits a mere 2.2% of the diffusion model parameters, does not modify the text encoder, and applies the edit in a fraction of a second using a single consumergrade GPU.</li>
</ul>

<p><strong>Cons:</strong></p>

<ul>
  <li>It risks interference with surrounding concepts when editing a particular concept. For example, editing doctors to be female might also affect teachers to be female. <d-cite key="gandikota2024unified"></d-cite>.</li>
  <li>TIME has a regularization term that prevents the edited matrix from changing too radically. However, it is a general term and thus affects all vector rep- resentations equally. The follow-up work of <d-cite key="orgad2023editing"></d-cite> proposes an alternative preservation term that allows targeted editing of the parameters of the pretrained generative model while maintaining its core capabilities.</li>
</ul>

<h2 id="unified-concept-editing-in-diffusion-models">Unified Concept Editing in Diffusion Models</h2>
<d-cite key="gandikota2024unified"></d-cite>

<ul>
  <li>Accepted to WACV 2024. <a href="https://arxiv.org/pdf/2308.14761.pdf" rel="external nofollow noopener" target="_blank">https://arxiv.org/pdf/2308.14761.pdf</a>
</li>
  <li>Affiliation: Northeastern University, Technion and MIT. Same group with the ESD paper.</li>
  <li>Link to Github: <a href="https://github.com/rohitgandikota/unified-concept-editing" rel="external nofollow noopener" target="_blank">https://github.com/rohitgandikota/unified-concept-editing</a>
</li>
</ul>

<h3 id="summary-uce">Summary UCE</h3>

<ul>
  <li>It is a follow-up work of <d-cite key="orgad2023editing"></d-cite> that proposes an alternative preservation term that allows targeted editing of the parameters of the pretrained generative model while maintaining its core capabilities.</li>
</ul>

<h3 id="central-optimization-problem-2">Central Optimization Problem</h3>

<p>Given a pretrain layer \(W^{*}\), a set of concepts to be edited \(E\) and a set of concepts to be preserved \(P\), the goal is to find a new layer \(W\) that is close to \(W^{*}\) but does not contain any concept in \(E\) and preserve all concepts in \(P\).</p>

<p>To do that, <d-cite key="gandikota2024unified"></d-cite> proposed to use the following optimization problem:</p>

\[\underset{W}{\min} \sum_{c_i \in E} \| W c_i - v_i^* \|^2_2 + \sum_{c_j \in P} \| W c_j - W^* c_j \|^2_2\]

<p>where \(v_i^*\) is the targeted vector for concept \(c_i\).</p>

<p>As derived in <d-cite key="orgad2023editing"></d-cite>, the solution of this optimization problem is:</p>

\[W = \left( \sum_{c_i \in E} v_i^* c_i^T + \sum_{c_j \in P} W^* c_j cj^T \right) \left( \sum_{c_i \in E} c_i c_i^T + \sum_{c_j \in P} c_j c_j^T \right)^{-1}\]

<p>By defining \(v^*\) differently, the authors proposed 3 types of editing:</p>

<ul>
  <li>
<strong>Erasing/Moderation</strong>: Choose \(v^* = W c^*\), where \(c^*\) is the targeted concept different from the concepts to be earased \(c_i \in E\)$. For example, harmful concept like “nudity” or “gun” can be erased to “safe/neutrual” concept like “flower” or “cat”, or artistic concept like “Kelly Mckernan” or “Van Gogh” to “non-artistic” concept like “art” or “ “.</li>
  <li>
<strong>Debiasing</strong>: Choose \(v^* = W (c_i + \sum_{t=1}^p \alpha_t a_t)\) where \(c_i\) is “doctor” and \(a_t\) is attributes that we want to distribute across such as “white”, “asian”, “black”. By this way, the original concept “doctor” no longer only associated with “white” but also with “asian” and “black”.</li>
</ul>

<h3 id="pros-and-cons-1">Pros and Cons</h3>

<p><strong>Pros:</strong></p>

<ul>
  <li>Fast and efficient. It can finish the editing in less than 5 minutes on a single V100 GPU (Compared to 1 hour for the ESD method). The editing performance in some settings (e.g., erasing object-related concepts such as “trucks”, “tench”) is better than the ESD method.</li>
</ul>

<p><strong>Poor performance</strong>
The performance on erasing concepts is still limited. As I reproduced the experiment to erase artist concept call “Kelly Mckernan” and compare with the original model, the two generated images from two models are still very similar.</p>

<p><strong>Limited Expressiveness</strong>
The authors use textual prompt as the input to specify the concept to be erased, e.g., “Kelly Mckernan” or “Barack Obama” or “nudity”. However, a concept can be described in many different ways, for example, “Barack Obama” can be described as “the 44th president of the United States” or “the first African American president of the United States”. Therefore, it is not possible to erase all concepts related to “Barack Obama” by just erasing the keyword “Barack Obama”.</p>

<p><strong>Unaware of the time step</strong>
In this formulation, the authors just proposed to rewrite the projection matrices \(W_K\) and \(W_V\) of the attention layer \(W\) independently and ignore the query matrix \(W_Q\). However, the query ouput \(W_Q x\) has the information about the time step \(t\) of the diffusion model.</p>

<p><strong>Unknown preserved concepts</strong>
In term of methodology, while there is a closed-form solution for the optimization problem, it is not clear how to solve the optimization problem when the number of preserved concepts is large and even uncountable (i.e., how we can know how many concept that Stable Diffusion can generate?).
In fact, I have tried to run the experiment to erase 5 concepts from the ImageNette dataset while not specifying the preserved concepts. While the erasing rate can be 100\%, the preserving rate is low, especially for those concepts that are not specified to be preserved.</p>

<p><strong>Invertibility issue</strong>
If we just ignore the preserved concepts, the optimization problem is still problematic.</p>

\[W = \left( \sum_{c_i \in E} v_i^* c_i^T \right) \left( \sum_{c_i \in E} c_i c_i^T \right)^{-1}\]

<p>where \(v_i^*\) is the targeted vector for concept \(c_i\).</p>

<p>Let’s dig deeper into this OP. As mentioned in the paper, \(v_i^*=W^* c_{tar}\) where \(c_{tar}\) is the targeted concept different from the concepts to be earased \(c_i \in E\)$ such as “nudity” or “gun” can be erased to “safe/neutrual” concept like “flower” or “cat”, or artistic concept like “Kelly Mckernan” or “Van Gogh” to “non-artistic” concept like “art” or “ “.</p>

<p>In implementation, \(c_i\) and \(c_{tar}\) are input of the attention layer \(W\) which are ouput of the text encoder, therefore, they are unchanged during the optimization process.</p>

<p>Therefore, the optimization problem can be rewritten as follows:</p>

\[W = \left( \sum_{c_i \in E} W^* c_{tar} c_i^T \right) \left( \sum_{c_i \in E} c_i c_i^T \right)^{-1}\]

<p>where \(W^* c_i\) is the projected vector.</p>

<p>As mentioned in Appendix A of the paper, one condition to ensure that the optimization problem has a solution is that the matrix \(\sum_{c_i \in E} c_i c_i^T\) is invertible. To ensure this condition, the authors proposed to add \(d\) additional preservation terms along the canonical basis vectors (i.e., adding identity matrix) as follows:</p>

\[W = \left( \sum_{c_i \in E} W^* c_{tar} c_i^T \right) \left( \sum_{c_i \in E} c_i c_i^T + \lambda I \right)^{-1}\]

<p>where \(\lambda\) is a regularization factor and \(I\) is the identity matrix. While this trick can ensure the invertibility, it can be seen that these additional preservation terms can affect the projection of the concepts to be erased \(c_i \in E\) and thus affect the erasing process (i.e., too big \(\lambda\))</p>

<p>Recall some basic linear algebra:</p>

<blockquote>
  <p>\(c_i\) is a vector with \(d\) dimensions, therefore, \(c_i c_i^T\) is a matrix with \(d \times d\) dimensions.</p>
</blockquote>

<blockquote>
  <p>W is a projection matrix with \(d_o \times d\) dimensions, therefore, \(W c_i\) is a vector with \(d_o\) dimensions and \(W c_i c_i^T\) is a matrix with \(d_o \times d\) dimensions.</p>
</blockquote>

<blockquote>
  <p>If \(c_i\) is a non-zero vector, then \(c_i c_i^T\) has rank 1. Therefore, \(\sum_{c_i \in E} c_i c_i^T\) has rank at most \(\min(\mid E \mid, d)\).</p>
</blockquote>

<blockquote>
  <p><strong>what is the canonical basic vectors?</strong></p>

  <p>The canonical basis vectors are the vectors with all components equal to zero except for one component equal to one. For example, in \(\mathbb{R}^3\), the canonical basis vectors are \(e_1 = (1, 0, 0)\), \(e_2 = (0, 1, 0)\) and \(e_3 = (0, 0, 1)\).</p>
</blockquote>

<h2 id="circumventing-concept-erasure-methods-for-text-to-image-generative-models">Circumventing Concept Erasure Methods For Text-to-Image Generative Models</h2>
<d-cite key="pham2023circumventing"></d-cite>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/erasing_concepts/circumvent-fig1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/erasing_concepts/circumvent-fig1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/erasing_concepts/circumvent-fig1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/erasing_concepts/circumvent-fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<ul>
  <li>Paper: <a href="https://openreview.net/forum?id=ag3o2T51Ht" rel="external nofollow noopener" target="_blank">https://openreview.net/forum?id=ag3o2T51Ht</a>
</li>
  <li>Accepted to ICLR 2024</li>
</ul>

<h3 id="summary">Summary</h3>

<ul>
  <li>The paper proposes a method called Concept Inversion to circumvent 7 recent concept erasure methods for text-to-image generative models including Erased Stable Diffusion <d-cite key="gandikota2023erasing"></d-cite>, Selective Amnesia <d-cite key="heng2023selective"></d-cite>, Forget-me-not <d-cite key="zhang2023forget"></d-cite>, Ablating Concepts <d-cite key="kumari2023ablating"></d-cite>, Unified Concept Editing <d-cite key="gandikota2024unified"></d-cite>, Negative Prompt <d-cite key="negativeprompt1111, miyake2023negative"></d-cite>, and Safe Latent Diffusion <d-cite key="schramowski2023safe"></d-cite>. The authors show that with even with zero training or fine-tuning the pretrained erased model, it is possible to generate the erased concept with a suitably constructed prompt.</li>
  <li>The authors utilized the Textual Inversion <d-cite key="gal2022image"></d-cite> technique to find special word embeddings that can recover the erased concepts. The method is simply yet effective showing that existing concept erasure methods actually perform some form of concept hiding or textually obfuscating rather than concept erasure. For example, while the erased model may not generate images of “nudity” when prompted with a word “nudity”, it can still generate images of “nudity” when prompted with a special phrase “a person without clothes”. We can intuitively understand the approach is find a special embedding \(S^{*}\) that represents these special phrases by inversing some images with the erased concept and then use this special embedding to generate the erased concept like “A person \(S^{*}\)”.</li>
  <li>
<strong>Cons</strong> Because using the Textual Inversion technique, this method needs to replace the original Embedding Lookup table so that it can map the placeholder \(S^{*}\) to the special embedding \(v^{*}\).</li>
</ul>

<p><strong>Recall the Textual Inversion technique</strong> <d-cite key="gal2022image"></d-cite>:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/textual_inversion/examples-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/textual_inversion/examples-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/textual_inversion/examples-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/textual_inversion/examples.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/textual_inversion/method-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/textual_inversion/method-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/textual_inversion/method-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/textual_inversion/method.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>

<p>Given a pretrained text-to-image generative model (Unet) \(\epsilon_\theta\), textual encoder \(c_\phi\) (denoted as \(c_\theta\) as the figure above, but it seems to be confused with the Unet \(\epsilon_\theta\)) and set of target images \(X\), and a specific text placeholder \(S^{*}\) that corresponds to a specific textual embedding vector \(v^{*}\), the goal is to find the special textual embedding vector \(v^{*}\) that can reconstruct the input image \(x \sim X\). The authors proposed to use the following optimization problem which is the same as the DDPM model but with the special placeholder/prompt \(S^{*}\):</p>

\[v^{*} = \underset{v}{\arg\min} \; \mathbb{E}_{z \sim \varepsilon(x), x \sim X, \epsilon \sim \mathcal{N}(0,I), t} [ \|\epsilon - \epsilon_\theta (z_t, c_\phi(v), t) \|_2^2 ]\]

<p>where \(v\) is the textual embedding vector \(v = \text{Lookup}(S^{*})\).</p>

<p><strong>Adapt to the concept erasure problem</strong></p>

<p>Given the background of the Textual Inversion technique, it is just straightforward to adapt this technique to circumvent the concept erasure problem. Most of the concept erasure methods are hacked by standard Textual Inversion. More details can be found in the paper. One important thing is that the authors need to have a set of target images \(X\) that contains the erased concept. The authors made an assume that the adversary can access a small number of
examples of the targeted concept from Google Images, specifically, 6 samples for art style concept (e.g., Van Gogh), 30 samples for object concept (e.g., cassette player), and 25 samples for ID concept (e.g., Angelina Jolie).</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/2024-02-08.bib"></d-bibliography>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Tuan-Anh  Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KGSMMS9MS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7KGSMMS9MS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
